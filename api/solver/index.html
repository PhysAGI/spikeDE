
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://physagi.github.io/spikeDE/api/solver/">
      
      
        <link rel="prev" href="../snn/">
      
      
        <link rel="next" href="../surrogate/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.3">
    
    
      
        <title>spikeDE.solver - spikeDE Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../assets/stylesheets/mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#spikedesolver" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="spikeDE Documentation" class="md-header__button md-logo" aria-label="spikeDE Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            spikeDE Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              spikeDE.solver
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="white" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/PhysAGI/spikeDE" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    PhysAGI/spikeDE
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../.." class="md-tabs__link">
          
  
  
    
  
  Home

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../get_start/" class="md-tabs__link">
          
  
  
    
  
  Getting started

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../tutorials/" class="md-tabs__link">
          
  
  
    
  
  Tutorials

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
    
  
  API Reference

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../blog/" class="md-tabs__link">
          
  
  
    
  
  Blog

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="spikeDE Documentation" class="md-nav__button md-logo" aria-label="spikeDE Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    spikeDE Documentation
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/PhysAGI/spikeDE" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    PhysAGI/spikeDE
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../.." class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../get_start/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    Getting started
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../tutorials/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    Tutorials
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    API Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../neuron/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    spikeDE.neuron
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../odefunc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    spikeDE.odefunc
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../snn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    spikeDE.snn
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    spikeDE.solver
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    spikeDE.solver
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#key-features" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Features
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.PerLayerAlphaInfo" class="md-nav__link">
    <span class="md-ellipsis">
      
        PerLayerAlphaInfo
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.SNNSolverConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        SNNSolverConfig
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SNNSolverConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#spikeDE.solver.SNNSolverConfig.from_inputs" class="md-nav__link">
    <span class="md-ellipsis">
      
        from_inputs
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.SNNFractionalMethod" class="md-nav__link">
    <span class="md-ellipsis">
      
        SNNFractionalMethod
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SNNFractionalMethod">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#spikeDE.solver.SNNFractionalMethod.stores_f_history" class="md-nav__link">
    <span class="md-ellipsis">
      
        stores_f_history
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spikeDE.solver.SNNFractionalMethod.compute_convolution" class="md-nav__link">
    <span class="md-ellipsis">
      
        compute_convolution
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spikeDE.solver.SNNFractionalMethod.compute_update_for_layer" class="md-nav__link">
    <span class="md-ellipsis">
      
        compute_update_for_layer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spikeDE.solver.SNNFractionalMethod.compute_weights_for_layer" class="md-nav__link">
    <span class="md-ellipsis">
      
        compute_weights_for_layer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spikeDE.solver.SNNFractionalMethod.initialize" class="md-nav__link">
    <span class="md-ellipsis">
      
        initialize
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.GrunwaldLetnikovSNN" class="md-nav__link">
    <span class="md-ellipsis">
      
        GrunwaldLetnikovSNN
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.ProductTrapezoidalSNN" class="md-nav__link">
    <span class="md-ellipsis">
      
        ProductTrapezoidalSNN
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.L1MethodSNN" class="md-nav__link">
    <span class="md-ellipsis">
      
        L1MethodSNN
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.AdamsBashforthSNN" class="md-nav__link">
    <span class="md-ellipsis">
      
        AdamsBashforthSNN
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.GrunwaldLetnikovMultitermSNN" class="md-nav__link">
    <span class="md-ellipsis">
      
        GrunwaldLetnikovMultitermSNN
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.FDEAdjointMethod" class="md-nav__link">
    <span class="md-ellipsis">
      
        FDEAdjointMethod
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FDEAdjointMethod">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#spikeDE.solver.FDEAdjointMethod.backward" class="md-nav__link">
    <span class="md-ellipsis">
      
        backward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spikeDE.solver.FDEAdjointMethod.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.snn_solve" class="md-nav__link">
    <span class="md-ellipsis">
      
        snn_solve
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.euler_integrate_tuple" class="md-nav__link">
    <span class="md-ellipsis">
      
        euler_integrate_tuple
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.gl_integrate_tuple" class="md-nav__link">
    <span class="md-ellipsis">
      
        gl_integrate_tuple
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.trap_integrate_tuple" class="md-nav__link">
    <span class="md-ellipsis">
      
        trap_integrate_tuple
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.l1_integrate_tuple" class="md-nav__link">
    <span class="md-ellipsis">
      
        l1_integrate_tuple
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.pred_integrate_tuple" class="md-nav__link">
    <span class="md-ellipsis">
      
        pred_integrate_tuple
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.fdeint_adjoint" class="md-nav__link">
    <span class="md-ellipsis">
      
        fdeint_adjoint
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.forward_euler_wo_history" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward_euler_wo_history
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.backward_euler_wo_history" class="md-nav__link">
    <span class="md-ellipsis">
      
        backward_euler_wo_history
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.forward_euler_w_history" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward_euler_w_history
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.backward_euler_w_history" class="md-nav__link">
    <span class="md-ellipsis">
      
        backward_euler_w_history
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.forward_gl" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward_gl
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.backward_gl" class="md-nav__link">
    <span class="md-ellipsis">
      
        backward_gl
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.forward_trap" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward_trap
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.backward_trap" class="md-nav__link">
    <span class="md-ellipsis">
      
        backward_trap
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.forward_l1" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward_l1
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.backward_l1" class="md-nav__link">
    <span class="md-ellipsis">
      
        backward_l1
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.forward_pred" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward_pred
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.backward_pred" class="md-nav__link">
    <span class="md-ellipsis">
      
        backward_pred
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.find_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        find_parameters
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.get_memory_bounds" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_memory_bounds
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.step_dynamics" class="md-nav__link">
    <span class="md-ellipsis">
      
        step_dynamics
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../surrogate/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    spikeDE.surrogate
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../layer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    spikeDE.layer
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../blog/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    Blog
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#key-features" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Features
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.PerLayerAlphaInfo" class="md-nav__link">
    <span class="md-ellipsis">
      
        PerLayerAlphaInfo
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.SNNSolverConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        SNNSolverConfig
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SNNSolverConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#spikeDE.solver.SNNSolverConfig.from_inputs" class="md-nav__link">
    <span class="md-ellipsis">
      
        from_inputs
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.SNNFractionalMethod" class="md-nav__link">
    <span class="md-ellipsis">
      
        SNNFractionalMethod
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SNNFractionalMethod">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#spikeDE.solver.SNNFractionalMethod.stores_f_history" class="md-nav__link">
    <span class="md-ellipsis">
      
        stores_f_history
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spikeDE.solver.SNNFractionalMethod.compute_convolution" class="md-nav__link">
    <span class="md-ellipsis">
      
        compute_convolution
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spikeDE.solver.SNNFractionalMethod.compute_update_for_layer" class="md-nav__link">
    <span class="md-ellipsis">
      
        compute_update_for_layer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spikeDE.solver.SNNFractionalMethod.compute_weights_for_layer" class="md-nav__link">
    <span class="md-ellipsis">
      
        compute_weights_for_layer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spikeDE.solver.SNNFractionalMethod.initialize" class="md-nav__link">
    <span class="md-ellipsis">
      
        initialize
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.GrunwaldLetnikovSNN" class="md-nav__link">
    <span class="md-ellipsis">
      
        GrunwaldLetnikovSNN
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.ProductTrapezoidalSNN" class="md-nav__link">
    <span class="md-ellipsis">
      
        ProductTrapezoidalSNN
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.L1MethodSNN" class="md-nav__link">
    <span class="md-ellipsis">
      
        L1MethodSNN
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.AdamsBashforthSNN" class="md-nav__link">
    <span class="md-ellipsis">
      
        AdamsBashforthSNN
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.GrunwaldLetnikovMultitermSNN" class="md-nav__link">
    <span class="md-ellipsis">
      
        GrunwaldLetnikovMultitermSNN
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.FDEAdjointMethod" class="md-nav__link">
    <span class="md-ellipsis">
      
        FDEAdjointMethod
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FDEAdjointMethod">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#spikeDE.solver.FDEAdjointMethod.backward" class="md-nav__link">
    <span class="md-ellipsis">
      
        backward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spikeDE.solver.FDEAdjointMethod.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.snn_solve" class="md-nav__link">
    <span class="md-ellipsis">
      
        snn_solve
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.euler_integrate_tuple" class="md-nav__link">
    <span class="md-ellipsis">
      
        euler_integrate_tuple
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.gl_integrate_tuple" class="md-nav__link">
    <span class="md-ellipsis">
      
        gl_integrate_tuple
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.trap_integrate_tuple" class="md-nav__link">
    <span class="md-ellipsis">
      
        trap_integrate_tuple
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.l1_integrate_tuple" class="md-nav__link">
    <span class="md-ellipsis">
      
        l1_integrate_tuple
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.pred_integrate_tuple" class="md-nav__link">
    <span class="md-ellipsis">
      
        pred_integrate_tuple
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.fdeint_adjoint" class="md-nav__link">
    <span class="md-ellipsis">
      
        fdeint_adjoint
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.forward_euler_wo_history" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward_euler_wo_history
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.backward_euler_wo_history" class="md-nav__link">
    <span class="md-ellipsis">
      
        backward_euler_wo_history
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.forward_euler_w_history" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward_euler_w_history
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.backward_euler_w_history" class="md-nav__link">
    <span class="md-ellipsis">
      
        backward_euler_w_history
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.forward_gl" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward_gl
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.backward_gl" class="md-nav__link">
    <span class="md-ellipsis">
      
        backward_gl
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.forward_trap" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward_trap
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.backward_trap" class="md-nav__link">
    <span class="md-ellipsis">
      
        backward_trap
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.forward_l1" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward_l1
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.backward_l1" class="md-nav__link">
    <span class="md-ellipsis">
      
        backward_l1
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.forward_pred" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward_pred
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.backward_pred" class="md-nav__link">
    <span class="md-ellipsis">
      
        backward_pred
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.find_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        find_parameters
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.get_memory_bounds" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_memory_bounds
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spikeDE.solver.step_dynamics" class="md-nav__link">
    <span class="md-ellipsis">
      
        step_dynamics
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
                




              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="spikedesolver">SpikeDE.solver</h1>
<p>This module delivers a comprehensive, differentiable numerical engine designed to simulate Spiking Neural Networks (SNNs) governed by Fractional Differential Equations (FDEs). Bridging the gap between fractional calculus and deep learning, this module supports both <strong>Riemann-Liouville</strong> and <strong>Caputo</strong> formulations through a diverse array of high-order discretization schemes, including <strong>Grünwald-Letnikov (GL)</strong>, <strong>Product Trapezoidal</strong>, <strong>L1</strong>, and <strong>Adams-Bashforth</strong> methods. It enables precise modeling of complex temporal dynamics while maintaining full compatibility with gradient-based optimization.</p>
<p>Whether used for forward inference via <code>snn_solve</code> or for training sophisticated fractional SNNs, the module provides a mathematically rigorous foundation for next-generation neural dynamics. Its architecture is built to handle advanced requirements such as per-layer fractional orders, multi-term distributed-order equations, and efficient memory management, ensuring scalability for long-sequence modeling.</p>
<h2 id="key-features">Key Features</h2>
<ul>
<li><strong>Diverse Discretization Schemes</strong>: Implements multiple high-precision numerical methods (Grünwald-Letnikov, Product Trapezoidal, L1, Adams-Bashforth) to solve FDEs under both Riemann-Liouville and Caputo definitions.</li>
<li><strong>Advanced Fractional Configurations</strong>: Natively supports <strong>per-layer fractional orders</strong>, allowing different layers to exhibit distinct memory properties, and handles <strong>multi-term distributed-order equations</strong> for complex dynamical systems.</li>
<li><strong>Flexible Solver Interface</strong>: Provides a unified API (<code>snn_solve</code>) alongside low-level integration primitives (<code>gl_integrate_tuple</code>, <code>l1_integrate_tuple</code>, etc.) for custom solver development and fine-grained control over state evolution.</li>
</ul>
<hr />


<div class="doc doc-object doc-module">




    <div class="doc doc-contents first">

          









<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h2 id="spikeDE.solver.PerLayerAlphaInfo" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">PerLayerAlphaInfo</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">PerLayerAlphaInfo</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">is_multi_term</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">coefficient</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">h_alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">h_alpha_gamma</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">h_alpha_over_alpha_gamma</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">



        <p>Metadata container for the fractional order (<span class="arithmatex">\(\alpha\)</span>) configuration of a single layer.</p>
<p>Stores the fractional order(s) and precomputed constants required for numerical integration.
To ensure gradient flow during backpropagation when <span class="arithmatex">\(\alpha\)</span> is learnable, all values are
stored as <code>torch.Tensor</code> objects rather than Python floats.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><span title="spikeDE.solver.PerLayerAlphaInfo.alpha">alpha</span></code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>A tensor containing the fractional order(s).
   Shape <code>(1,)</code> for single-term, shape <code>(M,)</code> for multi-term with <span class="arithmatex">\(M\)</span> terms.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="spikeDE.solver.PerLayerAlphaInfo.is_multi_term">is_multi_term</span></code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>)
          –
          <div class="doc-md-description">
            <p>Boolean flag indicating if the layer has multiple fractional terms (<span class="arithmatex">\(M &gt; 1\)</span>).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="spikeDE.solver.PerLayerAlphaInfo.coefficient">coefficient</span></code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a> | None</code>)
          –
          <div class="doc-md-description">
            <p>Optional tensor of coefficients <span class="arithmatex">\([c_1, ..., c_M]\)</span> for multi-term equations.
         Defaults to ones if not provided.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="spikeDE.solver.PerLayerAlphaInfo.h_alpha">h_alpha</span></code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a> | None</code>)
          –
          <div class="doc-md-description">
            <p>Precomputed <span class="arithmatex">\(h^\alpha\)</span> (Single-term only).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="spikeDE.solver.PerLayerAlphaInfo.h_alpha_gamma">h_alpha_gamma</span></code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a> | None</code>)
          –
          <div class="doc-md-description">
            <p>Precomputed <span class="arithmatex">\(h^\alpha \cdot \Gamma(2-\alpha)\)</span> (Single-term only).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="spikeDE.solver.PerLayerAlphaInfo.h_alpha_over_alpha_gamma">h_alpha_over_alpha_gamma</span></code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a> | None</code>)
          –
          <div class="doc-md-description">
            <p>Precomputed <span class="arithmatex">\(h^\alpha / (\alpha \cdot \Gamma(\alpha))\)</span> (Single-term only).</p>
          </div>
        </li>
    </ul>

          


  <div class="doc doc-backlinks">
        <b class="doc doc-backlink-type">Used by:</b>
        <ul class="doc doc-backlink-list">
            <li class="doc doc-backlink">
                  <span class="doc doc-backlink-crumb">
      <span>API Reference</span>
  </span>

                  <span class="doc doc-backlink-crumb">
      <a href="#spikedesolver">SpikeDE.solver</a>
  </span>

                  <span class="doc doc-backlink-crumb last">
      <a href="#spikeDE.solver.SNNSolverConfig">SNNSolverConfig</a>
  </span>

            </li>
        </ul>
  </div>











<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="spikeDE.solver.SNNSolverConfig" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">SNNSolverConfig</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">SNNSolverConfig</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">N</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">h</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">device</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.device" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device">device</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">dtype</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.dtype" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype">dtype</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">n_components</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">n_integrate</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">per_layer_info</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="            PerLayerAlphaInfo


  
      dataclass
   (spikeDE.solver.PerLayerAlphaInfo)" href="#spikeDE.solver.PerLayerAlphaInfo">PerLayerAlphaInfo</a></span><span class="p">]</span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">(),</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">



        <p>Central configuration object for SNN fractional solvers.</p>
<p>Aggregates simulation parameters, device information, and per-layer fractional metadata
to streamline the solver execution loop.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><span title="spikeDE.solver.SNNSolverConfig.N">N</span></code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>Number of time points in the grid.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="spikeDE.solver.SNNSolverConfig.h">h</span></code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Step size tensor (scalar), assumed uniform <span class="arithmatex">\(h = t_{k+1} - t_k\)</span>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="spikeDE.solver.SNNSolverConfig.device">device</span></code></b>
              (<code><a class="autorefs autorefs-external" title="torch.device" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device">device</a></code>)
          –
          <div class="doc-md-description">
            <p>Torch device for computation.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="spikeDE.solver.SNNSolverConfig.dtype">dtype</span></code></b>
              (<code><a class="autorefs autorefs-external" title="torch.dtype" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype">dtype</a></code>)
          –
          <div class="doc-md-description">
            <p>Torch data type for computation.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="spikeDE.solver.SNNSolverConfig.n_components">n_components</span></code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>Total number of state components (neurons + boundaries).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="spikeDE.solver.SNNSolverConfig.n_integrate">n_integrate</span></code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>Number of components to integrate (excludes boundary outputs).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><span title="spikeDE.solver.SNNSolverConfig.per_layer_info">per_layer_info</span></code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-internal" title="            PerLayerAlphaInfo


  
      dataclass
   (spikeDE.solver.PerLayerAlphaInfo)" href="#spikeDE.solver.PerLayerAlphaInfo">PerLayerAlphaInfo</a>]</code>)
          –
          <div class="doc-md-description">
            <p>List of <code>PerLayerAlphaInfo</code> objects, one per integrated layer.</p>
          </div>
        </li>
    </ul>

          


  <div class="doc doc-backlinks">
        <b class="doc doc-backlink-type">Returned by:</b>
        <ul class="doc doc-backlink-list">
            <li class="doc doc-backlink">
                  <span class="doc doc-backlink-crumb">
      <span>API Reference</span>
  </span>

                  <span class="doc doc-backlink-crumb">
      <a href="#spikedesolver">SpikeDE.solver</a>
  </span>

                  <span class="doc doc-backlink-crumb">
      <a href="#spikeDE.solver.SNNSolverConfig">SNNSolverConfig</a>
  </span>

                  <span class="doc doc-backlink-crumb last">
      <a href="#spikeDE.solver.SNNSolverConfig.from_inputs">from_inputs</a>
  </span>

            </li>
        </ul>
        <b class="doc doc-backlink-type">Used by:</b>
        <ul class="doc doc-backlink-list">
            <li class="doc doc-backlink">
                  <span class="doc doc-backlink-crumb">
      <span>API Reference</span>
  </span>

                  <span class="doc doc-backlink-crumb">
      <a href="#spikedesolver">SpikeDE.solver</a>
  </span>

                  <span class="doc doc-backlink-crumb">
      <a href="#spikeDE.solver.SNNFractionalMethod">SNNFractionalMethod</a>
  </span>

                  <span class="doc doc-backlink-crumb last">
      <a href="#spikeDE.solver.SNNFractionalMethod.compute_convolution">compute_convolution</a>
  </span>

            </li>
            <li class="doc doc-backlink">
                  <span class="doc doc-backlink-crumb">
      <span>API Reference</span>
  </span>

                  <span class="doc doc-backlink-crumb">
      <a href="#spikedesolver">SpikeDE.solver</a>
  </span>

                  <span class="doc doc-backlink-crumb">
      <a href="#spikeDE.solver.SNNFractionalMethod">SNNFractionalMethod</a>
  </span>

                  <span class="doc doc-backlink-crumb last">
      <a href="#spikeDE.solver.SNNFractionalMethod.compute_update_for_layer">compute_update_for_layer</a>
  </span>

            </li>
            <li class="doc doc-backlink">
                  <span class="doc doc-backlink-crumb">
      <span>API Reference</span>
  </span>

                  <span class="doc doc-backlink-crumb">
      <a href="#spikedesolver">SpikeDE.solver</a>
  </span>

                  <span class="doc doc-backlink-crumb">
      <a href="#spikeDE.solver.SNNFractionalMethod">SNNFractionalMethod</a>
  </span>

                  <span class="doc doc-backlink-crumb last">
      <a href="#spikeDE.solver.SNNFractionalMethod.compute_weights_for_layer">compute_weights_for_layer</a>
  </span>

            </li>
            <li class="doc doc-backlink">
                  <span class="doc doc-backlink-crumb">
      <span>API Reference</span>
  </span>

                  <span class="doc doc-backlink-crumb">
      <a href="#spikedesolver">SpikeDE.solver</a>
  </span>

                  <span class="doc doc-backlink-crumb">
      <a href="#spikeDE.solver.SNNFractionalMethod">SNNFractionalMethod</a>
  </span>

                  <span class="doc doc-backlink-crumb last">
      <a href="#spikeDE.solver.SNNFractionalMethod.initialize">initialize</a>
  </span>

            </li>
        </ul>
  </div>











<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="spikeDE.solver.SNNSolverConfig.from_inputs" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">from_inputs</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">from_inputs</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">per_layer_alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">per_layer_coefficient</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="            SNNSolverConfig


  
      dataclass
   (spikeDE.solver.SNNSolverConfig)" href="#spikeDE.solver.SNNSolverConfig">SNNSolverConfig</a></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Constructs a solver configuration from user inputs.</p>
<p>Processes raw alpha inputs (scalars, lists, or tensors) into standardized
<code>PerLayerAlphaInfo</code> objects. Precomputes constants involving the Gamma function
for single-term solvers to optimize the main integration loop.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>y0_tuple</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]</code>)
          –
          <div class="doc-md-description">
            <p>Tuple of initial state tensors. Used to infer device and dtype.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>per_layer_alpha</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a>]</code>)
          –
          <div class="doc-md-description">
            <p>List of alpha values. Each element can be:</p>
<ul>
<li><code>float</code>: Single-term scalar.</li>
<li><code>torch.Tensor</code>: 1-element (single-term) or M-element (multi-term).</li>
<li><code>list</code>: Converted to tensor.</li>
</ul>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Time grid tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>per_layer_coefficient</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a> | None] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Optional list of coefficient tensors for multi-term layers.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-internal" title="            SNNSolverConfig


  
      dataclass
   (spikeDE.solver.SNNSolverConfig)" href="#spikeDE.solver.SNNSolverConfig">SNNSolverConfig</a></code>
          –
          <div class="doc-md-description">
            <p>A configured <code>SNNSolverConfig</code> instance.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Raises:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/exceptions.html#AssertionError">AssertionError</a></code>
            –
          <div class="doc-md-description">
            <p>If <code>t_grid</code> has fewer than 2 points or coefficient dimensions mismatch alpha.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span>
<span class="normal"><a href="#__codelineno-0-264">264</a></span>
<span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-162"><a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="nd">@classmethod</span>
</span><span id="__span-0-163"><a id="__codelineno-0-163" name="__codelineno-0-163"></a><span class="k">def</span><span class="w"> </span><span class="nf">from_inputs</span><span class="p">(</span>
</span><span id="__span-0-164"><a id="__codelineno-0-164" name="__codelineno-0-164"></a>    <span class="bp">cls</span><span class="p">,</span>
</span><span id="__span-0-165"><a id="__codelineno-0-165" name="__codelineno-0-165"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-166"><a id="__codelineno-0-166" name="__codelineno-0-166"></a>    <span class="n">per_layer_alpha</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
</span><span id="__span-0-167"><a id="__codelineno-0-167" name="__codelineno-0-167"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-168"><a id="__codelineno-0-168" name="__codelineno-0-168"></a>    <span class="n">per_layer_coefficient</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-169"><a id="__codelineno-0-169" name="__codelineno-0-169"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;SNNSolverConfig&quot;</span><span class="p">:</span>
</span><span id="__span-0-170"><a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-171"><a id="__codelineno-0-171" name="__codelineno-0-171"></a><span class="sd">    Constructs a solver configuration from user inputs.</span>
</span><span id="__span-0-172"><a id="__codelineno-0-172" name="__codelineno-0-172"></a>
</span><span id="__span-0-173"><a id="__codelineno-0-173" name="__codelineno-0-173"></a><span class="sd">    Processes raw alpha inputs (scalars, lists, or tensors) into standardized</span>
</span><span id="__span-0-174"><a id="__codelineno-0-174" name="__codelineno-0-174"></a><span class="sd">    `PerLayerAlphaInfo` objects. Precomputes constants involving the Gamma function</span>
</span><span id="__span-0-175"><a id="__codelineno-0-175" name="__codelineno-0-175"></a><span class="sd">    for single-term solvers to optimize the main integration loop.</span>
</span><span id="__span-0-176"><a id="__codelineno-0-176" name="__codelineno-0-176"></a>
</span><span id="__span-0-177"><a id="__codelineno-0-177" name="__codelineno-0-177"></a><span class="sd">    Args:</span>
</span><span id="__span-0-178"><a id="__codelineno-0-178" name="__codelineno-0-178"></a><span class="sd">        y0_tuple: Tuple of initial state tensors. Used to infer device and dtype.</span>
</span><span id="__span-0-179"><a id="__codelineno-0-179" name="__codelineno-0-179"></a><span class="sd">        per_layer_alpha: List of alpha values. Each element can be:</span>
</span><span id="__span-0-180"><a id="__codelineno-0-180" name="__codelineno-0-180"></a>
</span><span id="__span-0-181"><a id="__codelineno-0-181" name="__codelineno-0-181"></a><span class="sd">            - `float`: Single-term scalar.</span>
</span><span id="__span-0-182"><a id="__codelineno-0-182" name="__codelineno-0-182"></a><span class="sd">            - `torch.Tensor`: 1-element (single-term) or M-element (multi-term).</span>
</span><span id="__span-0-183"><a id="__codelineno-0-183" name="__codelineno-0-183"></a><span class="sd">            - `list`: Converted to tensor.</span>
</span><span id="__span-0-184"><a id="__codelineno-0-184" name="__codelineno-0-184"></a><span class="sd">        t_grid: Time grid tensor.</span>
</span><span id="__span-0-185"><a id="__codelineno-0-185" name="__codelineno-0-185"></a><span class="sd">        per_layer_coefficient: Optional list of coefficient tensors for multi-term layers.</span>
</span><span id="__span-0-186"><a id="__codelineno-0-186" name="__codelineno-0-186"></a>
</span><span id="__span-0-187"><a id="__codelineno-0-187" name="__codelineno-0-187"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-188"><a id="__codelineno-0-188" name="__codelineno-0-188"></a><span class="sd">        A configured `SNNSolverConfig` instance.</span>
</span><span id="__span-0-189"><a id="__codelineno-0-189" name="__codelineno-0-189"></a>
</span><span id="__span-0-190"><a id="__codelineno-0-190" name="__codelineno-0-190"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-191"><a id="__codelineno-0-191" name="__codelineno-0-191"></a><span class="sd">        AssertionError: If `t_grid` has fewer than 2 points or coefficient dimensions mismatch alpha.</span>
</span><span id="__span-0-192"><a id="__codelineno-0-192" name="__codelineno-0-192"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-193"><a id="__codelineno-0-193" name="__codelineno-0-193"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">y0_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
</span><span id="__span-0-194"><a id="__codelineno-0-194" name="__codelineno-0-194"></a>    <span class="n">dtype</span> <span class="o">=</span> <span class="n">y0_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-195"><a id="__codelineno-0-195" name="__codelineno-0-195"></a>
</span><span id="__span-0-196"><a id="__codelineno-0-196" name="__codelineno-0-196"></a>    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_grid</span><span class="p">)</span>
</span><span id="__span-0-197"><a id="__codelineno-0-197" name="__codelineno-0-197"></a>    <span class="k">assert</span> <span class="n">N</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;t_grid must have at least 2 points&quot;</span>
</span><span id="__span-0-198"><a id="__codelineno-0-198" name="__codelineno-0-198"></a>
</span><span id="__span-0-199"><a id="__codelineno-0-199" name="__codelineno-0-199"></a>    <span class="n">t_grid</span> <span class="o">=</span> <span class="n">t_grid</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-200"><a id="__codelineno-0-200" name="__codelineno-0-200"></a>    <span class="n">h</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
</span><span id="__span-0-201"><a id="__codelineno-0-201" name="__codelineno-0-201"></a>
</span><span id="__span-0-202"><a id="__codelineno-0-202" name="__codelineno-0-202"></a>    <span class="n">n_components</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">)</span>
</span><span id="__span-0-203"><a id="__codelineno-0-203" name="__codelineno-0-203"></a>    <span class="c1"># length of (dv1/dt, dv2/dt, ..., dvN/dt, boundary_1, boundary_2, ...)</span>
</span><span id="__span-0-204"><a id="__codelineno-0-204" name="__codelineno-0-204"></a>
</span><span id="__span-0-205"><a id="__codelineno-0-205" name="__codelineno-0-205"></a>    <span class="n">n_integrate</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">per_layer_alpha</span><span class="p">)</span>
</span><span id="__span-0-206"><a id="__codelineno-0-206" name="__codelineno-0-206"></a>    <span class="c1"># n_integrate is the number of neurons,</span>
</span><span id="__span-0-207"><a id="__codelineno-0-207" name="__codelineno-0-207"></a>    <span class="c1"># i.e., length of (dv1/dt, dv2/dt, ..., dvN/dt)</span>
</span><span id="__span-0-208"><a id="__codelineno-0-208" name="__codelineno-0-208"></a>
</span><span id="__span-0-209"><a id="__codelineno-0-209" name="__codelineno-0-209"></a>    <span class="c1"># Build per-layer info</span>
</span><span id="__span-0-210"><a id="__codelineno-0-210" name="__codelineno-0-210"></a>    <span class="n">per_layer_info</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-211"><a id="__codelineno-0-211" name="__codelineno-0-211"></a>    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">per_layer_alpha</span><span class="p">):</span>
</span><span id="__span-0-212"><a id="__codelineno-0-212" name="__codelineno-0-212"></a>        <span class="c1"># Determine if this layer is multi-term based on number of elements</span>
</span><span id="__span-0-213"><a id="__codelineno-0-213" name="__codelineno-0-213"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
</span><span id="__span-0-214"><a id="__codelineno-0-214" name="__codelineno-0-214"></a>            <span class="n">is_multi_term</span> <span class="o">=</span> <span class="n">alpha</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span>
</span><span id="__span-0-215"><a id="__codelineno-0-215" name="__codelineno-0-215"></a>            <span class="n">alpha_tensor</span> <span class="o">=</span> <span class="n">alpha</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-216"><a id="__codelineno-0-216" name="__codelineno-0-216"></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
</span><span id="__span-0-217"><a id="__codelineno-0-217" name="__codelineno-0-217"></a>            <span class="n">is_multi_term</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
</span><span id="__span-0-218"><a id="__codelineno-0-218" name="__codelineno-0-218"></a>            <span class="n">alpha_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-219"><a id="__codelineno-0-219" name="__codelineno-0-219"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-220"><a id="__codelineno-0-220" name="__codelineno-0-220"></a>            <span class="c1"># Scalar float</span>
</span><span id="__span-0-221"><a id="__codelineno-0-221" name="__codelineno-0-221"></a>            <span class="n">is_multi_term</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="__span-0-222"><a id="__codelineno-0-222" name="__codelineno-0-222"></a>            <span class="n">alpha_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">alpha</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-223"><a id="__codelineno-0-223" name="__codelineno-0-223"></a>
</span><span id="__span-0-224"><a id="__codelineno-0-224" name="__codelineno-0-224"></a>        <span class="c1"># Get coefficient for this layer</span>
</span><span id="__span-0-225"><a id="__codelineno-0-225" name="__codelineno-0-225"></a>        <span class="n">coeff</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-226"><a id="__codelineno-0-226" name="__codelineno-0-226"></a>        <span class="k">if</span> <span class="n">per_layer_coefficient</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">per_layer_coefficient</span><span class="p">):</span>
</span><span id="__span-0-227"><a id="__codelineno-0-227" name="__codelineno-0-227"></a>            <span class="n">coeff</span> <span class="o">=</span> <span class="n">per_layer_coefficient</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="__span-0-228"><a id="__codelineno-0-228" name="__codelineno-0-228"></a>            <span class="k">if</span> <span class="n">coeff</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">coeff</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
</span><span id="__span-0-229"><a id="__codelineno-0-229" name="__codelineno-0-229"></a>                <span class="n">coeff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">coeff</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-230"><a id="__codelineno-0-230" name="__codelineno-0-230"></a>            <span class="k">elif</span> <span class="n">coeff</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-231"><a id="__codelineno-0-231" name="__codelineno-0-231"></a>                <span class="n">coeff</span> <span class="o">=</span> <span class="n">coeff</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-232"><a id="__codelineno-0-232" name="__codelineno-0-232"></a>
</span><span id="__span-0-233"><a id="__codelineno-0-233" name="__codelineno-0-233"></a>                <span class="c1"># Now compare dimensions when coeff exists</span>
</span><span id="__span-0-234"><a id="__codelineno-0-234" name="__codelineno-0-234"></a>            <span class="k">assert</span> <span class="p">(</span>
</span><span id="__span-0-235"><a id="__codelineno-0-235" name="__codelineno-0-235"></a>                <span class="n">coeff</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="n">alpha_tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
</span><span id="__span-0-236"><a id="__codelineno-0-236" name="__codelineno-0-236"></a>            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Coefficient tensor size mismatch: </span><span class="si">{</span><span class="n">coeff</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="si">}</span><span class="s2"> vs </span><span class="si">{</span><span class="n">alpha_tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="__span-0-237"><a id="__codelineno-0-237" name="__codelineno-0-237"></a>
</span><span id="__span-0-238"><a id="__codelineno-0-238" name="__codelineno-0-238"></a>        <span class="c1"># Default coefficient to ones if not provided (for both single and multi-term)</span>
</span><span id="__span-0-239"><a id="__codelineno-0-239" name="__codelineno-0-239"></a>        <span class="k">if</span> <span class="n">coeff</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-240"><a id="__codelineno-0-240" name="__codelineno-0-240"></a>            <span class="n">coeff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">alpha_tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-241"><a id="__codelineno-0-241" name="__codelineno-0-241"></a>
</span><span id="__span-0-242"><a id="__codelineno-0-242" name="__codelineno-0-242"></a>        <span class="c1"># For single-term, precompute constants (used by non-multiterm solvers)</span>
</span><span id="__span-0-243"><a id="__codelineno-0-243" name="__codelineno-0-243"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_multi_term</span><span class="p">:</span>
</span><span id="__span-0-244"><a id="__codelineno-0-244" name="__codelineno-0-244"></a>            <span class="n">alpha_val</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-245"><a id="__codelineno-0-245" name="__codelineno-0-245"></a>                <span class="n">alpha_tensor</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
</span><span id="__span-0-246"><a id="__codelineno-0-246" name="__codelineno-0-246"></a>            <span class="p">)</span>  <span class="c1"># Keep as 0-dim tensor for gradient flow</span>
</span><span id="__span-0-247"><a id="__codelineno-0-247" name="__codelineno-0-247"></a>            <span class="n">h_alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">alpha_val</span><span class="p">)</span>
</span><span id="__span-0-248"><a id="__codelineno-0-248" name="__codelineno-0-248"></a>            <span class="n">gamma_2_minus_alpha</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span>
</span><span id="__span-0-249"><a id="__codelineno-0-249" name="__codelineno-0-249"></a>                <span class="mi">2</span> <span class="o">-</span> <span class="n">alpha_val</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span><span id="__span-0-250"><a id="__codelineno-0-250" name="__codelineno-0-250"></a>            <span class="p">)</span>  <span class="c1"># gamma needs float</span>
</span><span id="__span-0-251"><a id="__codelineno-0-251" name="__codelineno-0-251"></a>            <span class="n">gamma_alpha</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">alpha_val</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="__span-0-252"><a id="__codelineno-0-252" name="__codelineno-0-252"></a>
</span><span id="__span-0-253"><a id="__codelineno-0-253" name="__codelineno-0-253"></a>            <span class="n">info</span> <span class="o">=</span> <span class="n">PerLayerAlphaInfo</span><span class="p">(</span>
</span><span id="__span-0-254"><a id="__codelineno-0-254" name="__codelineno-0-254"></a>                <span class="n">alpha</span><span class="o">=</span><span class="n">alpha_tensor</span><span class="p">,</span>  <span class="c1"># Keep as tensor for gradient flow</span>
</span><span id="__span-0-255"><a id="__codelineno-0-255" name="__codelineno-0-255"></a>                <span class="n">is_multi_term</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-256"><a id="__codelineno-0-256" name="__codelineno-0-256"></a>                <span class="n">coefficient</span><span class="o">=</span><span class="n">coeff</span><span class="p">,</span>
</span><span id="__span-0-257"><a id="__codelineno-0-257" name="__codelineno-0-257"></a>                <span class="n">h_alpha</span><span class="o">=</span><span class="n">h_alpha</span><span class="p">,</span>
</span><span id="__span-0-258"><a id="__codelineno-0-258" name="__codelineno-0-258"></a>                <span class="n">h_alpha_gamma</span><span class="o">=</span><span class="n">h_alpha</span> <span class="o">*</span> <span class="n">gamma_2_minus_alpha</span><span class="p">,</span>
</span><span id="__span-0-259"><a id="__codelineno-0-259" name="__codelineno-0-259"></a>                <span class="n">h_alpha_over_alpha_gamma</span><span class="o">=</span><span class="n">h_alpha</span> <span class="o">/</span> <span class="p">(</span><span class="n">alpha_val</span> <span class="o">*</span> <span class="n">gamma_alpha</span><span class="p">),</span>
</span><span id="__span-0-260"><a id="__codelineno-0-260" name="__codelineno-0-260"></a>            <span class="p">)</span>
</span><span id="__span-0-261"><a id="__codelineno-0-261" name="__codelineno-0-261"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-262"><a id="__codelineno-0-262" name="__codelineno-0-262"></a>            <span class="n">info</span> <span class="o">=</span> <span class="n">PerLayerAlphaInfo</span><span class="p">(</span>
</span><span id="__span-0-263"><a id="__codelineno-0-263" name="__codelineno-0-263"></a>                <span class="n">alpha</span><span class="o">=</span><span class="n">alpha_tensor</span><span class="p">,</span>
</span><span id="__span-0-264"><a id="__codelineno-0-264" name="__codelineno-0-264"></a>                <span class="n">is_multi_term</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-265"><a id="__codelineno-0-265" name="__codelineno-0-265"></a>                <span class="n">coefficient</span><span class="o">=</span><span class="n">coeff</span><span class="p">,</span>
</span><span id="__span-0-266"><a id="__codelineno-0-266" name="__codelineno-0-266"></a>            <span class="p">)</span>
</span><span id="__span-0-267"><a id="__codelineno-0-267" name="__codelineno-0-267"></a>
</span><span id="__span-0-268"><a id="__codelineno-0-268" name="__codelineno-0-268"></a>        <span class="n">per_layer_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">info</span><span class="p">)</span>
</span><span id="__span-0-269"><a id="__codelineno-0-269" name="__codelineno-0-269"></a>
</span><span id="__span-0-270"><a id="__codelineno-0-270" name="__codelineno-0-270"></a>    <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
</span><span id="__span-0-271"><a id="__codelineno-0-271" name="__codelineno-0-271"></a>        <span class="n">N</span><span class="o">=</span><span class="n">N</span><span class="p">,</span>
</span><span id="__span-0-272"><a id="__codelineno-0-272" name="__codelineno-0-272"></a>        <span class="n">h</span><span class="o">=</span><span class="n">h</span><span class="p">,</span>
</span><span id="__span-0-273"><a id="__codelineno-0-273" name="__codelineno-0-273"></a>        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
</span><span id="__span-0-274"><a id="__codelineno-0-274" name="__codelineno-0-274"></a>        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
</span><span id="__span-0-275"><a id="__codelineno-0-275" name="__codelineno-0-275"></a>        <span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span>
</span><span id="__span-0-276"><a id="__codelineno-0-276" name="__codelineno-0-276"></a>        <span class="n">n_integrate</span><span class="o">=</span><span class="n">n_integrate</span><span class="p">,</span>
</span><span id="__span-0-277"><a id="__codelineno-0-277" name="__codelineno-0-277"></a>        <span class="n">per_layer_info</span><span class="o">=</span><span class="n">per_layer_info</span><span class="p">,</span>
</span><span id="__span-0-278"><a id="__codelineno-0-278" name="__codelineno-0-278"></a>    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="spikeDE.solver.SNNFractionalMethod" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">SNNFractionalMethod</span>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-external" title="abc.ABC" href="https://docs.python.org/3/library/abc.html#abc.ABC">ABC</a></code></p>



        <p>Abstract Base Class (ABC) for SNN fractional differential equation solvers.</p>
<p>Defines the interface for various numerical methods (GL, L1, Trapezoidal, etc.).
Implementations must define how weights are computed, how convolutions are performed,
and how the state update is calculated.</p>
<p>Subclasses distinguish themselves by:</p>
<ol>
<li>The formulation used (Riemann-Liouville vs. Caputo).</li>
<li>The type of history stored (<span class="arithmatex">\(y\)</span> values vs. <span class="arithmatex">\(f(t,y)\)</span> values).</li>
<li>Support for single-term vs. multi-term equations.</li>
</ol>

          


  <div class="doc doc-backlinks">
        <b class="doc doc-backlink-type">Subclassed by:</b>
        <ul class="doc doc-backlink-list">
            <li class="doc doc-backlink">
                  <span class="doc doc-backlink-crumb">
      <span>API Reference</span>
  </span>

                  <span class="doc doc-backlink-crumb">
      <a href="#spikedesolver">SpikeDE.solver</a>
  </span>

                  <span class="doc doc-backlink-crumb last">
      <a href="#spikeDE.solver.AdamsBashforthSNN">AdamsBashforthSNN</a>
  </span>

            </li>
            <li class="doc doc-backlink">
                  <span class="doc doc-backlink-crumb">
      <span>API Reference</span>
  </span>

                  <span class="doc doc-backlink-crumb">
      <a href="#spikedesolver">SpikeDE.solver</a>
  </span>

                  <span class="doc doc-backlink-crumb last">
      <a href="#spikeDE.solver.GrunwaldLetnikovMultitermSNN">GrunwaldLetnikovMultitermSNN</a>
  </span>

            </li>
            <li class="doc doc-backlink">
                  <span class="doc doc-backlink-crumb">
      <span>API Reference</span>
  </span>

                  <span class="doc doc-backlink-crumb">
      <a href="#spikedesolver">SpikeDE.solver</a>
  </span>

                  <span class="doc doc-backlink-crumb last">
      <a href="#spikeDE.solver.GrunwaldLetnikovSNN">GrunwaldLetnikovSNN</a>
  </span>

            </li>
            <li class="doc doc-backlink">
                  <span class="doc doc-backlink-crumb">
      <span>API Reference</span>
  </span>

                  <span class="doc doc-backlink-crumb">
      <a href="#spikedesolver">SpikeDE.solver</a>
  </span>

                  <span class="doc doc-backlink-crumb last">
      <a href="#spikeDE.solver.L1MethodSNN">L1MethodSNN</a>
  </span>

            </li>
            <li class="doc doc-backlink">
                  <span class="doc doc-backlink-crumb">
      <span>API Reference</span>
  </span>

                  <span class="doc doc-backlink-crumb">
      <a href="#spikedesolver">SpikeDE.solver</a>
  </span>

                  <span class="doc doc-backlink-crumb last">
      <a href="#spikeDE.solver.ProductTrapezoidalSNN">ProductTrapezoidalSNN</a>
  </span>

            </li>
        </ul>
        <b class="doc doc-backlink-type">Used by:</b>
        <ul class="doc doc-backlink-list">
            <li class="doc doc-backlink">
                  <span class="doc doc-backlink-crumb">
      <span>API Reference</span>
  </span>

                  <span class="doc doc-backlink-crumb">
      <a href="#spikedesolver">SpikeDE.solver</a>
  </span>

                  <span class="doc doc-backlink-crumb last">
      <a href="#spikeDE.solver.snn_solve">snn_solve</a>
  </span>

            </li>
        </ul>
  </div>











<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="spikeDE.solver.SNNFractionalMethod.stores_f_history" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">stores_f_history</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">stores_f_history</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Indicates whether the method stores function evaluations <span class="arithmatex">\(f(t, y)\)</span> or state values <span class="arithmatex">\(y\)</span> in history.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>
          –
          <div class="doc-md-description">
            <p><code>True</code> if the method (e.g., Adams-Bashforth) relies on <span class="arithmatex">\(f\)</span>-history, <code>False</code> if the method (e.g., GL, L1) relies on <span class="arithmatex">\(y\)</span>-history.</p>
          </div>
        </li>
    </ul>

          
    </div>

</div>




<div class="doc doc-object doc-function">


<h3 id="spikeDE.solver.SNNFractionalMethod.compute_convolution" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">compute_convolution</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">compute_convolution</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">k</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">start_idx</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">weights</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">history_i</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">],</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">config</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            SNNSolverConfig


  
      dataclass
   (spikeDE.solver.SNNSolverConfig)" href="#spikeDE.solver.SNNSolverConfig">SNNSolverConfig</a></span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">layer_idx</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the weighted sum (convolution) of history values.</p>
<p>Calculates <span class="arithmatex">\(\sum w_j \cdot h_j\)</span>, where <span class="arithmatex">\(h_j\)</span> is either <span class="arithmatex">\(y_j\)</span> or <span class="arithmatex">\(f_j\)</span> depending on <code>stores_f_history</code>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>k</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>Current time step index.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>start_idx</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>Start index of the history window.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>weights</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></code>)
          –
          <div class="doc-md-description">
            <p>Weights computed by <code>compute_weights_for_layer</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>history_i</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]</code>)
          –
          <div class="doc-md-description">
            <p>List of historical tensors for the current component.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>config</code></b>
              (<code><a class="autorefs autorefs-internal" title="            SNNSolverConfig


  
      dataclass
   (spikeDE.solver.SNNSolverConfig)" href="#spikeDE.solver.SNNSolverConfig">SNNSolverConfig</a></code>)
          –
          <div class="doc-md-description">
            <p>Solver configuration.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>layer_idx</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>Index of the layer.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></code>
          –
          <div class="doc-md-description">
            <p>The result of the convolution sum (tensor).</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-384">384</a></span>
<span class="normal"><a href="#__codelineno-0-385">385</a></span>
<span class="normal"><a href="#__codelineno-0-386">386</a></span>
<span class="normal"><a href="#__codelineno-0-387">387</a></span>
<span class="normal"><a href="#__codelineno-0-388">388</a></span>
<span class="normal"><a href="#__codelineno-0-389">389</a></span>
<span class="normal"><a href="#__codelineno-0-390">390</a></span>
<span class="normal"><a href="#__codelineno-0-391">391</a></span>
<span class="normal"><a href="#__codelineno-0-392">392</a></span>
<span class="normal"><a href="#__codelineno-0-393">393</a></span>
<span class="normal"><a href="#__codelineno-0-394">394</a></span>
<span class="normal"><a href="#__codelineno-0-395">395</a></span>
<span class="normal"><a href="#__codelineno-0-396">396</a></span>
<span class="normal"><a href="#__codelineno-0-397">397</a></span>
<span class="normal"><a href="#__codelineno-0-398">398</a></span>
<span class="normal"><a href="#__codelineno-0-399">399</a></span>
<span class="normal"><a href="#__codelineno-0-400">400</a></span>
<span class="normal"><a href="#__codelineno-0-401">401</a></span>
<span class="normal"><a href="#__codelineno-0-402">402</a></span>
<span class="normal"><a href="#__codelineno-0-403">403</a></span>
<span class="normal"><a href="#__codelineno-0-404">404</a></span>
<span class="normal"><a href="#__codelineno-0-405">405</a></span>
<span class="normal"><a href="#__codelineno-0-406">406</a></span>
<span class="normal"><a href="#__codelineno-0-407">407</a></span>
<span class="normal"><a href="#__codelineno-0-408">408</a></span>
<span class="normal"><a href="#__codelineno-0-409">409</a></span>
<span class="normal"><a href="#__codelineno-0-410">410</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-384"><a id="__codelineno-0-384" name="__codelineno-0-384"></a><span class="nd">@abstractmethod</span>
</span><span id="__span-0-385"><a id="__codelineno-0-385" name="__codelineno-0-385"></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_convolution</span><span class="p">(</span>
</span><span id="__span-0-386"><a id="__codelineno-0-386" name="__codelineno-0-386"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-387"><a id="__codelineno-0-387" name="__codelineno-0-387"></a>    <span class="n">k</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-388"><a id="__codelineno-0-388" name="__codelineno-0-388"></a>    <span class="n">start_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-389"><a id="__codelineno-0-389" name="__codelineno-0-389"></a>    <span class="n">weights</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span id="__span-0-390"><a id="__codelineno-0-390" name="__codelineno-0-390"></a>    <span class="n">history_i</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="__span-0-391"><a id="__codelineno-0-391" name="__codelineno-0-391"></a>    <span class="n">config</span><span class="p">:</span> <span class="n">SNNSolverConfig</span><span class="p">,</span>
</span><span id="__span-0-392"><a id="__codelineno-0-392" name="__codelineno-0-392"></a>    <span class="n">layer_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-393"><a id="__codelineno-0-393" name="__codelineno-0-393"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
</span><span id="__span-0-394"><a id="__codelineno-0-394" name="__codelineno-0-394"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-395"><a id="__codelineno-0-395" name="__codelineno-0-395"></a><span class="sd">    Computes the weighted sum (convolution) of history values.</span>
</span><span id="__span-0-396"><a id="__codelineno-0-396" name="__codelineno-0-396"></a>
</span><span id="__span-0-397"><a id="__codelineno-0-397" name="__codelineno-0-397"></a><span class="sd">    Calculates $\sum w_j \cdot h_j$, where $h_j$ is either $y_j$ or $f_j$ depending on `stores_f_history`.</span>
</span><span id="__span-0-398"><a id="__codelineno-0-398" name="__codelineno-0-398"></a>
</span><span id="__span-0-399"><a id="__codelineno-0-399" name="__codelineno-0-399"></a><span class="sd">    Args:</span>
</span><span id="__span-0-400"><a id="__codelineno-0-400" name="__codelineno-0-400"></a><span class="sd">        k: Current time step index.</span>
</span><span id="__span-0-401"><a id="__codelineno-0-401" name="__codelineno-0-401"></a><span class="sd">        start_idx: Start index of the history window.</span>
</span><span id="__span-0-402"><a id="__codelineno-0-402" name="__codelineno-0-402"></a><span class="sd">        weights: Weights computed by `compute_weights_for_layer`.</span>
</span><span id="__span-0-403"><a id="__codelineno-0-403" name="__codelineno-0-403"></a><span class="sd">        history_i: List of historical tensors for the current component.</span>
</span><span id="__span-0-404"><a id="__codelineno-0-404" name="__codelineno-0-404"></a><span class="sd">        config: Solver configuration.</span>
</span><span id="__span-0-405"><a id="__codelineno-0-405" name="__codelineno-0-405"></a><span class="sd">        layer_idx: Index of the layer.</span>
</span><span id="__span-0-406"><a id="__codelineno-0-406" name="__codelineno-0-406"></a>
</span><span id="__span-0-407"><a id="__codelineno-0-407" name="__codelineno-0-407"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-408"><a id="__codelineno-0-408" name="__codelineno-0-408"></a><span class="sd">        The result of the convolution sum (tensor).</span>
</span><span id="__span-0-409"><a id="__codelineno-0-409" name="__codelineno-0-409"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-410"><a id="__codelineno-0-410" name="__codelineno-0-410"></a>    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spikeDE.solver.SNNFractionalMethod.compute_update_for_layer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">compute_update_for_layer</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">compute_update_for_layer</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">f_k_i</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="n">convolution_sum</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            SNNSolverConfig


  
      dataclass
   (spikeDE.solver.SNNSolverConfig)" href="#spikeDE.solver.SNNSolverConfig">SNNSolverConfig</a></span><span class="p">,</span> <span class="n">layer_idx</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the next state <span class="arithmatex">\(y_{k+1}\)</span> for a specific layer.</p>
<p>Combines the current derivative <span class="arithmatex">\(f_k\)</span> and the convolution sum according to the method's formula.
Note: The method name in the original code was slightly misleading; this function computes the update,
while <code>compute_convolution</code> computes the sum. Based on usage in <code>snn_solve</code>, this function
applies the final formula. However, looking at the implementation in subclasses,
<code>compute_convolution</code> actually performs the summation loop, and this function applies the scaling.</p>
<p>Correction based on code analysis:
<code>compute_convolution</code> returns the sum <span class="arithmatex">\(\sum w_j h_j\)</span>.
<code>compute_update_for_layer</code> takes that sum and <span class="arithmatex">\(f_k\)</span> to return <span class="arithmatex">\(y_{k+1}\)</span>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>f_k_i</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>The derivative/value <span class="arithmatex">\(f(t_k, y_k)\)</span> for this layer.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>convolution_sum</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></code>)
          –
          <div class="doc-md-description">
            <p>The result of the history convolution.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>config</code></b>
              (<code><a class="autorefs autorefs-internal" title="            SNNSolverConfig


  
      dataclass
   (spikeDE.solver.SNNSolverConfig)" href="#spikeDE.solver.SNNSolverConfig">SNNSolverConfig</a></code>)
          –
          <div class="doc-md-description">
            <p>Solver configuration.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>layer_idx</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>Index of the layer.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
          –
          <div class="doc-md-description">
            <p>The updated state tensor <span class="arithmatex">\(y_{k+1}\)</span>.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-352">352</a></span>
<span class="normal"><a href="#__codelineno-0-353">353</a></span>
<span class="normal"><a href="#__codelineno-0-354">354</a></span>
<span class="normal"><a href="#__codelineno-0-355">355</a></span>
<span class="normal"><a href="#__codelineno-0-356">356</a></span>
<span class="normal"><a href="#__codelineno-0-357">357</a></span>
<span class="normal"><a href="#__codelineno-0-358">358</a></span>
<span class="normal"><a href="#__codelineno-0-359">359</a></span>
<span class="normal"><a href="#__codelineno-0-360">360</a></span>
<span class="normal"><a href="#__codelineno-0-361">361</a></span>
<span class="normal"><a href="#__codelineno-0-362">362</a></span>
<span class="normal"><a href="#__codelineno-0-363">363</a></span>
<span class="normal"><a href="#__codelineno-0-364">364</a></span>
<span class="normal"><a href="#__codelineno-0-365">365</a></span>
<span class="normal"><a href="#__codelineno-0-366">366</a></span>
<span class="normal"><a href="#__codelineno-0-367">367</a></span>
<span class="normal"><a href="#__codelineno-0-368">368</a></span>
<span class="normal"><a href="#__codelineno-0-369">369</a></span>
<span class="normal"><a href="#__codelineno-0-370">370</a></span>
<span class="normal"><a href="#__codelineno-0-371">371</a></span>
<span class="normal"><a href="#__codelineno-0-372">372</a></span>
<span class="normal"><a href="#__codelineno-0-373">373</a></span>
<span class="normal"><a href="#__codelineno-0-374">374</a></span>
<span class="normal"><a href="#__codelineno-0-375">375</a></span>
<span class="normal"><a href="#__codelineno-0-376">376</a></span>
<span class="normal"><a href="#__codelineno-0-377">377</a></span>
<span class="normal"><a href="#__codelineno-0-378">378</a></span>
<span class="normal"><a href="#__codelineno-0-379">379</a></span>
<span class="normal"><a href="#__codelineno-0-380">380</a></span>
<span class="normal"><a href="#__codelineno-0-381">381</a></span>
<span class="normal"><a href="#__codelineno-0-382">382</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-352"><a id="__codelineno-0-352" name="__codelineno-0-352"></a><span class="nd">@abstractmethod</span>
</span><span id="__span-0-353"><a id="__codelineno-0-353" name="__codelineno-0-353"></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_update_for_layer</span><span class="p">(</span>
</span><span id="__span-0-354"><a id="__codelineno-0-354" name="__codelineno-0-354"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-355"><a id="__codelineno-0-355" name="__codelineno-0-355"></a>    <span class="n">f_k_i</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-356"><a id="__codelineno-0-356" name="__codelineno-0-356"></a>    <span class="n">convolution_sum</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span id="__span-0-357"><a id="__codelineno-0-357" name="__codelineno-0-357"></a>    <span class="n">config</span><span class="p">:</span> <span class="n">SNNSolverConfig</span><span class="p">,</span>
</span><span id="__span-0-358"><a id="__codelineno-0-358" name="__codelineno-0-358"></a>    <span class="n">layer_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-359"><a id="__codelineno-0-359" name="__codelineno-0-359"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-360"><a id="__codelineno-0-360" name="__codelineno-0-360"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-361"><a id="__codelineno-0-361" name="__codelineno-0-361"></a><span class="sd">    Computes the next state $y_{k+1}$ for a specific layer.</span>
</span><span id="__span-0-362"><a id="__codelineno-0-362" name="__codelineno-0-362"></a>
</span><span id="__span-0-363"><a id="__codelineno-0-363" name="__codelineno-0-363"></a><span class="sd">    Combines the current derivative $f_k$ and the convolution sum according to the method&#39;s formula.</span>
</span><span id="__span-0-364"><a id="__codelineno-0-364" name="__codelineno-0-364"></a><span class="sd">    Note: The method name in the original code was slightly misleading; this function computes the update,</span>
</span><span id="__span-0-365"><a id="__codelineno-0-365" name="__codelineno-0-365"></a><span class="sd">    while `compute_convolution` computes the sum. Based on usage in `snn_solve`, this function</span>
</span><span id="__span-0-366"><a id="__codelineno-0-366" name="__codelineno-0-366"></a><span class="sd">    applies the final formula. However, looking at the implementation in subclasses,</span>
</span><span id="__span-0-367"><a id="__codelineno-0-367" name="__codelineno-0-367"></a><span class="sd">    `compute_convolution` actually performs the summation loop, and this function applies the scaling.</span>
</span><span id="__span-0-368"><a id="__codelineno-0-368" name="__codelineno-0-368"></a>
</span><span id="__span-0-369"><a id="__codelineno-0-369" name="__codelineno-0-369"></a><span class="sd">    Correction based on code analysis:</span>
</span><span id="__span-0-370"><a id="__codelineno-0-370" name="__codelineno-0-370"></a><span class="sd">    `compute_convolution` returns the sum $\sum w_j h_j$.</span>
</span><span id="__span-0-371"><a id="__codelineno-0-371" name="__codelineno-0-371"></a><span class="sd">    `compute_update_for_layer` takes that sum and $f_k$ to return $y_{k+1}$.</span>
</span><span id="__span-0-372"><a id="__codelineno-0-372" name="__codelineno-0-372"></a>
</span><span id="__span-0-373"><a id="__codelineno-0-373" name="__codelineno-0-373"></a><span class="sd">    Args:</span>
</span><span id="__span-0-374"><a id="__codelineno-0-374" name="__codelineno-0-374"></a><span class="sd">        f_k_i: The derivative/value $f(t_k, y_k)$ for this layer.</span>
</span><span id="__span-0-375"><a id="__codelineno-0-375" name="__codelineno-0-375"></a><span class="sd">        convolution_sum: The result of the history convolution.</span>
</span><span id="__span-0-376"><a id="__codelineno-0-376" name="__codelineno-0-376"></a><span class="sd">        config: Solver configuration.</span>
</span><span id="__span-0-377"><a id="__codelineno-0-377" name="__codelineno-0-377"></a><span class="sd">        layer_idx: Index of the layer.</span>
</span><span id="__span-0-378"><a id="__codelineno-0-378" name="__codelineno-0-378"></a>
</span><span id="__span-0-379"><a id="__codelineno-0-379" name="__codelineno-0-379"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-380"><a id="__codelineno-0-380" name="__codelineno-0-380"></a><span class="sd">        The updated state tensor $y_{k+1}$.</span>
</span><span id="__span-0-381"><a id="__codelineno-0-381" name="__codelineno-0-381"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-382"><a id="__codelineno-0-382" name="__codelineno-0-382"></a>    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spikeDE.solver.SNNFractionalMethod.compute_weights_for_layer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">compute_weights_for_layer</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">compute_weights_for_layer</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">k</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span> <span class="n">start_idx</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            SNNSolverConfig


  
      dataclass
   (spikeDE.solver.SNNSolverConfig)" href="#spikeDE.solver.SNNSolverConfig">SNNSolverConfig</a></span><span class="p">,</span> <span class="n">layer_idx</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the convolution weights for a specific layer at time step <span class="arithmatex">\(k\)</span>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>k</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>Current time step index.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>start_idx</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>Start index of the history window.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>config</code></b>
              (<code><a class="autorefs autorefs-internal" title="            SNNSolverConfig


  
      dataclass
   (spikeDE.solver.SNNSolverConfig)" href="#spikeDE.solver.SNNSolverConfig">SNNSolverConfig</a></code>)
          –
          <div class="doc-md-description">
            <p>Solver configuration containing layer metadata.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>layer_idx</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>Index of the layer being processed.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></code>
          –
          <div class="doc-md-description">
            <p>A tensor or structure containing the weights <span class="arithmatex">\(w_j\)</span> for the convolution sum.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-334">334</a></span>
<span class="normal"><a href="#__codelineno-0-335">335</a></span>
<span class="normal"><a href="#__codelineno-0-336">336</a></span>
<span class="normal"><a href="#__codelineno-0-337">337</a></span>
<span class="normal"><a href="#__codelineno-0-338">338</a></span>
<span class="normal"><a href="#__codelineno-0-339">339</a></span>
<span class="normal"><a href="#__codelineno-0-340">340</a></span>
<span class="normal"><a href="#__codelineno-0-341">341</a></span>
<span class="normal"><a href="#__codelineno-0-342">342</a></span>
<span class="normal"><a href="#__codelineno-0-343">343</a></span>
<span class="normal"><a href="#__codelineno-0-344">344</a></span>
<span class="normal"><a href="#__codelineno-0-345">345</a></span>
<span class="normal"><a href="#__codelineno-0-346">346</a></span>
<span class="normal"><a href="#__codelineno-0-347">347</a></span>
<span class="normal"><a href="#__codelineno-0-348">348</a></span>
<span class="normal"><a href="#__codelineno-0-349">349</a></span>
<span class="normal"><a href="#__codelineno-0-350">350</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-334"><a id="__codelineno-0-334" name="__codelineno-0-334"></a><span class="nd">@abstractmethod</span>
</span><span id="__span-0-335"><a id="__codelineno-0-335" name="__codelineno-0-335"></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_weights_for_layer</span><span class="p">(</span>
</span><span id="__span-0-336"><a id="__codelineno-0-336" name="__codelineno-0-336"></a>    <span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">start_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">SNNSolverConfig</span><span class="p">,</span> <span class="n">layer_idx</span><span class="p">:</span> <span class="nb">int</span>
</span><span id="__span-0-337"><a id="__codelineno-0-337" name="__codelineno-0-337"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
</span><span id="__span-0-338"><a id="__codelineno-0-338" name="__codelineno-0-338"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-339"><a id="__codelineno-0-339" name="__codelineno-0-339"></a><span class="sd">    Computes the convolution weights for a specific layer at time step $k$.</span>
</span><span id="__span-0-340"><a id="__codelineno-0-340" name="__codelineno-0-340"></a>
</span><span id="__span-0-341"><a id="__codelineno-0-341" name="__codelineno-0-341"></a><span class="sd">    Args:</span>
</span><span id="__span-0-342"><a id="__codelineno-0-342" name="__codelineno-0-342"></a><span class="sd">        k: Current time step index.</span>
</span><span id="__span-0-343"><a id="__codelineno-0-343" name="__codelineno-0-343"></a><span class="sd">        start_idx: Start index of the history window.</span>
</span><span id="__span-0-344"><a id="__codelineno-0-344" name="__codelineno-0-344"></a><span class="sd">        config: Solver configuration containing layer metadata.</span>
</span><span id="__span-0-345"><a id="__codelineno-0-345" name="__codelineno-0-345"></a><span class="sd">        layer_idx: Index of the layer being processed.</span>
</span><span id="__span-0-346"><a id="__codelineno-0-346" name="__codelineno-0-346"></a>
</span><span id="__span-0-347"><a id="__codelineno-0-347" name="__codelineno-0-347"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-348"><a id="__codelineno-0-348" name="__codelineno-0-348"></a><span class="sd">        A tensor or structure containing the weights $w_j$ for the convolution sum.</span>
</span><span id="__span-0-349"><a id="__codelineno-0-349" name="__codelineno-0-349"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-350"><a id="__codelineno-0-350" name="__codelineno-0-350"></a>    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spikeDE.solver.SNNFractionalMethod.initialize" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">initialize</span>


</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">initialize</span><span class="p">(</span><span class="n">config</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            SNNSolverConfig


  
      dataclass
   (spikeDE.solver.SNNSolverConfig)" href="#spikeDE.solver.SNNSolverConfig">SNNSolverConfig</a></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Optional hook for method-specific precomputation before the time loop.</p>
<p>Used to precompute static coefficients (e.g., GL binomial coefficients) that depend
on <span class="arithmatex">\(\alpha\)</span> and <span class="arithmatex">\(N\)</span> but not on the state <span class="arithmatex">\(y\)</span>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>config</code></b>
              (<code><a class="autorefs autorefs-internal" title="            SNNSolverConfig


  
      dataclass
   (spikeDE.solver.SNNSolverConfig)" href="#spikeDE.solver.SNNSolverConfig">SNNSolverConfig</a></code>)
          –
          <div class="doc-md-description">
            <p>Solver configuration.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-412">412</a></span>
<span class="normal"><a href="#__codelineno-0-413">413</a></span>
<span class="normal"><a href="#__codelineno-0-414">414</a></span>
<span class="normal"><a href="#__codelineno-0-415">415</a></span>
<span class="normal"><a href="#__codelineno-0-416">416</a></span>
<span class="normal"><a href="#__codelineno-0-417">417</a></span>
<span class="normal"><a href="#__codelineno-0-418">418</a></span>
<span class="normal"><a href="#__codelineno-0-419">419</a></span>
<span class="normal"><a href="#__codelineno-0-420">420</a></span>
<span class="normal"><a href="#__codelineno-0-421">421</a></span>
<span class="normal"><a href="#__codelineno-0-422">422</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-412"><a id="__codelineno-0-412" name="__codelineno-0-412"></a><span class="k">def</span><span class="w"> </span><span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">SNNSolverConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-413"><a id="__codelineno-0-413" name="__codelineno-0-413"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-414"><a id="__codelineno-0-414" name="__codelineno-0-414"></a><span class="sd">    Optional hook for method-specific precomputation before the time loop.</span>
</span><span id="__span-0-415"><a id="__codelineno-0-415" name="__codelineno-0-415"></a>
</span><span id="__span-0-416"><a id="__codelineno-0-416" name="__codelineno-0-416"></a><span class="sd">    Used to precompute static coefficients (e.g., GL binomial coefficients) that depend</span>
</span><span id="__span-0-417"><a id="__codelineno-0-417" name="__codelineno-0-417"></a><span class="sd">    on $\alpha$ and $N$ but not on the state $y$.</span>
</span><span id="__span-0-418"><a id="__codelineno-0-418" name="__codelineno-0-418"></a>
</span><span id="__span-0-419"><a id="__codelineno-0-419" name="__codelineno-0-419"></a><span class="sd">    Args:</span>
</span><span id="__span-0-420"><a id="__codelineno-0-420" name="__codelineno-0-420"></a><span class="sd">        config: Solver configuration.</span>
</span><span id="__span-0-421"><a id="__codelineno-0-421" name="__codelineno-0-421"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-422"><a id="__codelineno-0-422" name="__codelineno-0-422"></a>    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="spikeDE.solver.GrunwaldLetnikovSNN" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">GrunwaldLetnikovSNN</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">GrunwaldLetnikovSNN</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="            SNNFractionalMethod (spikeDE.solver.SNNFractionalMethod)" href="#spikeDE.solver.SNNFractionalMethod">SNNFractionalMethod</a></code></p>



        <p>Grünwald-Letnikov (GL) solver for single-term Riemann-Liouville Fractional Differential Equations (FDEs).</p>
<p>This class implements the standard GL discretization scheme, which approximates the
Riemann-Liouville fractional derivative <span class="arithmatex">\(D^\alpha y(t)\)</span> using a finite difference convolution.</p>
<p>Mathematical Formulation:
The update rule for the state <span class="arithmatex">\(y\)</span> at step <span class="arithmatex">\(k+1\)</span> is given by:</p>
<div class="arithmatex">\[y_{k+1} = h^\alpha f(t_k, y_k) - \sum_{j=0}^{k} c_{k-j}^{(\alpha)} y_j\]</div>
<p>where <span class="arithmatex">\(h\)</span> is the step size, <span class="arithmatex">\(f(t, y)\)</span> is the ODE function, and <span class="arithmatex">\(c_j^{(\alpha)}\)</span> are the
Grünwald-Letnikov coefficients generated recursively:</p>
<div class="arithmatex">\[c_0^{(\alpha)} = 1, \quad c_j^{(\alpha)} = \left(1 - \frac{1+\alpha}{j}\right)c_{j-1}^{(\alpha)} \quad \text{for } j \ge 1\]</div>
<p>Key Characteristics:</p>
<ul>
<li><strong>Formulation</strong>: Riemann-Liouville.</li>
<li><strong>Accuracy</strong>: First-order <span class="arithmatex">\(O(h)\)</span>.</li>
<li><strong>Memory</strong>: Requires full history of states <span class="arithmatex">\(y\)</span> unless truncated.</li>
<li><strong>Constraint</strong>: Strictly supports single-term fractional orders (<span class="arithmatex">\(\alpha\)</span> is a scalar per layer).
  Attempting to use multi-term <span class="arithmatex">\(\alpha\)</span> will raise a <code>ValueError</code>. For multi-term support,
  use <code>GrunwaldLetnikovMultitermSNN</code>.</li>
</ul>

          







                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>spikeDE/solver.py</code></summary>
                    <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-452">452</a></span>
<span class="normal"><a href="#__codelineno-0-453">453</a></span>
<span class="normal"><a href="#__codelineno-0-454">454</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-452"><a id="__codelineno-0-452" name="__codelineno-0-452"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="__span-0-453"><a id="__codelineno-0-453" name="__codelineno-0-453"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Initializes the solver with empty coefficient storage.&quot;&quot;&quot;</span>
</span><span id="__span-0-454"><a id="__codelineno-0-454" name="__codelineno-0-454"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_c_per_layer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="spikeDE.solver.ProductTrapezoidalSNN" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">ProductTrapezoidalSNN</span>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="            SNNFractionalMethod (spikeDE.solver.SNNFractionalMethod)" href="#spikeDE.solver.SNNFractionalMethod">SNNFractionalMethod</a></code></p>



        <p>Product Trapezoidal solver for single-term Riemann-Liouville FDEs.</p>
<p>This method offers higher accuracy (<span class="arithmatex">\(O(h^2)\)</span>) compared to the Grünwald-Letnikov scheme
by using a piecewise linear interpolation of the integrand. It is particularly effective
for smooth solutions.</p>
<p>The update rule is:</p>
<div class="arithmatex">\[y_{k+1} = \frac{h^\alpha}{\Gamma(2-\alpha)} f(t_k, y_k) - \sum_{j=0}^{k} A_{j,k+1} y_j\]</div>
<p>The weights <span class="arithmatex">\(A_{j,k+1}\)</span> are position-dependent and defined as:</p>
<ul>
<li>For <span class="arithmatex">\(j=0\)</span>:</li>
</ul>
<p>$<span class="arithmatex">\(A_{0,k+1} = k^{1-\alpha} - (k+\alpha)(k+1)^{-\alpha}\)</span>$</p>
<ul>
<li>For <span class="arithmatex">\(j \ge 1\)</span>:</li>
</ul>
<p>$<span class="arithmatex">\(A_{j,k+1} = (k+2-j)^{1-\alpha} + (k-j)^{1-\alpha} - 2(k+1-j)^{1-\alpha}\)</span>$</p>
<p>Key Characteristics:</p>
<ul>
<li><strong>Formulation</strong>: Riemann-Liouville.</li>
<li><strong>Accuracy</strong>: Second-order <span class="arithmatex">\(O(h^2)\)</span>.</li>
<li><strong>Constraint</strong>: Supports single-term <span class="arithmatex">\(\alpha\)</span> only.</li>
</ul>

          










<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="spikeDE.solver.L1MethodSNN" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">L1MethodSNN</span>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="            SNNFractionalMethod (spikeDE.solver.SNNFractionalMethod)" href="#spikeDE.solver.SNNFractionalMethod">SNNFractionalMethod</a></code></p>



        <p>L1 scheme solver for single-term Caputo Fractional Differential Equations.</p>
<p>The L1 method is the most widely used numerical scheme for Caputo derivatives,
offering an accuracy of <span class="arithmatex">\(O(h^{2-\alpha})\)</span> for smooth solutions. It approximates
the fractional derivative using piecewise linear interpolation of the function.</p>
<p>Mathematical Formulation:
The update rule is:</p>
<div class="arithmatex">\[y_{k+1} = \frac{h^\alpha}{\Gamma(2-\alpha)} f(t_k, y_k) - \sum_{j=0}^{k} c_j^{(k)} y_j\]</div>
<p>The coefficients <span class="arithmatex">\(c_j^{(k)}\)</span> are defined as:</p>
<ul>
<li>For <span class="arithmatex">\(j=0\)</span>:</li>
</ul>
<p>$<span class="arithmatex">\(c_0^{(k)} = -\left((k+1)^{1-\alpha} - k^{1-\alpha}\right)\)</span>$</p>
<ul>
<li>For <span class="arithmatex">\(j \ge 1\)</span>:</li>
</ul>
<p>$<span class="arithmatex">\(c_j^{(k)} = (k-j+2)^{1-\alpha} - 2(k-j+1)^{1-\alpha} + (k-j)^{1-\alpha}\)</span>$</p>
<p>Key Characteristics:</p>
<ul>
<li><strong>Formulation</strong>: Caputo.</li>
<li><strong>Accuracy</strong>: <span class="arithmatex">\(O(h^{2-\alpha})\)</span>.</li>
<li><strong>Constraint</strong>: Single-term <span class="arithmatex">\(\alpha\)</span> only.</li>
</ul>

          










<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="spikeDE.solver.AdamsBashforthSNN" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">AdamsBashforthSNN</span>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="            SNNFractionalMethod (spikeDE.solver.SNNFractionalMethod)" href="#spikeDE.solver.SNNFractionalMethod">SNNFractionalMethod</a></code></p>



        <p>Adams-Bashforth predictor method for single-term Caputo FDEs.</p>
<p>This method serves as a predictor step in predictor-corrector schemes (like PECE).
Unlike the other methods which convolve state history <span class="arithmatex">\(y_j\)</span>, Adams-Bashforth convolves
the history of function evaluations <span class="arithmatex">\(f(t_j, y_j)\)</span>.</p>
<p>The update rule is:</p>
<div class="arithmatex">\[y_{k+1} = \sum_{j=0}^{k} b_{j,k+1} f(t_j, y_j)\]</div>
<p>where the weights are:</p>
<div class="arithmatex">\[b_{j,k+1} = \frac{h^\alpha}{\alpha \Gamma(\alpha)} \left[ (k+1-j)^\alpha - (k-j)^\alpha \right]\]</div>
<p>Key Characteristics:</p>
<ul>
<li><strong>Formulation</strong>: Caputo (Predictor).</li>
<li><strong>History Type</strong>: Stores <span class="arithmatex">\(f(t, y)\)</span> instead of <span class="arithmatex">\(y\)</span>.</li>
<li><strong>Constraint</strong>: Single-term <span class="arithmatex">\(\alpha\)</span> only.</li>
</ul>

          










<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="spikeDE.solver.GrunwaldLetnikovMultitermSNN" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">GrunwaldLetnikovMultitermSNN</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">GrunwaldLetnikovMultitermSNN</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="            SNNFractionalMethod (spikeDE.solver.SNNFractionalMethod)" href="#spikeDE.solver.SNNFractionalMethod">SNNFractionalMethod</a></code></p>



        <p>Unified Grünwald-Letnikov solver for multi-term Riemann-Liouville FDEs.</p>
<p>This solver handles distributed-order or multi-term equations of the form:</p>
<div class="arithmatex">\[\sum_{m=1}^{M} c_m D^{\alpha_m} y(t) = f(t, y(t))\]</div>
<p>It generalizes the single-term GL method by aggregating the coefficients from each term
into a single effective convolution kernel.</p>
<p>The discretization leads to the update rule:</p>
<div class="arithmatex">\[y_{k+1} = \frac{1}{\tilde{c}_0} \left( f(t_k, y_k) - \sum_{j=0}^{k} \tilde{c}_{k-j} y_j \right)\]</div>
<p>where the aggregated coefficients <span class="arithmatex">\(\tilde{c}_m\)</span> are computed as:</p>
<div class="arithmatex">\[\tilde{c}_m = \sum_{i=1}^{M} c_i h^{-\alpha_i} c_m^{(\alpha_i)}\]</div>
<p>Here, <span class="arithmatex">\(c_i\)</span> are the user-defined equation coefficients, <span class="arithmatex">\(h^{-\alpha_i}\)</span> scales by step size,
and <span class="arithmatex">\(c_m^{(\alpha_i)}\)</span> are the standard GL coefficients for order <span class="arithmatex">\(\alpha_i\)</span>.</p>
<p>Key Characteristics:</p>
<ul>
<li><strong>Formulation</strong>: Riemann-Liouville (Multi-term).</li>
<li><strong>Flexibility</strong>: Supports both single-term (as a 1-term case) and multi-term layers.</li>
<li><strong>Gradient Flow</strong>: Fully differentiable with respect to <span class="arithmatex">\(\alpha_m\)</span> and coefficients <span class="arithmatex">\(c_m\)</span>.</li>
</ul>

          







                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>spikeDE/solver.py</code></summary>
                    <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-822">822</a></span>
<span class="normal"><a href="#__codelineno-0-823">823</a></span>
<span class="normal"><a href="#__codelineno-0-824">824</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-822"><a id="__codelineno-0-822" name="__codelineno-0-822"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="__span-0-823"><a id="__codelineno-0-823" name="__codelineno-0-823"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_c_tilde_per_layer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-824"><a id="__codelineno-0-824" name="__codelineno-0-824"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_c_tilde_0_inv_per_layer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="spikeDE.solver.FDEAdjointMethod" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">FDEAdjointMethod</span>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-external" title="torch.autograd.Function" href="https://docs.pytorch.org/docs/stable/autograd.html#torch.autograd.Function">Function</a></code></p>



        <p>Custom Autograd Function for Fractional Differential Equations with Adjoint Sensitivity.</p>
<p>This class implements the forward and backward passes required for differentiating through
FDE solvers. It supports various numerical schemes (GL, Trapezoidal, L1, Adams-Bashforth)
and handles the complexity of fractional memory terms during backpropagation.</p>
<p>Mathematical Formulation:
The adjoint state <span class="arithmatex">\(\lambda(t)\)</span> satisfies the fractional adjoint equation:</p>
<div class="arithmatex">\[D^\alpha \lambda(t) = -\left(\frac{\partial f}{\partial y}\right)^T \lambda(t)\]</div>
<p>solved backwards from <span class="arithmatex">\(t=T\)</span> to <span class="arithmatex">\(t=0\)</span>. Parameter gradients are computed via:</p>
<div class="arithmatex">\[\frac{dL}{d\theta} = \int_0^T \lambda(t)^T \frac{\partial f}{\partial \theta} dt\]</div>

          










<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="spikeDE.solver.FDEAdjointMethod.backward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">backward</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">:</span> <span class="n"><span title="torch.autograd.function.FunctionCtx">FunctionCtx</span></span><span class="p">,</span> <span class="o">*</span><span class="n">grad_output</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Performs the backward adjoint integration to compute gradients.</p>
<p>Reconstructs the augmented dynamics system and solves it backwards in time to obtain
gradients with respect to initial states (<span class="arithmatex">\(y_0\)</span>) and model parameters (<span class="arithmatex">\(\theta\)</span>).</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ctx</code></b>
              (<code><span title="torch.autograd.function.FunctionCtx">FunctionCtx</span></code>)
          –
          <div class="doc-md-description">
            <p>Context object containing saved tensors from forward pass.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>*grad_output</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>, default:
                  <code>()</code>
)
          –
          <div class="doc-md-description">
            <p>Gradients of the loss with respect to the output states <span class="arithmatex">\(y(t_{end})\)</span>.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a> | None, ...]</code>
          –
          <div class="doc-md-description">
            <p>A tuple of gradients corresponding to the inputs of <code>forward</code>: <code>(grad_func, grad_n_state, grad_n_params, grad_y0..., grad_alpha, grad_t_grid, grad_method, grad_params..., grad_memory)</code>. Non-tensor inputs return <code>None</code>.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1510">1510</a></span>
<span class="normal"><a href="#__codelineno-0-1511">1511</a></span>
<span class="normal"><a href="#__codelineno-0-1512">1512</a></span>
<span class="normal"><a href="#__codelineno-0-1513">1513</a></span>
<span class="normal"><a href="#__codelineno-0-1514">1514</a></span>
<span class="normal"><a href="#__codelineno-0-1515">1515</a></span>
<span class="normal"><a href="#__codelineno-0-1516">1516</a></span>
<span class="normal"><a href="#__codelineno-0-1517">1517</a></span>
<span class="normal"><a href="#__codelineno-0-1518">1518</a></span>
<span class="normal"><a href="#__codelineno-0-1519">1519</a></span>
<span class="normal"><a href="#__codelineno-0-1520">1520</a></span>
<span class="normal"><a href="#__codelineno-0-1521">1521</a></span>
<span class="normal"><a href="#__codelineno-0-1522">1522</a></span>
<span class="normal"><a href="#__codelineno-0-1523">1523</a></span>
<span class="normal"><a href="#__codelineno-0-1524">1524</a></span>
<span class="normal"><a href="#__codelineno-0-1525">1525</a></span>
<span class="normal"><a href="#__codelineno-0-1526">1526</a></span>
<span class="normal"><a href="#__codelineno-0-1527">1527</a></span>
<span class="normal"><a href="#__codelineno-0-1528">1528</a></span>
<span class="normal"><a href="#__codelineno-0-1529">1529</a></span>
<span class="normal"><a href="#__codelineno-0-1530">1530</a></span>
<span class="normal"><a href="#__codelineno-0-1531">1531</a></span>
<span class="normal"><a href="#__codelineno-0-1532">1532</a></span>
<span class="normal"><a href="#__codelineno-0-1533">1533</a></span>
<span class="normal"><a href="#__codelineno-0-1534">1534</a></span>
<span class="normal"><a href="#__codelineno-0-1535">1535</a></span>
<span class="normal"><a href="#__codelineno-0-1536">1536</a></span>
<span class="normal"><a href="#__codelineno-0-1537">1537</a></span>
<span class="normal"><a href="#__codelineno-0-1538">1538</a></span>
<span class="normal"><a href="#__codelineno-0-1539">1539</a></span>
<span class="normal"><a href="#__codelineno-0-1540">1540</a></span>
<span class="normal"><a href="#__codelineno-0-1541">1541</a></span>
<span class="normal"><a href="#__codelineno-0-1542">1542</a></span>
<span class="normal"><a href="#__codelineno-0-1543">1543</a></span>
<span class="normal"><a href="#__codelineno-0-1544">1544</a></span>
<span class="normal"><a href="#__codelineno-0-1545">1545</a></span>
<span class="normal"><a href="#__codelineno-0-1546">1546</a></span>
<span class="normal"><a href="#__codelineno-0-1547">1547</a></span>
<span class="normal"><a href="#__codelineno-0-1548">1548</a></span>
<span class="normal"><a href="#__codelineno-0-1549">1549</a></span>
<span class="normal"><a href="#__codelineno-0-1550">1550</a></span>
<span class="normal"><a href="#__codelineno-0-1551">1551</a></span>
<span class="normal"><a href="#__codelineno-0-1552">1552</a></span>
<span class="normal"><a href="#__codelineno-0-1553">1553</a></span>
<span class="normal"><a href="#__codelineno-0-1554">1554</a></span>
<span class="normal"><a href="#__codelineno-0-1555">1555</a></span>
<span class="normal"><a href="#__codelineno-0-1556">1556</a></span>
<span class="normal"><a href="#__codelineno-0-1557">1557</a></span>
<span class="normal"><a href="#__codelineno-0-1558">1558</a></span>
<span class="normal"><a href="#__codelineno-0-1559">1559</a></span>
<span class="normal"><a href="#__codelineno-0-1560">1560</a></span>
<span class="normal"><a href="#__codelineno-0-1561">1561</a></span>
<span class="normal"><a href="#__codelineno-0-1562">1562</a></span>
<span class="normal"><a href="#__codelineno-0-1563">1563</a></span>
<span class="normal"><a href="#__codelineno-0-1564">1564</a></span>
<span class="normal"><a href="#__codelineno-0-1565">1565</a></span>
<span class="normal"><a href="#__codelineno-0-1566">1566</a></span>
<span class="normal"><a href="#__codelineno-0-1567">1567</a></span>
<span class="normal"><a href="#__codelineno-0-1568">1568</a></span>
<span class="normal"><a href="#__codelineno-0-1569">1569</a></span>
<span class="normal"><a href="#__codelineno-0-1570">1570</a></span>
<span class="normal"><a href="#__codelineno-0-1571">1571</a></span>
<span class="normal"><a href="#__codelineno-0-1572">1572</a></span>
<span class="normal"><a href="#__codelineno-0-1573">1573</a></span>
<span class="normal"><a href="#__codelineno-0-1574">1574</a></span>
<span class="normal"><a href="#__codelineno-0-1575">1575</a></span>
<span class="normal"><a href="#__codelineno-0-1576">1576</a></span>
<span class="normal"><a href="#__codelineno-0-1577">1577</a></span>
<span class="normal"><a href="#__codelineno-0-1578">1578</a></span>
<span class="normal"><a href="#__codelineno-0-1579">1579</a></span>
<span class="normal"><a href="#__codelineno-0-1580">1580</a></span>
<span class="normal"><a href="#__codelineno-0-1581">1581</a></span>
<span class="normal"><a href="#__codelineno-0-1582">1582</a></span>
<span class="normal"><a href="#__codelineno-0-1583">1583</a></span>
<span class="normal"><a href="#__codelineno-0-1584">1584</a></span>
<span class="normal"><a href="#__codelineno-0-1585">1585</a></span>
<span class="normal"><a href="#__codelineno-0-1586">1586</a></span>
<span class="normal"><a href="#__codelineno-0-1587">1587</a></span>
<span class="normal"><a href="#__codelineno-0-1588">1588</a></span>
<span class="normal"><a href="#__codelineno-0-1589">1589</a></span>
<span class="normal"><a href="#__codelineno-0-1590">1590</a></span>
<span class="normal"><a href="#__codelineno-0-1591">1591</a></span>
<span class="normal"><a href="#__codelineno-0-1592">1592</a></span>
<span class="normal"><a href="#__codelineno-0-1593">1593</a></span>
<span class="normal"><a href="#__codelineno-0-1594">1594</a></span>
<span class="normal"><a href="#__codelineno-0-1595">1595</a></span>
<span class="normal"><a href="#__codelineno-0-1596">1596</a></span>
<span class="normal"><a href="#__codelineno-0-1597">1597</a></span>
<span class="normal"><a href="#__codelineno-0-1598">1598</a></span>
<span class="normal"><a href="#__codelineno-0-1599">1599</a></span>
<span class="normal"><a href="#__codelineno-0-1600">1600</a></span>
<span class="normal"><a href="#__codelineno-0-1601">1601</a></span>
<span class="normal"><a href="#__codelineno-0-1602">1602</a></span>
<span class="normal"><a href="#__codelineno-0-1603">1603</a></span>
<span class="normal"><a href="#__codelineno-0-1604">1604</a></span>
<span class="normal"><a href="#__codelineno-0-1605">1605</a></span>
<span class="normal"><a href="#__codelineno-0-1606">1606</a></span>
<span class="normal"><a href="#__codelineno-0-1607">1607</a></span>
<span class="normal"><a href="#__codelineno-0-1608">1608</a></span>
<span class="normal"><a href="#__codelineno-0-1609">1609</a></span>
<span class="normal"><a href="#__codelineno-0-1610">1610</a></span>
<span class="normal"><a href="#__codelineno-0-1611">1611</a></span>
<span class="normal"><a href="#__codelineno-0-1612">1612</a></span>
<span class="normal"><a href="#__codelineno-0-1613">1613</a></span>
<span class="normal"><a href="#__codelineno-0-1614">1614</a></span>
<span class="normal"><a href="#__codelineno-0-1615">1615</a></span>
<span class="normal"><a href="#__codelineno-0-1616">1616</a></span>
<span class="normal"><a href="#__codelineno-0-1617">1617</a></span>
<span class="normal"><a href="#__codelineno-0-1618">1618</a></span>
<span class="normal"><a href="#__codelineno-0-1619">1619</a></span>
<span class="normal"><a href="#__codelineno-0-1620">1620</a></span>
<span class="normal"><a href="#__codelineno-0-1621">1621</a></span>
<span class="normal"><a href="#__codelineno-0-1622">1622</a></span>
<span class="normal"><a href="#__codelineno-0-1623">1623</a></span>
<span class="normal"><a href="#__codelineno-0-1624">1624</a></span>
<span class="normal"><a href="#__codelineno-0-1625">1625</a></span>
<span class="normal"><a href="#__codelineno-0-1626">1626</a></span>
<span class="normal"><a href="#__codelineno-0-1627">1627</a></span>
<span class="normal"><a href="#__codelineno-0-1628">1628</a></span>
<span class="normal"><a href="#__codelineno-0-1629">1629</a></span>
<span class="normal"><a href="#__codelineno-0-1630">1630</a></span>
<span class="normal"><a href="#__codelineno-0-1631">1631</a></span>
<span class="normal"><a href="#__codelineno-0-1632">1632</a></span>
<span class="normal"><a href="#__codelineno-0-1633">1633</a></span>
<span class="normal"><a href="#__codelineno-0-1634">1634</a></span>
<span class="normal"><a href="#__codelineno-0-1635">1635</a></span>
<span class="normal"><a href="#__codelineno-0-1636">1636</a></span>
<span class="normal"><a href="#__codelineno-0-1637">1637</a></span>
<span class="normal"><a href="#__codelineno-0-1638">1638</a></span>
<span class="normal"><a href="#__codelineno-0-1639">1639</a></span>
<span class="normal"><a href="#__codelineno-0-1640">1640</a></span>
<span class="normal"><a href="#__codelineno-0-1641">1641</a></span>
<span class="normal"><a href="#__codelineno-0-1642">1642</a></span>
<span class="normal"><a href="#__codelineno-0-1643">1643</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1510"><a id="__codelineno-0-1510" name="__codelineno-0-1510"></a><span class="nd">@staticmethod</span>
</span><span id="__span-0-1511"><a id="__codelineno-0-1511" name="__codelineno-0-1511"></a><span class="k">def</span><span class="w"> </span><span class="nf">backward</span><span class="p">(</span>
</span><span id="__span-0-1512"><a id="__codelineno-0-1512" name="__codelineno-0-1512"></a>    <span class="n">ctx</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">FunctionCtx</span><span class="p">,</span> <span class="o">*</span><span class="n">grad_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</span><span id="__span-0-1513"><a id="__codelineno-0-1513" name="__codelineno-0-1513"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="o">...</span><span class="p">]:</span>
</span><span id="__span-0-1514"><a id="__codelineno-0-1514" name="__codelineno-0-1514"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-1515"><a id="__codelineno-0-1515" name="__codelineno-0-1515"></a><span class="sd">    Performs the backward adjoint integration to compute gradients.</span>
</span><span id="__span-0-1516"><a id="__codelineno-0-1516" name="__codelineno-0-1516"></a>
</span><span id="__span-0-1517"><a id="__codelineno-0-1517" name="__codelineno-0-1517"></a><span class="sd">    Reconstructs the augmented dynamics system and solves it backwards in time to obtain</span>
</span><span id="__span-0-1518"><a id="__codelineno-0-1518" name="__codelineno-0-1518"></a><span class="sd">    gradients with respect to initial states ($y_0$) and model parameters ($\theta$).</span>
</span><span id="__span-0-1519"><a id="__codelineno-0-1519" name="__codelineno-0-1519"></a>
</span><span id="__span-0-1520"><a id="__codelineno-0-1520" name="__codelineno-0-1520"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1521"><a id="__codelineno-0-1521" name="__codelineno-0-1521"></a><span class="sd">        ctx: Context object containing saved tensors from forward pass.</span>
</span><span id="__span-0-1522"><a id="__codelineno-0-1522" name="__codelineno-0-1522"></a><span class="sd">        *grad_output: Gradients of the loss with respect to the output states $y(t_{end})$.</span>
</span><span id="__span-0-1523"><a id="__codelineno-0-1523" name="__codelineno-0-1523"></a>
</span><span id="__span-0-1524"><a id="__codelineno-0-1524" name="__codelineno-0-1524"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1525"><a id="__codelineno-0-1525" name="__codelineno-0-1525"></a><span class="sd">        A tuple of gradients corresponding to the inputs of `forward`: `(grad_func, grad_n_state, grad_n_params, grad_y0..., grad_alpha, grad_t_grid, grad_method, grad_params..., grad_memory)`. Non-tensor inputs return `None`.</span>
</span><span id="__span-0-1526"><a id="__codelineno-0-1526" name="__codelineno-0-1526"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-1527"><a id="__codelineno-0-1527" name="__codelineno-0-1527"></a>    <span class="c1"># 早退：不需要反传时，返回正确数量的 None</span>
</span><span id="__span-0-1528"><a id="__codelineno-0-1528" name="__codelineno-0-1528"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="s2">&quot;yhistory&quot;</span><span class="p">):</span>
</span><span id="__span-0-1529"><a id="__codelineno-0-1529" name="__codelineno-0-1529"></a>        <span class="n">n_state</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">n_state</span>
</span><span id="__span-0-1530"><a id="__codelineno-0-1530" name="__codelineno-0-1530"></a>        <span class="n">n_params</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">n_params</span>
</span><span id="__span-0-1531"><a id="__codelineno-0-1531" name="__codelineno-0-1531"></a>        <span class="n">grads</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-1532"><a id="__codelineno-0-1532" name="__codelineno-0-1532"></a>        <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># ode_func</span>
</span><span id="__span-0-1533"><a id="__codelineno-0-1533" name="__codelineno-0-1533"></a>        <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># n_state</span>
</span><span id="__span-0-1534"><a id="__codelineno-0-1534" name="__codelineno-0-1534"></a>        <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># n_params</span>
</span><span id="__span-0-1535"><a id="__codelineno-0-1535" name="__codelineno-0-1535"></a>        <span class="n">grads</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_state</span><span class="p">)</span>  <span class="c1"># y0_1,...,y0_n</span>
</span><span id="__span-0-1536"><a id="__codelineno-0-1536" name="__codelineno-0-1536"></a>        <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># alpha</span>
</span><span id="__span-0-1537"><a id="__codelineno-0-1537" name="__codelineno-0-1537"></a>        <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># t_grid</span>
</span><span id="__span-0-1538"><a id="__codelineno-0-1538" name="__codelineno-0-1538"></a>        <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># method</span>
</span><span id="__span-0-1539"><a id="__codelineno-0-1539" name="__codelineno-0-1539"></a>        <span class="n">grads</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_params</span><span class="p">)</span>  <span class="c1"># p1,...,pm</span>
</span><span id="__span-0-1540"><a id="__codelineno-0-1540" name="__codelineno-0-1540"></a>        <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># memory</span>
</span><span id="__span-0-1541"><a id="__codelineno-0-1541" name="__codelineno-0-1541"></a>        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>
</span><span id="__span-0-1542"><a id="__codelineno-0-1542" name="__codelineno-0-1542"></a>
</span><span id="__span-0-1543"><a id="__codelineno-0-1543" name="__codelineno-0-1543"></a>    <span class="c1"># 恢复保存的张量和属性</span>
</span><span id="__span-0-1544"><a id="__codelineno-0-1544" name="__codelineno-0-1544"></a>    <span class="n">t_grid</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">saved_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="__span-0-1545"><a id="__codelineno-0-1545" name="__codelineno-0-1545"></a>    <span class="n">func_params</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">func_params</span>
</span><span id="__span-0-1546"><a id="__codelineno-0-1546" name="__codelineno-0-1546"></a>    <span class="n">yhistory</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">yhistory</span>
</span><span id="__span-0-1547"><a id="__codelineno-0-1547" name="__codelineno-0-1547"></a>    <span class="c1"># yhistory is the last states for euler and the full history for other methods</span>
</span><span id="__span-0-1548"><a id="__codelineno-0-1548" name="__codelineno-0-1548"></a>
</span><span id="__span-0-1549"><a id="__codelineno-0-1549" name="__codelineno-0-1549"></a>    <span class="n">func</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">ode_func</span>
</span><span id="__span-0-1550"><a id="__codelineno-0-1550" name="__codelineno-0-1550"></a>    <span class="n">alpha</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">alpha</span>
</span><span id="__span-0-1551"><a id="__codelineno-0-1551" name="__codelineno-0-1551"></a>    <span class="n">method</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">method</span>
</span><span id="__span-0-1552"><a id="__codelineno-0-1552" name="__codelineno-0-1552"></a>    <span class="n">memory</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">memory</span>
</span><span id="__span-0-1553"><a id="__codelineno-0-1553" name="__codelineno-0-1553"></a>    <span class="n">n_tensors</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">yhistory</span><span class="p">)</span>
</span><span id="__span-0-1554"><a id="__codelineno-0-1554" name="__codelineno-0-1554"></a>
</span><span id="__span-0-1555"><a id="__codelineno-0-1555" name="__codelineno-0-1555"></a>    <span class="c1"># 创建 augmented dynamics</span>
</span><span id="__span-0-1556"><a id="__codelineno-0-1556" name="__codelineno-0-1556"></a>    <span class="k">class</span><span class="w"> </span><span class="nc">AugDynamics</span><span class="p">:</span>
</span><span id="__span-0-1557"><a id="__codelineno-0-1557" name="__codelineno-0-1557"></a>        <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">n_tensors</span><span class="p">,</span> <span class="n">func_params</span><span class="p">):</span>
</span><span id="__span-0-1558"><a id="__codelineno-0-1558" name="__codelineno-0-1558"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">func</span> <span class="o">=</span> <span class="n">func</span>
</span><span id="__span-0-1559"><a id="__codelineno-0-1559" name="__codelineno-0-1559"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">n_tensors</span> <span class="o">=</span> <span class="n">n_tensors</span>
</span><span id="__span-0-1560"><a id="__codelineno-0-1560" name="__codelineno-0-1560"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">f_params</span> <span class="o">=</span> <span class="n">func_params</span>  <span class="c1"># 使用传入的参数</span>
</span><span id="__span-0-1561"><a id="__codelineno-0-1561" name="__codelineno-0-1561"></a>
</span><span id="__span-0-1562"><a id="__codelineno-0-1562" name="__codelineno-0-1562"></a>        <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">y_aug</span><span class="p">):</span>
</span><span id="__span-0-1563"><a id="__codelineno-0-1563" name="__codelineno-0-1563"></a>            <span class="n">y</span><span class="p">,</span> <span class="n">adj_y</span><span class="p">,</span> <span class="n">adj_params</span> <span class="o">=</span> <span class="n">y_aug</span>
</span><span id="__span-0-1564"><a id="__codelineno-0-1564" name="__codelineno-0-1564"></a>
</span><span id="__span-0-1565"><a id="__codelineno-0-1565" name="__codelineno-0-1565"></a>            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
</span><span id="__span-0-1566"><a id="__codelineno-0-1566" name="__codelineno-0-1566"></a>                <span class="c1"># detach 并设置 requires_grad</span>
</span><span id="__span-0-1567"><a id="__codelineno-0-1567" name="__codelineno-0-1567"></a>                <span class="n">y</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">y_</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">y_</span> <span class="ow">in</span> <span class="n">y</span><span class="p">)</span>
</span><span id="__span-0-1568"><a id="__codelineno-0-1568" name="__codelineno-0-1568"></a>                <span class="n">func_eval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span id="__span-0-1569"><a id="__codelineno-0-1569" name="__codelineno-0-1569"></a>
</span><span id="__span-0-1570"><a id="__codelineno-0-1570" name="__codelineno-0-1570"></a>                <span class="c1"># 计算 VJP</span>
</span><span id="__span-0-1571"><a id="__codelineno-0-1571" name="__codelineno-0-1571"></a>                <span class="n">vjp_y_and_params</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span>
</span><span id="__span-0-1572"><a id="__codelineno-0-1572" name="__codelineno-0-1572"></a>                    <span class="n">func_eval</span><span class="p">,</span>
</span><span id="__span-0-1573"><a id="__codelineno-0-1573" name="__codelineno-0-1573"></a>                    <span class="n">y</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_params</span><span class="p">,</span>
</span><span id="__span-0-1574"><a id="__codelineno-0-1574" name="__codelineno-0-1574"></a>                    <span class="nb">tuple</span><span class="p">(</span><span class="n">adj_y</span><span class="p">),</span>
</span><span id="__span-0-1575"><a id="__codelineno-0-1575" name="__codelineno-0-1575"></a>                    <span class="n">allow_unused</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-1576"><a id="__codelineno-0-1576" name="__codelineno-0-1576"></a>                    <span class="n">retain_graph</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># 不保留图</span>
</span><span id="__span-0-1577"><a id="__codelineno-0-1577" name="__codelineno-0-1577"></a>                    <span class="n">create_graph</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-1578"><a id="__codelineno-0-1578" name="__codelineno-0-1578"></a>                <span class="p">)</span>
</span><span id="__span-0-1579"><a id="__codelineno-0-1579" name="__codelineno-0-1579"></a>
</span><span id="__span-0-1580"><a id="__codelineno-0-1580" name="__codelineno-0-1580"></a>            <span class="n">vjp_y</span> <span class="o">=</span> <span class="n">vjp_y_and_params</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_tensors</span><span class="p">]</span>
</span><span id="__span-0-1581"><a id="__codelineno-0-1581" name="__codelineno-0-1581"></a>            <span class="n">vjp_params</span> <span class="o">=</span> <span class="n">vjp_y_and_params</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_tensors</span> <span class="p">:]</span>
</span><span id="__span-0-1582"><a id="__codelineno-0-1582" name="__codelineno-0-1582"></a>
</span><span id="__span-0-1583"><a id="__codelineno-0-1583" name="__codelineno-0-1583"></a>            <span class="c1"># 处理 None 梯度</span>
</span><span id="__span-0-1584"><a id="__codelineno-0-1584" name="__codelineno-0-1584"></a>            <span class="n">vjp_y</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
</span><span id="__span-0-1585"><a id="__codelineno-0-1585" name="__codelineno-0-1585"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y_</span><span class="p">)</span> <span class="k">if</span> <span class="n">vjp_y_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">vjp_y_</span>
</span><span id="__span-0-1586"><a id="__codelineno-0-1586" name="__codelineno-0-1586"></a>                <span class="k">for</span> <span class="n">vjp_y_</span><span class="p">,</span> <span class="n">y_</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">vjp_y</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span id="__span-0-1587"><a id="__codelineno-0-1587" name="__codelineno-0-1587"></a>            <span class="p">)</span>
</span><span id="__span-0-1588"><a id="__codelineno-0-1588" name="__codelineno-0-1588"></a>
</span><span id="__span-0-1589"><a id="__codelineno-0-1589" name="__codelineno-0-1589"></a>            <span class="n">vjp_params</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
</span><span id="__span-0-1590"><a id="__codelineno-0-1590" name="__codelineno-0-1590"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">if</span> <span class="n">vp</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">vp</span>
</span><span id="__span-0-1591"><a id="__codelineno-0-1591" name="__codelineno-0-1591"></a>                <span class="k">for</span> <span class="n">vp</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">vjp_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_params</span><span class="p">)</span>
</span><span id="__span-0-1592"><a id="__codelineno-0-1592" name="__codelineno-0-1592"></a>            <span class="p">)</span>
</span><span id="__span-0-1593"><a id="__codelineno-0-1593" name="__codelineno-0-1593"></a>
</span><span id="__span-0-1594"><a id="__codelineno-0-1594" name="__codelineno-0-1594"></a>            <span class="k">return</span> <span class="p">(</span><span class="n">func_eval</span><span class="p">,</span> <span class="n">vjp_y</span><span class="p">,</span> <span class="n">vjp_params</span><span class="p">)</span>
</span><span id="__span-0-1595"><a id="__codelineno-0-1595" name="__codelineno-0-1595"></a>
</span><span id="__span-0-1596"><a id="__codelineno-0-1596" name="__codelineno-0-1596"></a>    <span class="c1"># 创建 augmented dynamics 实例</span>
</span><span id="__span-0-1597"><a id="__codelineno-0-1597" name="__codelineno-0-1597"></a>    <span class="n">augmented_dynamics</span> <span class="o">=</span> <span class="n">AugDynamics</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">n_tensors</span><span class="p">,</span> <span class="n">func_params</span><span class="p">)</span>
</span><span id="__span-0-1598"><a id="__codelineno-0-1598" name="__codelineno-0-1598"></a>    <span class="n">t_grid_flip</span> <span class="o">=</span> <span class="n">t_grid</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-1599"><a id="__codelineno-0-1599" name="__codelineno-0-1599"></a>
</span><span id="__span-0-1600"><a id="__codelineno-0-1600" name="__codelineno-0-1600"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="__span-0-1601"><a id="__codelineno-0-1601" name="__codelineno-0-1601"></a>        <span class="n">adj_y</span> <span class="o">=</span> <span class="n">grad_output</span>
</span><span id="__span-0-1602"><a id="__codelineno-0-1602" name="__codelineno-0-1602"></a>
</span><span id="__span-0-1603"><a id="__codelineno-0-1603" name="__codelineno-0-1603"></a>        <span class="c1"># 初始化参数梯度</span>
</span><span id="__span-0-1604"><a id="__codelineno-0-1604" name="__codelineno-0-1604"></a>        <span class="k">if</span> <span class="n">func_params</span><span class="p">:</span>
</span><span id="__span-0-1605"><a id="__codelineno-0-1605" name="__codelineno-0-1605"></a>            <span class="n">adj_params</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">func_params</span><span class="p">)</span>
</span><span id="__span-0-1606"><a id="__codelineno-0-1606" name="__codelineno-0-1606"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-1607"><a id="__codelineno-0-1607" name="__codelineno-0-1607"></a>            <span class="n">adj_params</span> <span class="o">=</span> <span class="p">()</span>
</span><span id="__span-0-1608"><a id="__codelineno-0-1608" name="__codelineno-0-1608"></a>
</span><span id="__span-0-1609"><a id="__codelineno-0-1609" name="__codelineno-0-1609"></a>        <span class="c1"># 设置初始增广状态</span>
</span><span id="__span-0-1610"><a id="__codelineno-0-1610" name="__codelineno-0-1610"></a>        <span class="c1"># 注意：yhistory 作为初始 y 状态</span>
</span><span id="__span-0-1611"><a id="__codelineno-0-1611" name="__codelineno-0-1611"></a>        <span class="n">aug_y0</span> <span class="o">=</span> <span class="p">([],</span> <span class="n">adj_y</span><span class="p">,</span> <span class="n">adj_params</span><span class="p">)</span>
</span><span id="__span-0-1612"><a id="__codelineno-0-1612" name="__codelineno-0-1612"></a>
</span><span id="__span-0-1613"><a id="__codelineno-0-1613" name="__codelineno-0-1613"></a>        <span class="c1"># 调用反向求解器</span>
</span><span id="__span-0-1614"><a id="__codelineno-0-1614" name="__codelineno-0-1614"></a>        <span class="n">adj_y</span><span class="p">,</span> <span class="n">adj_params</span> <span class="o">=</span> <span class="n">SOLVERS_Backward</span><span class="p">[</span><span class="n">method</span><span class="p">](</span>
</span><span id="__span-0-1615"><a id="__codelineno-0-1615" name="__codelineno-0-1615"></a>            <span class="n">augmented_dynamics</span><span class="p">,</span>
</span><span id="__span-0-1616"><a id="__codelineno-0-1616" name="__codelineno-0-1616"></a>            <span class="n">aug_y0</span><span class="p">,</span>
</span><span id="__span-0-1617"><a id="__codelineno-0-1617" name="__codelineno-0-1617"></a>            <span class="n">alpha</span><span class="p">,</span>
</span><span id="__span-0-1618"><a id="__codelineno-0-1618" name="__codelineno-0-1618"></a>            <span class="n">t_grid_flip</span><span class="p">,</span>
</span><span id="__span-0-1619"><a id="__codelineno-0-1619" name="__codelineno-0-1619"></a>            <span class="n">yhistory</span><span class="p">,</span>  <span class="c1"># 传递最终状态</span>
</span><span id="__span-0-1620"><a id="__codelineno-0-1620" name="__codelineno-0-1620"></a>            <span class="n">memory</span><span class="p">,</span>
</span><span id="__span-0-1621"><a id="__codelineno-0-1621" name="__codelineno-0-1621"></a>        <span class="p">)</span>
</span><span id="__span-0-1622"><a id="__codelineno-0-1622" name="__codelineno-0-1622"></a>
</span><span id="__span-0-1623"><a id="__codelineno-0-1623" name="__codelineno-0-1623"></a>    <span class="c1"># 清理</span>
</span><span id="__span-0-1624"><a id="__codelineno-0-1624" name="__codelineno-0-1624"></a>    <span class="c1"># del augmented_dynamics</span>
</span><span id="__span-0-1625"><a id="__codelineno-0-1625" name="__codelineno-0-1625"></a>    <span class="c1"># del ctx.yhistory</span>
</span><span id="__span-0-1626"><a id="__codelineno-0-1626" name="__codelineno-0-1626"></a>
</span><span id="__span-0-1627"><a id="__codelineno-0-1627" name="__codelineno-0-1627"></a>    <span class="c1"># 在最后，确保清理所有局部变量</span>
</span><span id="__span-0-1628"><a id="__codelineno-0-1628" name="__codelineno-0-1628"></a>    <span class="k">del</span> <span class="n">augmented_dynamics</span>
</span><span id="__span-0-1629"><a id="__codelineno-0-1629" name="__codelineno-0-1629"></a>    <span class="k">del</span> <span class="n">yhistory</span>  <span class="c1"># 也要删除局部变量</span>
</span><span id="__span-0-1630"><a id="__codelineno-0-1630" name="__codelineno-0-1630"></a>    <span class="k">del</span> <span class="n">func</span>
</span><span id="__span-0-1631"><a id="__codelineno-0-1631" name="__codelineno-0-1631"></a>    <span class="k">del</span> <span class="n">func_params</span>
</span><span id="__span-0-1632"><a id="__codelineno-0-1632" name="__codelineno-0-1632"></a>    <span class="k">del</span> <span class="n">ctx</span><span class="o">.</span><span class="n">yhistory</span>
</span><span id="__span-0-1633"><a id="__codelineno-0-1633" name="__codelineno-0-1633"></a>    <span class="k">del</span> <span class="n">ctx</span><span class="o">.</span><span class="n">ode_func</span>
</span><span id="__span-0-1634"><a id="__codelineno-0-1634" name="__codelineno-0-1634"></a>    <span class="k">del</span> <span class="n">ctx</span><span class="o">.</span><span class="n">func_params</span>
</span><span id="__span-0-1635"><a id="__codelineno-0-1635" name="__codelineno-0-1635"></a>    <span class="k">del</span> <span class="n">ctx</span><span class="o">.</span><span class="n">alpha</span>
</span><span id="__span-0-1636"><a id="__codelineno-0-1636" name="__codelineno-0-1636"></a>    <span class="k">del</span> <span class="n">ctx</span><span class="o">.</span><span class="n">method</span>
</span><span id="__span-0-1637"><a id="__codelineno-0-1637" name="__codelineno-0-1637"></a>
</span><span id="__span-0-1638"><a id="__codelineno-0-1638" name="__codelineno-0-1638"></a>    <span class="c1"># 准备返回值</span>
</span><span id="__span-0-1639"><a id="__codelineno-0-1639" name="__codelineno-0-1639"></a>    <span class="c1"># 返回格式：(grad_func, grad_y0_tuple, grad_alpha, grad_t_grid, grad_method, grad_func_params, grad_memory)</span>
</span><span id="__span-0-1640"><a id="__codelineno-0-1640" name="__codelineno-0-1640"></a>    <span class="n">grad_y0</span> <span class="o">=</span> <span class="n">adj_y</span>
</span><span id="__span-0-1641"><a id="__codelineno-0-1641" name="__codelineno-0-1641"></a>    <span class="n">grad_params</span> <span class="o">=</span> <span class="n">adj_params</span>
</span><span id="__span-0-1642"><a id="__codelineno-0-1642" name="__codelineno-0-1642"></a>
</span><span id="__span-0-1643"><a id="__codelineno-0-1643" name="__codelineno-0-1643"></a>    <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">grad_y0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">grad_params</span><span class="p">,</span> <span class="kc">None</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spikeDE.solver.FDEAdjointMethod.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

</h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ctx</span><span class="p">:</span> <span class="n"><span title="torch.autograd.function.FunctionCtx">FunctionCtx</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">n_state</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">n_params</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Performs the forward integration of the FDE.</p>
<p>Unpacks arguments, selects the appropriate solver based on <code>method</code>, and computes
the state trajectory. Saves necessary context for the backward pass.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ctx</code></b>
              (<code><span title="torch.autograd.function.FunctionCtx">FunctionCtx</span></code>)
          –
          <div class="doc-md-description">
            <p>Context object to save tensors for backward pass.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></code>)
          –
          <div class="doc-md-description">
            <p>The ODE function <span class="arithmatex">\(f(t, y)\)</span>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>n_state</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>Number of state components in <code>y0_tuple</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>n_params</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>Number of learnable parameters in <code>ode_func</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>*args</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></code>, default:
                  <code>()</code>
)
          –
          <div class="doc-md-description">
            <p>Packed arguments containing:</p>
<ul>
<li><code>y0_tuple</code>: Initial states (n_state tensors).</li>
<li><code>alpha</code>: Fractional order.</li>
<li><code>t_grid</code>: Time grid.</li>
<li><code>method</code>: Solver method string.</li>
<li><code>func_params</code>: Model parameters (n_params tensors).</li>
<li><code>memory</code>: Memory truncation limit.</li>
</ul>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]</code>
          –
          <div class="doc-md-description">
            <p>A tuple of tensors representing the final state <span class="arithmatex">\(y(t_{end})\)</span>.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1429">1429</a></span>
<span class="normal"><a href="#__codelineno-0-1430">1430</a></span>
<span class="normal"><a href="#__codelineno-0-1431">1431</a></span>
<span class="normal"><a href="#__codelineno-0-1432">1432</a></span>
<span class="normal"><a href="#__codelineno-0-1433">1433</a></span>
<span class="normal"><a href="#__codelineno-0-1434">1434</a></span>
<span class="normal"><a href="#__codelineno-0-1435">1435</a></span>
<span class="normal"><a href="#__codelineno-0-1436">1436</a></span>
<span class="normal"><a href="#__codelineno-0-1437">1437</a></span>
<span class="normal"><a href="#__codelineno-0-1438">1438</a></span>
<span class="normal"><a href="#__codelineno-0-1439">1439</a></span>
<span class="normal"><a href="#__codelineno-0-1440">1440</a></span>
<span class="normal"><a href="#__codelineno-0-1441">1441</a></span>
<span class="normal"><a href="#__codelineno-0-1442">1442</a></span>
<span class="normal"><a href="#__codelineno-0-1443">1443</a></span>
<span class="normal"><a href="#__codelineno-0-1444">1444</a></span>
<span class="normal"><a href="#__codelineno-0-1445">1445</a></span>
<span class="normal"><a href="#__codelineno-0-1446">1446</a></span>
<span class="normal"><a href="#__codelineno-0-1447">1447</a></span>
<span class="normal"><a href="#__codelineno-0-1448">1448</a></span>
<span class="normal"><a href="#__codelineno-0-1449">1449</a></span>
<span class="normal"><a href="#__codelineno-0-1450">1450</a></span>
<span class="normal"><a href="#__codelineno-0-1451">1451</a></span>
<span class="normal"><a href="#__codelineno-0-1452">1452</a></span>
<span class="normal"><a href="#__codelineno-0-1453">1453</a></span>
<span class="normal"><a href="#__codelineno-0-1454">1454</a></span>
<span class="normal"><a href="#__codelineno-0-1455">1455</a></span>
<span class="normal"><a href="#__codelineno-0-1456">1456</a></span>
<span class="normal"><a href="#__codelineno-0-1457">1457</a></span>
<span class="normal"><a href="#__codelineno-0-1458">1458</a></span>
<span class="normal"><a href="#__codelineno-0-1459">1459</a></span>
<span class="normal"><a href="#__codelineno-0-1460">1460</a></span>
<span class="normal"><a href="#__codelineno-0-1461">1461</a></span>
<span class="normal"><a href="#__codelineno-0-1462">1462</a></span>
<span class="normal"><a href="#__codelineno-0-1463">1463</a></span>
<span class="normal"><a href="#__codelineno-0-1464">1464</a></span>
<span class="normal"><a href="#__codelineno-0-1465">1465</a></span>
<span class="normal"><a href="#__codelineno-0-1466">1466</a></span>
<span class="normal"><a href="#__codelineno-0-1467">1467</a></span>
<span class="normal"><a href="#__codelineno-0-1468">1468</a></span>
<span class="normal"><a href="#__codelineno-0-1469">1469</a></span>
<span class="normal"><a href="#__codelineno-0-1470">1470</a></span>
<span class="normal"><a href="#__codelineno-0-1471">1471</a></span>
<span class="normal"><a href="#__codelineno-0-1472">1472</a></span>
<span class="normal"><a href="#__codelineno-0-1473">1473</a></span>
<span class="normal"><a href="#__codelineno-0-1474">1474</a></span>
<span class="normal"><a href="#__codelineno-0-1475">1475</a></span>
<span class="normal"><a href="#__codelineno-0-1476">1476</a></span>
<span class="normal"><a href="#__codelineno-0-1477">1477</a></span>
<span class="normal"><a href="#__codelineno-0-1478">1478</a></span>
<span class="normal"><a href="#__codelineno-0-1479">1479</a></span>
<span class="normal"><a href="#__codelineno-0-1480">1480</a></span>
<span class="normal"><a href="#__codelineno-0-1481">1481</a></span>
<span class="normal"><a href="#__codelineno-0-1482">1482</a></span>
<span class="normal"><a href="#__codelineno-0-1483">1483</a></span>
<span class="normal"><a href="#__codelineno-0-1484">1484</a></span>
<span class="normal"><a href="#__codelineno-0-1485">1485</a></span>
<span class="normal"><a href="#__codelineno-0-1486">1486</a></span>
<span class="normal"><a href="#__codelineno-0-1487">1487</a></span>
<span class="normal"><a href="#__codelineno-0-1488">1488</a></span>
<span class="normal"><a href="#__codelineno-0-1489">1489</a></span>
<span class="normal"><a href="#__codelineno-0-1490">1490</a></span>
<span class="normal"><a href="#__codelineno-0-1491">1491</a></span>
<span class="normal"><a href="#__codelineno-0-1492">1492</a></span>
<span class="normal"><a href="#__codelineno-0-1493">1493</a></span>
<span class="normal"><a href="#__codelineno-0-1494">1494</a></span>
<span class="normal"><a href="#__codelineno-0-1495">1495</a></span>
<span class="normal"><a href="#__codelineno-0-1496">1496</a></span>
<span class="normal"><a href="#__codelineno-0-1497">1497</a></span>
<span class="normal"><a href="#__codelineno-0-1498">1498</a></span>
<span class="normal"><a href="#__codelineno-0-1499">1499</a></span>
<span class="normal"><a href="#__codelineno-0-1500">1500</a></span>
<span class="normal"><a href="#__codelineno-0-1501">1501</a></span>
<span class="normal"><a href="#__codelineno-0-1502">1502</a></span>
<span class="normal"><a href="#__codelineno-0-1503">1503</a></span>
<span class="normal"><a href="#__codelineno-0-1504">1504</a></span>
<span class="normal"><a href="#__codelineno-0-1505">1505</a></span>
<span class="normal"><a href="#__codelineno-0-1506">1506</a></span>
<span class="normal"><a href="#__codelineno-0-1507">1507</a></span>
<span class="normal"><a href="#__codelineno-0-1508">1508</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1429"><a id="__codelineno-0-1429" name="__codelineno-0-1429"></a><span class="nd">@staticmethod</span>
</span><span id="__span-0-1430"><a id="__codelineno-0-1430" name="__codelineno-0-1430"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-1431"><a id="__codelineno-0-1431" name="__codelineno-0-1431"></a>    <span class="n">ctx</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">FunctionCtx</span><span class="p">,</span>
</span><span id="__span-0-1432"><a id="__codelineno-0-1432" name="__codelineno-0-1432"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
</span><span id="__span-0-1433"><a id="__codelineno-0-1433" name="__codelineno-0-1433"></a>    <span class="n">n_state</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-1434"><a id="__codelineno-0-1434" name="__codelineno-0-1434"></a>    <span class="n">n_params</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-1435"><a id="__codelineno-0-1435" name="__codelineno-0-1435"></a>    <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span id="__span-0-1436"><a id="__codelineno-0-1436" name="__codelineno-0-1436"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
</span><span id="__span-0-1437"><a id="__codelineno-0-1437" name="__codelineno-0-1437"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-1438"><a id="__codelineno-0-1438" name="__codelineno-0-1438"></a><span class="sd">    Performs the forward integration of the FDE.</span>
</span><span id="__span-0-1439"><a id="__codelineno-0-1439" name="__codelineno-0-1439"></a>
</span><span id="__span-0-1440"><a id="__codelineno-0-1440" name="__codelineno-0-1440"></a><span class="sd">    Unpacks arguments, selects the appropriate solver based on `method`, and computes</span>
</span><span id="__span-0-1441"><a id="__codelineno-0-1441" name="__codelineno-0-1441"></a><span class="sd">    the state trajectory. Saves necessary context for the backward pass.</span>
</span><span id="__span-0-1442"><a id="__codelineno-0-1442" name="__codelineno-0-1442"></a>
</span><span id="__span-0-1443"><a id="__codelineno-0-1443" name="__codelineno-0-1443"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1444"><a id="__codelineno-0-1444" name="__codelineno-0-1444"></a><span class="sd">        ctx: Context object to save tensors for backward pass.</span>
</span><span id="__span-0-1445"><a id="__codelineno-0-1445" name="__codelineno-0-1445"></a><span class="sd">        ode_func: The ODE function $f(t, y)$.</span>
</span><span id="__span-0-1446"><a id="__codelineno-0-1446" name="__codelineno-0-1446"></a><span class="sd">        n_state: Number of state components in `y0_tuple`.</span>
</span><span id="__span-0-1447"><a id="__codelineno-0-1447" name="__codelineno-0-1447"></a><span class="sd">        n_params: Number of learnable parameters in `ode_func`.</span>
</span><span id="__span-0-1448"><a id="__codelineno-0-1448" name="__codelineno-0-1448"></a><span class="sd">        *args: Packed arguments containing:</span>
</span><span id="__span-0-1449"><a id="__codelineno-0-1449" name="__codelineno-0-1449"></a>
</span><span id="__span-0-1450"><a id="__codelineno-0-1450" name="__codelineno-0-1450"></a><span class="sd">            - `y0_tuple`: Initial states (n_state tensors).</span>
</span><span id="__span-0-1451"><a id="__codelineno-0-1451" name="__codelineno-0-1451"></a><span class="sd">            - `alpha`: Fractional order.</span>
</span><span id="__span-0-1452"><a id="__codelineno-0-1452" name="__codelineno-0-1452"></a><span class="sd">            - `t_grid`: Time grid.</span>
</span><span id="__span-0-1453"><a id="__codelineno-0-1453" name="__codelineno-0-1453"></a><span class="sd">            - `method`: Solver method string.</span>
</span><span id="__span-0-1454"><a id="__codelineno-0-1454" name="__codelineno-0-1454"></a><span class="sd">            - `func_params`: Model parameters (n_params tensors).</span>
</span><span id="__span-0-1455"><a id="__codelineno-0-1455" name="__codelineno-0-1455"></a><span class="sd">            - `memory`: Memory truncation limit.</span>
</span><span id="__span-0-1456"><a id="__codelineno-0-1456" name="__codelineno-0-1456"></a>
</span><span id="__span-0-1457"><a id="__codelineno-0-1457" name="__codelineno-0-1457"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1458"><a id="__codelineno-0-1458" name="__codelineno-0-1458"></a><span class="sd">        A tuple of tensors representing the final state $y(t_{end})$.</span>
</span><span id="__span-0-1459"><a id="__codelineno-0-1459" name="__codelineno-0-1459"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-1460"><a id="__codelineno-0-1460" name="__codelineno-0-1460"></a>    <span class="n">n_state</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_state</span><span class="p">)</span>
</span><span id="__span-0-1461"><a id="__codelineno-0-1461" name="__codelineno-0-1461"></a>    <span class="n">n_params</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_params</span><span class="p">)</span>
</span><span id="__span-0-1462"><a id="__codelineno-0-1462" name="__codelineno-0-1462"></a>
</span><span id="__span-0-1463"><a id="__codelineno-0-1463" name="__codelineno-0-1463"></a>    <span class="c1"># 解析位置参数： y0_1,...,y0_n, alpha, t_grid, method, p1,...,pm, memory</span>
</span><span id="__span-0-1464"><a id="__codelineno-0-1464" name="__codelineno-0-1464"></a>    <span class="n">y0_tuple</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">args</span><span class="p">[:</span><span class="n">n_state</span><span class="p">])</span>  <span class="c1"># Tensors</span>
</span><span id="__span-0-1465"><a id="__codelineno-0-1465" name="__codelineno-0-1465"></a>    <span class="n">alpha</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="n">n_state</span><span class="p">]</span>  <span class="c1"># Tensor 或 float（若要学习，必须是 Tensor）</span>
</span><span id="__span-0-1466"><a id="__codelineno-0-1466" name="__codelineno-0-1466"></a>    <span class="n">t_grid</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="n">n_state</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Tensor</span>
</span><span id="__span-0-1467"><a id="__codelineno-0-1467" name="__codelineno-0-1467"></a>    <span class="n">method</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="n">n_state</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]</span>  <span class="c1"># str / enum（非 Tensor）</span>
</span><span id="__span-0-1468"><a id="__codelineno-0-1468" name="__codelineno-0-1468"></a>    <span class="n">func_params</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
</span><span id="__span-0-1469"><a id="__codelineno-0-1469" name="__codelineno-0-1469"></a>        <span class="n">args</span><span class="p">[</span><span class="n">n_state</span> <span class="o">+</span> <span class="mi">3</span> <span class="p">:</span> <span class="n">n_state</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">+</span> <span class="n">n_params</span><span class="p">]</span>
</span><span id="__span-0-1470"><a id="__codelineno-0-1470" name="__codelineno-0-1470"></a>    <span class="p">)</span>  <span class="c1"># Tensors (Parameters)</span>
</span><span id="__span-0-1471"><a id="__codelineno-0-1471" name="__codelineno-0-1471"></a>    <span class="n">memory</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="n">n_state</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">+</span> <span class="n">n_params</span><span class="p">]</span>  <span class="c1"># 任意对象（非 Tensor）</span>
</span><span id="__span-0-1472"><a id="__codelineno-0-1472" name="__codelineno-0-1472"></a>
</span><span id="__span-0-1473"><a id="__codelineno-0-1473" name="__codelineno-0-1473"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="__span-0-1474"><a id="__codelineno-0-1474" name="__codelineno-0-1474"></a>        <span class="n">yhistory</span> <span class="o">=</span> <span class="n">SOLVERS_Forward</span><span class="p">[</span><span class="n">method</span><span class="p">](</span>
</span><span id="__span-0-1475"><a id="__codelineno-0-1475" name="__codelineno-0-1475"></a>            <span class="n">ode_func</span><span class="o">=</span><span class="n">ode_func</span><span class="p">,</span>
</span><span id="__span-0-1476"><a id="__codelineno-0-1476" name="__codelineno-0-1476"></a>            <span class="n">y0_tuple</span><span class="o">=</span><span class="n">y0_tuple</span><span class="p">,</span>
</span><span id="__span-0-1477"><a id="__codelineno-0-1477" name="__codelineno-0-1477"></a>            <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
</span><span id="__span-0-1478"><a id="__codelineno-0-1478" name="__codelineno-0-1478"></a>            <span class="n">t_grid</span><span class="o">=</span><span class="n">t_grid</span><span class="p">,</span>
</span><span id="__span-0-1479"><a id="__codelineno-0-1479" name="__codelineno-0-1479"></a>            <span class="n">memory</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span>
</span><span id="__span-0-1480"><a id="__codelineno-0-1480" name="__codelineno-0-1480"></a>        <span class="p">)</span>
</span><span id="__span-0-1481"><a id="__codelineno-0-1481" name="__codelineno-0-1481"></a>
</span><span id="__span-0-1482"><a id="__codelineno-0-1482" name="__codelineno-0-1482"></a>    <span class="c1"># 检查是否需要梯度</span>
</span><span id="__span-0-1483"><a id="__codelineno-0-1483" name="__codelineno-0-1483"></a>    <span class="n">y0_needs_grad</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">requires_grad</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">y0_tuple</span><span class="p">)</span>
</span><span id="__span-0-1484"><a id="__codelineno-0-1484" name="__codelineno-0-1484"></a>    <span class="n">params_need_grad</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-1485"><a id="__codelineno-0-1485" name="__codelineno-0-1485"></a>        <span class="nb">any</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">func_params</span><span class="p">)</span> <span class="k">if</span> <span class="n">func_params</span> <span class="k">else</span> <span class="kc">False</span>
</span><span id="__span-0-1486"><a id="__codelineno-0-1486" name="__codelineno-0-1486"></a>    <span class="p">)</span>
</span><span id="__span-0-1487"><a id="__codelineno-0-1487" name="__codelineno-0-1487"></a>
</span><span id="__span-0-1488"><a id="__codelineno-0-1488" name="__codelineno-0-1488"></a>    <span class="n">ctx</span><span class="o">.</span><span class="n">n_state</span> <span class="o">=</span> <span class="n">n_state</span>
</span><span id="__span-0-1489"><a id="__codelineno-0-1489" name="__codelineno-0-1489"></a>    <span class="n">ctx</span><span class="o">.</span><span class="n">n_params</span> <span class="o">=</span> <span class="n">n_params</span>
</span><span id="__span-0-1490"><a id="__codelineno-0-1490" name="__codelineno-0-1490"></a>    <span class="k">if</span> <span class="n">y0_needs_grad</span> <span class="ow">or</span> <span class="n">params_need_grad</span><span class="p">:</span>
</span><span id="__span-0-1491"><a id="__codelineno-0-1491" name="__codelineno-0-1491"></a>        <span class="c1"># 保存必要的张量用于反向传播</span>
</span><span id="__span-0-1492"><a id="__codelineno-0-1492" name="__codelineno-0-1492"></a>        <span class="c1"># 注意：保存整个 tuple 对象，而不是展开的张量</span>
</span><span id="__span-0-1493"><a id="__codelineno-0-1493" name="__codelineno-0-1493"></a>        <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_backward</span><span class="p">(</span><span class="n">t_grid</span><span class="p">)</span>
</span><span id="__span-0-1494"><a id="__codelineno-0-1494" name="__codelineno-0-1494"></a>        <span class="n">ctx</span><span class="o">.</span><span class="n">func_params</span> <span class="o">=</span> <span class="n">func_params</span>  <span class="c1"># 同样保存为属性</span>
</span><span id="__span-0-1495"><a id="__codelineno-0-1495" name="__codelineno-0-1495"></a>        <span class="n">ctx</span><span class="o">.</span><span class="n">yhistory</span> <span class="o">=</span> <span class="n">yhistory</span>  <span class="c1"># 保存最终状态</span>
</span><span id="__span-0-1496"><a id="__codelineno-0-1496" name="__codelineno-0-1496"></a>        <span class="n">ctx</span><span class="o">.</span><span class="n">ode_func</span> <span class="o">=</span> <span class="n">ode_func</span>
</span><span id="__span-0-1497"><a id="__codelineno-0-1497" name="__codelineno-0-1497"></a>        <span class="n">ctx</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
</span><span id="__span-0-1498"><a id="__codelineno-0-1498" name="__codelineno-0-1498"></a>        <span class="n">ctx</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
</span><span id="__span-0-1499"><a id="__codelineno-0-1499" name="__codelineno-0-1499"></a>        <span class="n">ctx</span><span class="o">.</span><span class="n">memory</span> <span class="o">=</span> <span class="n">memory</span>
</span><span id="__span-0-1500"><a id="__codelineno-0-1500" name="__codelineno-0-1500"></a>
</span><span id="__span-0-1501"><a id="__codelineno-0-1501" name="__codelineno-0-1501"></a>    <span class="c1"># 返回结果</span>
</span><span id="__span-0-1502"><a id="__codelineno-0-1502" name="__codelineno-0-1502"></a>    <span class="c1"># if method == &#39;euler&#39;:</span>
</span><span id="__span-0-1503"><a id="__codelineno-0-1503" name="__codelineno-0-1503"></a>    <span class="c1">#     outs = tuple(yhistory)</span>
</span><span id="__span-0-1504"><a id="__codelineno-0-1504" name="__codelineno-0-1504"></a>    <span class="c1"># else:</span>
</span><span id="__span-0-1505"><a id="__codelineno-0-1505" name="__codelineno-0-1505"></a>    <span class="c1">#     # 如果 yhistory 是嵌套列表，取最后一个</span>
</span><span id="__span-0-1506"><a id="__codelineno-0-1506" name="__codelineno-0-1506"></a>    <span class="n">outs</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">y</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">yhistory</span><span class="p">])</span>
</span><span id="__span-0-1507"><a id="__codelineno-0-1507" name="__codelineno-0-1507"></a>
</span><span id="__span-0-1508"><a id="__codelineno-0-1508" name="__codelineno-0-1508"></a>    <span class="k">return</span> <span class="n">outs</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.snn_solve" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">snn_solve</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">snn_solve</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">[[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Tuple" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">per_layer_alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">],</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">method</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            SNNFractionalMethod (spikeDE.solver.SNNFractionalMethod)" href="#spikeDE.solver.SNNFractionalMethod">SNNFractionalMethod</a></span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">per_layer_coefficient</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Unified driver function for solving SNN fractional differential equations.</p>
<p>Orchestrates the time-stepping loop, managing state history, memory truncation,
and dispatching to the specific numerical method provided.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a>[[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, <a class="autorefs autorefs-external" title="typing.Tuple" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a>], <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>]</code>)
          –
          <div class="doc-md-description">
            <p>Function <code>f(t, y_tuple)</code> returning derivatives.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y0_tuple</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]</code>)
          –
          <div class="doc-md-description">
            <p>Initial state tuple.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>per_layer_alpha</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a>]</code>)
          –
          <div class="doc-md-description">
            <p>List of fractional orders per layer.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Time points tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>method</code></b>
              (<code><a class="autorefs autorefs-internal" title="            SNNFractionalMethod (spikeDE.solver.SNNFractionalMethod)" href="#spikeDE.solver.SNNFractionalMethod">SNNFractionalMethod</a></code>)
          –
          <div class="doc-md-description">
            <p>Instance of <code>SNNFractionalMethod</code> (e.g., <code>GrunwaldLetnikovSNN</code>).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Optional integer to limit history length for convolution.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>per_layer_coefficient</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a> | None] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Coefficients for multi-term layers.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>
          –
          <div class="doc-md-description">
            <p>List of lists containing the trajectory of each state component.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-895">895</a></span>
<span class="normal"><a href="#__codelineno-0-896">896</a></span>
<span class="normal"><a href="#__codelineno-0-897">897</a></span>
<span class="normal"><a href="#__codelineno-0-898">898</a></span>
<span class="normal"><a href="#__codelineno-0-899">899</a></span>
<span class="normal"><a href="#__codelineno-0-900">900</a></span>
<span class="normal"><a href="#__codelineno-0-901">901</a></span>
<span class="normal"><a href="#__codelineno-0-902">902</a></span>
<span class="normal"><a href="#__codelineno-0-903">903</a></span>
<span class="normal"><a href="#__codelineno-0-904">904</a></span>
<span class="normal"><a href="#__codelineno-0-905">905</a></span>
<span class="normal"><a href="#__codelineno-0-906">906</a></span>
<span class="normal"><a href="#__codelineno-0-907">907</a></span>
<span class="normal"><a href="#__codelineno-0-908">908</a></span>
<span class="normal"><a href="#__codelineno-0-909">909</a></span>
<span class="normal"><a href="#__codelineno-0-910">910</a></span>
<span class="normal"><a href="#__codelineno-0-911">911</a></span>
<span class="normal"><a href="#__codelineno-0-912">912</a></span>
<span class="normal"><a href="#__codelineno-0-913">913</a></span>
<span class="normal"><a href="#__codelineno-0-914">914</a></span>
<span class="normal"><a href="#__codelineno-0-915">915</a></span>
<span class="normal"><a href="#__codelineno-0-916">916</a></span>
<span class="normal"><a href="#__codelineno-0-917">917</a></span>
<span class="normal"><a href="#__codelineno-0-918">918</a></span>
<span class="normal"><a href="#__codelineno-0-919">919</a></span>
<span class="normal"><a href="#__codelineno-0-920">920</a></span>
<span class="normal"><a href="#__codelineno-0-921">921</a></span>
<span class="normal"><a href="#__codelineno-0-922">922</a></span>
<span class="normal"><a href="#__codelineno-0-923">923</a></span>
<span class="normal"><a href="#__codelineno-0-924">924</a></span>
<span class="normal"><a href="#__codelineno-0-925">925</a></span>
<span class="normal"><a href="#__codelineno-0-926">926</a></span>
<span class="normal"><a href="#__codelineno-0-927">927</a></span>
<span class="normal"><a href="#__codelineno-0-928">928</a></span>
<span class="normal"><a href="#__codelineno-0-929">929</a></span>
<span class="normal"><a href="#__codelineno-0-930">930</a></span>
<span class="normal"><a href="#__codelineno-0-931">931</a></span>
<span class="normal"><a href="#__codelineno-0-932">932</a></span>
<span class="normal"><a href="#__codelineno-0-933">933</a></span>
<span class="normal"><a href="#__codelineno-0-934">934</a></span>
<span class="normal"><a href="#__codelineno-0-935">935</a></span>
<span class="normal"><a href="#__codelineno-0-936">936</a></span>
<span class="normal"><a href="#__codelineno-0-937">937</a></span>
<span class="normal"><a href="#__codelineno-0-938">938</a></span>
<span class="normal"><a href="#__codelineno-0-939">939</a></span>
<span class="normal"><a href="#__codelineno-0-940">940</a></span>
<span class="normal"><a href="#__codelineno-0-941">941</a></span>
<span class="normal"><a href="#__codelineno-0-942">942</a></span>
<span class="normal"><a href="#__codelineno-0-943">943</a></span>
<span class="normal"><a href="#__codelineno-0-944">944</a></span>
<span class="normal"><a href="#__codelineno-0-945">945</a></span>
<span class="normal"><a href="#__codelineno-0-946">946</a></span>
<span class="normal"><a href="#__codelineno-0-947">947</a></span>
<span class="normal"><a href="#__codelineno-0-948">948</a></span>
<span class="normal"><a href="#__codelineno-0-949">949</a></span>
<span class="normal"><a href="#__codelineno-0-950">950</a></span>
<span class="normal"><a href="#__codelineno-0-951">951</a></span>
<span class="normal"><a href="#__codelineno-0-952">952</a></span>
<span class="normal"><a href="#__codelineno-0-953">953</a></span>
<span class="normal"><a href="#__codelineno-0-954">954</a></span>
<span class="normal"><a href="#__codelineno-0-955">955</a></span>
<span class="normal"><a href="#__codelineno-0-956">956</a></span>
<span class="normal"><a href="#__codelineno-0-957">957</a></span>
<span class="normal"><a href="#__codelineno-0-958">958</a></span>
<span class="normal"><a href="#__codelineno-0-959">959</a></span>
<span class="normal"><a href="#__codelineno-0-960">960</a></span>
<span class="normal"><a href="#__codelineno-0-961">961</a></span>
<span class="normal"><a href="#__codelineno-0-962">962</a></span>
<span class="normal"><a href="#__codelineno-0-963">963</a></span>
<span class="normal"><a href="#__codelineno-0-964">964</a></span>
<span class="normal"><a href="#__codelineno-0-965">965</a></span>
<span class="normal"><a href="#__codelineno-0-966">966</a></span>
<span class="normal"><a href="#__codelineno-0-967">967</a></span>
<span class="normal"><a href="#__codelineno-0-968">968</a></span>
<span class="normal"><a href="#__codelineno-0-969">969</a></span>
<span class="normal"><a href="#__codelineno-0-970">970</a></span>
<span class="normal"><a href="#__codelineno-0-971">971</a></span>
<span class="normal"><a href="#__codelineno-0-972">972</a></span>
<span class="normal"><a href="#__codelineno-0-973">973</a></span>
<span class="normal"><a href="#__codelineno-0-974">974</a></span>
<span class="normal"><a href="#__codelineno-0-975">975</a></span>
<span class="normal"><a href="#__codelineno-0-976">976</a></span>
<span class="normal"><a href="#__codelineno-0-977">977</a></span>
<span class="normal"><a href="#__codelineno-0-978">978</a></span>
<span class="normal"><a href="#__codelineno-0-979">979</a></span>
<span class="normal"><a href="#__codelineno-0-980">980</a></span>
<span class="normal"><a href="#__codelineno-0-981">981</a></span>
<span class="normal"><a href="#__codelineno-0-982">982</a></span>
<span class="normal"><a href="#__codelineno-0-983">983</a></span>
<span class="normal"><a href="#__codelineno-0-984">984</a></span>
<span class="normal"><a href="#__codelineno-0-985">985</a></span>
<span class="normal"><a href="#__codelineno-0-986">986</a></span>
<span class="normal"><a href="#__codelineno-0-987">987</a></span>
<span class="normal"><a href="#__codelineno-0-988">988</a></span>
<span class="normal"><a href="#__codelineno-0-989">989</a></span>
<span class="normal"><a href="#__codelineno-0-990">990</a></span>
<span class="normal"><a href="#__codelineno-0-991">991</a></span>
<span class="normal"><a href="#__codelineno-0-992">992</a></span>
<span class="normal"><a href="#__codelineno-0-993">993</a></span>
<span class="normal"><a href="#__codelineno-0-994">994</a></span>
<span class="normal"><a href="#__codelineno-0-995">995</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-895"><a id="__codelineno-0-895" name="__codelineno-0-895"></a><span class="k">def</span><span class="w"> </span><span class="nf">snn_solve</span><span class="p">(</span>
</span><span id="__span-0-896"><a id="__codelineno-0-896" name="__codelineno-0-896"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">],</span>
</span><span id="__span-0-897"><a id="__codelineno-0-897" name="__codelineno-0-897"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-898"><a id="__codelineno-0-898" name="__codelineno-0-898"></a>    <span class="n">per_layer_alpha</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
</span><span id="__span-0-899"><a id="__codelineno-0-899" name="__codelineno-0-899"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-900"><a id="__codelineno-0-900" name="__codelineno-0-900"></a>    <span class="n">method</span><span class="p">:</span> <span class="n">SNNFractionalMethod</span><span class="p">,</span>
</span><span id="__span-0-901"><a id="__codelineno-0-901" name="__codelineno-0-901"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-902"><a id="__codelineno-0-902" name="__codelineno-0-902"></a>    <span class="n">per_layer_coefficient</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-903"><a id="__codelineno-0-903" name="__codelineno-0-903"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="__span-0-904"><a id="__codelineno-0-904" name="__codelineno-0-904"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-905"><a id="__codelineno-0-905" name="__codelineno-0-905"></a><span class="sd">    Unified driver function for solving SNN fractional differential equations.</span>
</span><span id="__span-0-906"><a id="__codelineno-0-906" name="__codelineno-0-906"></a>
</span><span id="__span-0-907"><a id="__codelineno-0-907" name="__codelineno-0-907"></a><span class="sd">    Orchestrates the time-stepping loop, managing state history, memory truncation,</span>
</span><span id="__span-0-908"><a id="__codelineno-0-908" name="__codelineno-0-908"></a><span class="sd">    and dispatching to the specific numerical method provided.</span>
</span><span id="__span-0-909"><a id="__codelineno-0-909" name="__codelineno-0-909"></a>
</span><span id="__span-0-910"><a id="__codelineno-0-910" name="__codelineno-0-910"></a><span class="sd">    Args:</span>
</span><span id="__span-0-911"><a id="__codelineno-0-911" name="__codelineno-0-911"></a><span class="sd">        ode_func: Function `f(t, y_tuple)` returning derivatives.</span>
</span><span id="__span-0-912"><a id="__codelineno-0-912" name="__codelineno-0-912"></a><span class="sd">        y0_tuple: Initial state tuple.</span>
</span><span id="__span-0-913"><a id="__codelineno-0-913" name="__codelineno-0-913"></a><span class="sd">        per_layer_alpha: List of fractional orders per layer.</span>
</span><span id="__span-0-914"><a id="__codelineno-0-914" name="__codelineno-0-914"></a><span class="sd">        t_grid: Time points tensor.</span>
</span><span id="__span-0-915"><a id="__codelineno-0-915" name="__codelineno-0-915"></a><span class="sd">        method: Instance of `SNNFractionalMethod` (e.g., `GrunwaldLetnikovSNN`).</span>
</span><span id="__span-0-916"><a id="__codelineno-0-916" name="__codelineno-0-916"></a><span class="sd">        memory: Optional integer to limit history length for convolution.</span>
</span><span id="__span-0-917"><a id="__codelineno-0-917" name="__codelineno-0-917"></a><span class="sd">        per_layer_coefficient: Coefficients for multi-term layers.</span>
</span><span id="__span-0-918"><a id="__codelineno-0-918" name="__codelineno-0-918"></a>
</span><span id="__span-0-919"><a id="__codelineno-0-919" name="__codelineno-0-919"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-920"><a id="__codelineno-0-920" name="__codelineno-0-920"></a><span class="sd">        List of lists containing the trajectory of each state component.</span>
</span><span id="__span-0-921"><a id="__codelineno-0-921" name="__codelineno-0-921"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-922"><a id="__codelineno-0-922" name="__codelineno-0-922"></a>    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">),</span> <span class="s2">&quot;y0_tuple must be a tuple&quot;</span>
</span><span id="__span-0-923"><a id="__codelineno-0-923" name="__codelineno-0-923"></a>
</span><span id="__span-0-924"><a id="__codelineno-0-924" name="__codelineno-0-924"></a>    <span class="c1"># Create configuration with per-layer alpha</span>
</span><span id="__span-0-925"><a id="__codelineno-0-925" name="__codelineno-0-925"></a>    <span class="n">config</span> <span class="o">=</span> <span class="n">SNNSolverConfig</span><span class="o">.</span><span class="n">from_inputs</span><span class="p">(</span>
</span><span id="__span-0-926"><a id="__codelineno-0-926" name="__codelineno-0-926"></a>        <span class="n">y0_tuple</span><span class="p">,</span> <span class="n">per_layer_alpha</span><span class="p">,</span> <span class="n">t_grid</span><span class="p">,</span> <span class="n">per_layer_coefficient</span>
</span><span id="__span-0-927"><a id="__codelineno-0-927" name="__codelineno-0-927"></a>    <span class="p">)</span>
</span><span id="__span-0-928"><a id="__codelineno-0-928" name="__codelineno-0-928"></a>
</span><span id="__span-0-929"><a id="__codelineno-0-929" name="__codelineno-0-929"></a>    <span class="c1"># Move t_grid to correct device/dtype</span>
</span><span id="__span-0-930"><a id="__codelineno-0-930" name="__codelineno-0-930"></a>    <span class="n">t_grid</span> <span class="o">=</span> <span class="n">t_grid</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-931"><a id="__codelineno-0-931" name="__codelineno-0-931"></a>
</span><span id="__span-0-932"><a id="__codelineno-0-932" name="__codelineno-0-932"></a>    <span class="c1"># Initialize method</span>
</span><span id="__span-0-933"><a id="__codelineno-0-933" name="__codelineno-0-933"></a>    <span class="n">method</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="__span-0-934"><a id="__codelineno-0-934" name="__codelineno-0-934"></a>
</span><span id="__span-0-935"><a id="__codelineno-0-935" name="__codelineno-0-935"></a>    <span class="c1"># Initialize state</span>
</span><span id="__span-0-936"><a id="__codelineno-0-936" name="__codelineno-0-936"></a>    <span class="n">y_current</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">)</span>
</span><span id="__span-0-937"><a id="__codelineno-0-937" name="__codelineno-0-937"></a>
</span><span id="__span-0-938"><a id="__codelineno-0-938" name="__codelineno-0-938"></a>    <span class="c1"># History</span>
</span><span id="__span-0-939"><a id="__codelineno-0-939" name="__codelineno-0-939"></a>    <span class="n">y_history</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">y0_tuple</span><span class="p">]</span>
</span><span id="__span-0-940"><a id="__codelineno-0-940" name="__codelineno-0-940"></a>
</span><span id="__span-0-941"><a id="__codelineno-0-941" name="__codelineno-0-941"></a>    <span class="c1"># For predictor method, we need f-history</span>
</span><span id="__span-0-942"><a id="__codelineno-0-942" name="__codelineno-0-942"></a>    <span class="k">if</span> <span class="n">method</span><span class="o">.</span><span class="n">stores_f_history</span><span class="p">:</span>
</span><span id="__span-0-943"><a id="__codelineno-0-943" name="__codelineno-0-943"></a>        <span class="n">fhistory</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_integrate</span><span class="p">)]</span>
</span><span id="__span-0-944"><a id="__codelineno-0-944" name="__codelineno-0-944"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-945"><a id="__codelineno-0-945" name="__codelineno-0-945"></a>        <span class="n">fhistory</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-946"><a id="__codelineno-0-946" name="__codelineno-0-946"></a>
</span><span id="__span-0-947"><a id="__codelineno-0-947" name="__codelineno-0-947"></a>    <span class="c1"># Main loop</span>
</span><span id="__span-0-948"><a id="__codelineno-0-948" name="__codelineno-0-948"></a>    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-949"><a id="__codelineno-0-949" name="__codelineno-0-949"></a>        <span class="n">t_k</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
</span><span id="__span-0-950"><a id="__codelineno-0-950" name="__codelineno-0-950"></a>
</span><span id="__span-0-951"><a id="__codelineno-0-951" name="__codelineno-0-951"></a>        <span class="c1"># Evaluate f(t_k, y_k)</span>
</span><span id="__span-0-952"><a id="__codelineno-0-952" name="__codelineno-0-952"></a>        <span class="n">f_k</span> <span class="o">=</span> <span class="n">ode_func</span><span class="p">(</span><span class="n">t_k</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">y_current</span><span class="p">))</span>
</span><span id="__span-0-953"><a id="__codelineno-0-953" name="__codelineno-0-953"></a>
</span><span id="__span-0-954"><a id="__codelineno-0-954" name="__codelineno-0-954"></a>        <span class="c1"># Store function evaluations if needed</span>
</span><span id="__span-0-955"><a id="__codelineno-0-955" name="__codelineno-0-955"></a>        <span class="k">if</span> <span class="n">method</span><span class="o">.</span><span class="n">stores_f_history</span><span class="p">:</span>
</span><span id="__span-0-956"><a id="__codelineno-0-956" name="__codelineno-0-956"></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_integrate</span><span class="p">):</span>
</span><span id="__span-0-957"><a id="__codelineno-0-957" name="__codelineno-0-957"></a>                <span class="n">fhistory</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f_k</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="__span-0-958"><a id="__codelineno-0-958" name="__codelineno-0-958"></a>
</span><span id="__span-0-959"><a id="__codelineno-0-959" name="__codelineno-0-959"></a>        <span class="c1"># Determine memory range</span>
</span><span id="__span-0-960"><a id="__codelineno-0-960" name="__codelineno-0-960"></a>        <span class="n">start_idx</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_memory_bounds</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">memory</span><span class="p">)</span>
</span><span id="__span-0-961"><a id="__codelineno-0-961" name="__codelineno-0-961"></a>
</span><span id="__span-0-962"><a id="__codelineno-0-962" name="__codelineno-0-962"></a>        <span class="c1"># Update each integrated component with its own alpha</span>
</span><span id="__span-0-963"><a id="__codelineno-0-963" name="__codelineno-0-963"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_integrate</span><span class="p">):</span>
</span><span id="__span-0-964"><a id="__codelineno-0-964" name="__codelineno-0-964"></a>            <span class="c1"># Compute weights for this specific layer</span>
</span><span id="__span-0-965"><a id="__codelineno-0-965" name="__codelineno-0-965"></a>            <span class="n">weights</span> <span class="o">=</span> <span class="n">method</span><span class="o">.</span><span class="n">compute_weights_for_layer</span><span class="p">(</span>
</span><span id="__span-0-966"><a id="__codelineno-0-966" name="__codelineno-0-966"></a>                <span class="n">k</span><span class="p">,</span> <span class="n">start_idx</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">layer_idx</span><span class="o">=</span><span class="n">i</span>
</span><span id="__span-0-967"><a id="__codelineno-0-967" name="__codelineno-0-967"></a>            <span class="p">)</span>
</span><span id="__span-0-968"><a id="__codelineno-0-968" name="__codelineno-0-968"></a>
</span><span id="__span-0-969"><a id="__codelineno-0-969" name="__codelineno-0-969"></a>            <span class="c1"># Get appropriate history</span>
</span><span id="__span-0-970"><a id="__codelineno-0-970" name="__codelineno-0-970"></a>            <span class="n">history_i</span> <span class="o">=</span> <span class="n">fhistory</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">method</span><span class="o">.</span><span class="n">stores_f_history</span> <span class="k">else</span> <span class="n">y_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="__span-0-971"><a id="__codelineno-0-971" name="__codelineno-0-971"></a>
</span><span id="__span-0-972"><a id="__codelineno-0-972" name="__codelineno-0-972"></a>            <span class="c1"># Compute convolution sum</span>
</span><span id="__span-0-973"><a id="__codelineno-0-973" name="__codelineno-0-973"></a>            <span class="n">convolution_sum</span> <span class="o">=</span> <span class="n">method</span><span class="o">.</span><span class="n">compute_convolution</span><span class="p">(</span>
</span><span id="__span-0-974"><a id="__codelineno-0-974" name="__codelineno-0-974"></a>                <span class="n">k</span><span class="p">,</span> <span class="n">start_idx</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">history_i</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">layer_idx</span><span class="o">=</span><span class="n">i</span>
</span><span id="__span-0-975"><a id="__codelineno-0-975" name="__codelineno-0-975"></a>            <span class="p">)</span>
</span><span id="__span-0-976"><a id="__codelineno-0-976" name="__codelineno-0-976"></a>
</span><span id="__span-0-977"><a id="__codelineno-0-977" name="__codelineno-0-977"></a>            <span class="c1"># Compute update for this layer</span>
</span><span id="__span-0-978"><a id="__codelineno-0-978" name="__codelineno-0-978"></a>            <span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">method</span><span class="o">.</span><span class="n">compute_update_for_layer</span><span class="p">(</span>
</span><span id="__span-0-979"><a id="__codelineno-0-979" name="__codelineno-0-979"></a>                <span class="n">f_k</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">convolution_sum</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">layer_idx</span><span class="o">=</span><span class="n">i</span>
</span><span id="__span-0-980"><a id="__codelineno-0-980" name="__codelineno-0-980"></a>            <span class="p">)</span>
</span><span id="__span-0-981"><a id="__codelineno-0-981" name="__codelineno-0-981"></a>
</span><span id="__span-0-982"><a id="__codelineno-0-982" name="__codelineno-0-982"></a>            <span class="c1"># Store in history</span>
</span><span id="__span-0-983"><a id="__codelineno-0-983" name="__codelineno-0-983"></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">method</span><span class="o">.</span><span class="n">stores_f_history</span><span class="p">:</span>
</span><span id="__span-0-984"><a id="__codelineno-0-984" name="__codelineno-0-984"></a>                <span class="n">y_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="__span-0-985"><a id="__codelineno-0-985" name="__codelineno-0-985"></a>
</span><span id="__span-0-986"><a id="__codelineno-0-986" name="__codelineno-0-986"></a>        <span class="c1"># Pass-through boundary output e.g. the final spike output</span>
</span><span id="__span-0-987"><a id="__codelineno-0-987" name="__codelineno-0-987"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_integrate</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">n_components</span><span class="p">):</span>
</span><span id="__span-0-988"><a id="__codelineno-0-988" name="__codelineno-0-988"></a>            <span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">f_k</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="__span-0-989"><a id="__codelineno-0-989" name="__codelineno-0-989"></a>            <span class="n">y_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="__span-0-990"><a id="__codelineno-0-990" name="__codelineno-0-990"></a>
</span><span id="__span-0-991"><a id="__codelineno-0-991" name="__codelineno-0-991"></a>    <span class="c1"># Cleanup</span>
</span><span id="__span-0-992"><a id="__codelineno-0-992" name="__codelineno-0-992"></a>    <span class="k">if</span> <span class="n">fhistory</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-993"><a id="__codelineno-0-993" name="__codelineno-0-993"></a>        <span class="k">del</span> <span class="n">fhistory</span>
</span><span id="__span-0-994"><a id="__codelineno-0-994" name="__codelineno-0-994"></a>
</span><span id="__span-0-995"><a id="__codelineno-0-995" name="__codelineno-0-995"></a>    <span class="k">return</span> <span class="n">y_history</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.euler_integrate_tuple" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">euler_integrate_tuple</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">euler_integrate_tuple</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">[[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Tuple" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">]],</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">]],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">neuron_count</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Performs standard explicit Euler integration for integer-order ODEs (<span class="arithmatex">\(D^1 y = f(t, y)\)</span>).</p>
<p>This function distinguishes between dynamic state variables (neurons) which are integrated,
and boundary outputs (e.g., spike outputs) which are treated as pass-through values computed
directly from the derivative without accumulation.</p>
<p>The update rule for integrated components is:</p>
<div class="arithmatex">\[y_{k+1} = y_k + \Delta t \cdot f(t_k, y_k)\]</div>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a>[[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, <a class="autorefs autorefs-external" title="typing.Tuple" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]], <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]]</code>)
          –
          <div class="doc-md-description">
            <p>A callable <code>f(t, y_tuple)</code> returning a tuple of derivatives.
      Expected format: <code>(dy_1, ..., dy_N, boundary_1, ...)</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y0_tuple</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]</code>)
          –
          <div class="doc-md-description">
            <p>A tuple of initial state tensors <code>(y_1, ..., y_N, boundary_1, ...)</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>A 1D tensor of time points <code>[t_0, t_1, ..., t_N]</code>. Step sizes can be non-uniform.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>neuron_count</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>The number of components in the state tuple representing dynamic neurons
          to be integrated. Components beyond this index are treated as pass-through boundaries.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>
          –
          <div class="doc-md-description">
            <p>A list of lists, where <code>history[i][k]</code> is the state of component <code>i</code> at time step <code>k+1</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>
          –
          <div class="doc-md-description">
            <p>The length of each inner list is <code>len(t_grid) - 1</code>.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Raises:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/exceptions.html#AssertionError">AssertionError</a></code>
            –
          <div class="doc-md-description">
            <p>If <code>y0_tuple</code> is not a tuple or <code>t_grid</code> has fewer than 2 points.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-0-10">10</a></span>
<span class="normal"><a href="#__codelineno-0-11">11</a></span>
<span class="normal"><a href="#__codelineno-0-12">12</a></span>
<span class="normal"><a href="#__codelineno-0-13">13</a></span>
<span class="normal"><a href="#__codelineno-0-14">14</a></span>
<span class="normal"><a href="#__codelineno-0-15">15</a></span>
<span class="normal"><a href="#__codelineno-0-16">16</a></span>
<span class="normal"><a href="#__codelineno-0-17">17</a></span>
<span class="normal"><a href="#__codelineno-0-18">18</a></span>
<span class="normal"><a href="#__codelineno-0-19">19</a></span>
<span class="normal"><a href="#__codelineno-0-20">20</a></span>
<span class="normal"><a href="#__codelineno-0-21">21</a></span>
<span class="normal"><a href="#__codelineno-0-22">22</a></span>
<span class="normal"><a href="#__codelineno-0-23">23</a></span>
<span class="normal"><a href="#__codelineno-0-24">24</a></span>
<span class="normal"><a href="#__codelineno-0-25">25</a></span>
<span class="normal"><a href="#__codelineno-0-26">26</a></span>
<span class="normal"><a href="#__codelineno-0-27">27</a></span>
<span class="normal"><a href="#__codelineno-0-28">28</a></span>
<span class="normal"><a href="#__codelineno-0-29">29</a></span>
<span class="normal"><a href="#__codelineno-0-30">30</a></span>
<span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span>
<span class="normal"><a href="#__codelineno-0-76">76</a></span>
<span class="normal"><a href="#__codelineno-0-77">77</a></span>
<span class="normal"><a href="#__codelineno-0-78">78</a></span>
<span class="normal"><a href="#__codelineno-0-79">79</a></span>
<span class="normal"><a href="#__codelineno-0-80">80</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="k">def</span><span class="w"> </span><span class="nf">euler_integrate_tuple</span><span class="p">(</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11"></a>        <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12"></a>    <span class="p">],</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15"></a>    <span class="n">neuron_count</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="__span-0-17"><a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-18"><a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="sd">    Performs standard explicit Euler integration for integer-order ODEs ($D^1 y = f(t, y)$).</span>
</span><span id="__span-0-19"><a id="__codelineno-0-19" name="__codelineno-0-19"></a>
</span><span id="__span-0-20"><a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="sd">    This function distinguishes between dynamic state variables (neurons) which are integrated,</span>
</span><span id="__span-0-21"><a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">    and boundary outputs (e.g., spike outputs) which are treated as pass-through values computed</span>
</span><span id="__span-0-22"><a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">    directly from the derivative without accumulation.</span>
</span><span id="__span-0-23"><a id="__codelineno-0-23" name="__codelineno-0-23"></a>
</span><span id="__span-0-24"><a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">    The update rule for integrated components is:</span>
</span><span id="__span-0-25"><a id="__codelineno-0-25" name="__codelineno-0-25"></a>
</span><span id="__span-0-26"><a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">    $$y_{k+1} = y_k + \Delta t \cdot f(t_k, y_k)$$</span>
</span><span id="__span-0-27"><a id="__codelineno-0-27" name="__codelineno-0-27"></a>
</span><span id="__span-0-28"><a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">    Args:</span>
</span><span id="__span-0-29"><a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">        ode_func: A callable `f(t, y_tuple)` returning a tuple of derivatives.</span>
</span><span id="__span-0-30"><a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">                  Expected format: `(dy_1, ..., dy_N, boundary_1, ...)`.</span>
</span><span id="__span-0-31"><a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">        y0_tuple: A tuple of initial state tensors `(y_1, ..., y_N, boundary_1, ...)`.</span>
</span><span id="__span-0-32"><a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">        t_grid: A 1D tensor of time points `[t_0, t_1, ..., t_N]`. Step sizes can be non-uniform.</span>
</span><span id="__span-0-33"><a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">        neuron_count: The number of components in the state tuple representing dynamic neurons</span>
</span><span id="__span-0-34"><a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">                      to be integrated. Components beyond this index are treated as pass-through boundaries.</span>
</span><span id="__span-0-35"><a id="__codelineno-0-35" name="__codelineno-0-35"></a>
</span><span id="__span-0-36"><a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-37"><a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">        A list of lists, where `history[i][k]` is the state of component `i` at time step `k+1`.</span>
</span><span id="__span-0-38"><a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">        The length of each inner list is `len(t_grid) - 1`.</span>
</span><span id="__span-0-39"><a id="__codelineno-0-39" name="__codelineno-0-39"></a>
</span><span id="__span-0-40"><a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-41"><a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">        AssertionError: If `y0_tuple` is not a tuple or `t_grid` has fewer than 2 points.</span>
</span><span id="__span-0-42"><a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-43"><a id="__codelineno-0-43" name="__codelineno-0-43"></a>    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
</span><span id="__span-0-44"><a id="__codelineno-0-44" name="__codelineno-0-44"></a>    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_grid</span><span class="p">)</span>
</span><span id="__span-0-45"><a id="__codelineno-0-45" name="__codelineno-0-45"></a>    <span class="k">assert</span> <span class="n">N</span> <span class="o">&gt;=</span> <span class="mi">2</span>
</span><span id="__span-0-46"><a id="__codelineno-0-46" name="__codelineno-0-46"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">y0_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
</span><span id="__span-0-47"><a id="__codelineno-0-47" name="__codelineno-0-47"></a>    <span class="n">dtype</span> <span class="o">=</span> <span class="n">y0_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-48"><a id="__codelineno-0-48" name="__codelineno-0-48"></a>    <span class="n">t_grid</span> <span class="o">=</span> <span class="n">t_grid</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-49"><a id="__codelineno-0-49" name="__codelineno-0-49"></a>
</span><span id="__span-0-50"><a id="__codelineno-0-50" name="__codelineno-0-50"></a>    <span class="n">n_integrate</span> <span class="o">=</span> <span class="n">neuron_count</span>
</span><span id="__span-0-51"><a id="__codelineno-0-51" name="__codelineno-0-51"></a>    <span class="c1"># n_integrate is the number of neurons,</span>
</span><span id="__span-0-52"><a id="__codelineno-0-52" name="__codelineno-0-52"></a>    <span class="c1"># i.e., length of (dv1/dt, dv2/dt, ..., dvN/dt)</span>
</span><span id="__span-0-53"><a id="__codelineno-0-53" name="__codelineno-0-53"></a>    <span class="n">n_components</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">)</span>
</span><span id="__span-0-54"><a id="__codelineno-0-54" name="__codelineno-0-54"></a>    <span class="c1"># length of (dv1/dt, dv2/dt, ..., dvN/dt, boundary_1, boundary_2, ...)</span>
</span><span id="__span-0-55"><a id="__codelineno-0-55" name="__codelineno-0-55"></a>
</span><span id="__span-0-56"><a id="__codelineno-0-56" name="__codelineno-0-56"></a>    <span class="c1"># Initialize history lists for each component</span>
</span><span id="__span-0-57"><a id="__codelineno-0-57" name="__codelineno-0-57"></a>    <span class="n">y_current</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">)</span>
</span><span id="__span-0-58"><a id="__codelineno-0-58" name="__codelineno-0-58"></a>    <span class="n">y_history</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">y0_tuple</span><span class="p">]</span>
</span><span id="__span-0-59"><a id="__codelineno-0-59" name="__codelineno-0-59"></a>
</span><span id="__span-0-60"><a id="__codelineno-0-60" name="__codelineno-0-60"></a>    <span class="c1"># Euler integration: y_{k+1} = y_k + dt * f(t_k, y_k)</span>
</span><span id="__span-0-61"><a id="__codelineno-0-61" name="__codelineno-0-61"></a>    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-62"><a id="__codelineno-0-62" name="__codelineno-0-62"></a>        <span class="n">tk</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
</span><span id="__span-0-63"><a id="__codelineno-0-63" name="__codelineno-0-63"></a>        <span class="n">dt</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># Scalar tensor, will broadcast automatically</span>
</span><span id="__span-0-64"><a id="__codelineno-0-64" name="__codelineno-0-64"></a>        <span class="n">dy</span> <span class="o">=</span> <span class="n">ode_func</span><span class="p">(</span>
</span><span id="__span-0-65"><a id="__codelineno-0-65" name="__codelineno-0-65"></a>            <span class="n">tk</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">y_current</span><span class="p">)</span>
</span><span id="__span-0-66"><a id="__codelineno-0-66" name="__codelineno-0-66"></a>        <span class="p">)</span>  <span class="c1"># Expect tuple return, consistent with y structure</span>
</span><span id="__span-0-67"><a id="__codelineno-0-67" name="__codelineno-0-67"></a>        <span class="c1"># assert isinstance(dy, tuple) and len(dy) == len(y)</span>
</span><span id="__span-0-68"><a id="__codelineno-0-68" name="__codelineno-0-68"></a>
</span><span id="__span-0-69"><a id="__codelineno-0-69" name="__codelineno-0-69"></a>        <span class="c1"># Update all integrated components except the last one</span>
</span><span id="__span-0-70"><a id="__codelineno-0-70" name="__codelineno-0-70"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_integrate</span><span class="p">):</span>
</span><span id="__span-0-71"><a id="__codelineno-0-71" name="__codelineno-0-71"></a>            <span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">dy</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="__span-0-72"><a id="__codelineno-0-72" name="__codelineno-0-72"></a>            <span class="n">y_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="__span-0-73"><a id="__codelineno-0-73" name="__codelineno-0-73"></a>
</span><span id="__span-0-74"><a id="__codelineno-0-74" name="__codelineno-0-74"></a>        <span class="c1"># Pass-through boundary output e.g. final spike output</span>
</span><span id="__span-0-75"><a id="__codelineno-0-75" name="__codelineno-0-75"></a>        <span class="c1"># See odefunc_fx.md</span>
</span><span id="__span-0-76"><a id="__codelineno-0-76" name="__codelineno-0-76"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_integrate</span><span class="p">,</span> <span class="n">n_components</span><span class="p">):</span>
</span><span id="__span-0-77"><a id="__codelineno-0-77" name="__codelineno-0-77"></a>            <span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">dy</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="__span-0-78"><a id="__codelineno-0-78" name="__codelineno-0-78"></a>            <span class="n">y_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="__span-0-79"><a id="__codelineno-0-79" name="__codelineno-0-79"></a>
</span><span id="__span-0-80"><a id="__codelineno-0-80" name="__codelineno-0-80"></a>    <span class="k">return</span> <span class="n">y_history</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.gl_integrate_tuple" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">gl_integrate_tuple</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">gl_integrate_tuple</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">per_layer_alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">],</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">per_layer_coefficient</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Solves FDEs using the Grünwald-Letnikov (GL) method with per-layer alpha support.</p>
<p>Automatically switches to <code>GrunwaldLetnikovMultitermSNN</code> if any layer has multi-term alpha.
Suitable for Riemann-Liouville formulations.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></code>)
          –
          <div class="doc-md-description">
            <p>Function <code>f(t, y_tuple)</code> returning derivatives.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y0_tuple</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]</code>)
          –
          <div class="doc-md-description">
            <p>Initial state tuple.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>per_layer_alpha</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a>]</code>)
          –
          <div class="doc-md-description">
            <p>List of alpha values, one per integrated component.
             Each can be scalar (single-term) or list/tensor (multi-term).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Time points tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Optional memory truncation length.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>per_layer_coefficient</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a> | None] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Coefficients for multi-term layers.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>
          –
          <div class="doc-md-description">
            <p>List of lists containing the state trajectory.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1068">1068</a></span>
<span class="normal"><a href="#__codelineno-0-1069">1069</a></span>
<span class="normal"><a href="#__codelineno-0-1070">1070</a></span>
<span class="normal"><a href="#__codelineno-0-1071">1071</a></span>
<span class="normal"><a href="#__codelineno-0-1072">1072</a></span>
<span class="normal"><a href="#__codelineno-0-1073">1073</a></span>
<span class="normal"><a href="#__codelineno-0-1074">1074</a></span>
<span class="normal"><a href="#__codelineno-0-1075">1075</a></span>
<span class="normal"><a href="#__codelineno-0-1076">1076</a></span>
<span class="normal"><a href="#__codelineno-0-1077">1077</a></span>
<span class="normal"><a href="#__codelineno-0-1078">1078</a></span>
<span class="normal"><a href="#__codelineno-0-1079">1079</a></span>
<span class="normal"><a href="#__codelineno-0-1080">1080</a></span>
<span class="normal"><a href="#__codelineno-0-1081">1081</a></span>
<span class="normal"><a href="#__codelineno-0-1082">1082</a></span>
<span class="normal"><a href="#__codelineno-0-1083">1083</a></span>
<span class="normal"><a href="#__codelineno-0-1084">1084</a></span>
<span class="normal"><a href="#__codelineno-0-1085">1085</a></span>
<span class="normal"><a href="#__codelineno-0-1086">1086</a></span>
<span class="normal"><a href="#__codelineno-0-1087">1087</a></span>
<span class="normal"><a href="#__codelineno-0-1088">1088</a></span>
<span class="normal"><a href="#__codelineno-0-1089">1089</a></span>
<span class="normal"><a href="#__codelineno-0-1090">1090</a></span>
<span class="normal"><a href="#__codelineno-0-1091">1091</a></span>
<span class="normal"><a href="#__codelineno-0-1092">1092</a></span>
<span class="normal"><a href="#__codelineno-0-1093">1093</a></span>
<span class="normal"><a href="#__codelineno-0-1094">1094</a></span>
<span class="normal"><a href="#__codelineno-0-1095">1095</a></span>
<span class="normal"><a href="#__codelineno-0-1096">1096</a></span>
<span class="normal"><a href="#__codelineno-0-1097">1097</a></span>
<span class="normal"><a href="#__codelineno-0-1098">1098</a></span>
<span class="normal"><a href="#__codelineno-0-1099">1099</a></span>
<span class="normal"><a href="#__codelineno-0-1100">1100</a></span>
<span class="normal"><a href="#__codelineno-0-1101">1101</a></span>
<span class="normal"><a href="#__codelineno-0-1102">1102</a></span>
<span class="normal"><a href="#__codelineno-0-1103">1103</a></span>
<span class="normal"><a href="#__codelineno-0-1104">1104</a></span>
<span class="normal"><a href="#__codelineno-0-1105">1105</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1068"><a id="__codelineno-0-1068" name="__codelineno-0-1068"></a><span class="k">def</span><span class="w"> </span><span class="nf">gl_integrate_tuple</span><span class="p">(</span>
</span><span id="__span-0-1069"><a id="__codelineno-0-1069" name="__codelineno-0-1069"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
</span><span id="__span-0-1070"><a id="__codelineno-0-1070" name="__codelineno-0-1070"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-1071"><a id="__codelineno-0-1071" name="__codelineno-0-1071"></a>    <span class="n">per_layer_alpha</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
</span><span id="__span-0-1072"><a id="__codelineno-0-1072" name="__codelineno-0-1072"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-1073"><a id="__codelineno-0-1073" name="__codelineno-0-1073"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1074"><a id="__codelineno-0-1074" name="__codelineno-0-1074"></a>    <span class="n">per_layer_coefficient</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1075"><a id="__codelineno-0-1075" name="__codelineno-0-1075"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="__span-0-1076"><a id="__codelineno-0-1076" name="__codelineno-0-1076"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-1077"><a id="__codelineno-0-1077" name="__codelineno-0-1077"></a><span class="sd">    Solves FDEs using the Grünwald-Letnikov (GL) method with per-layer alpha support.</span>
</span><span id="__span-0-1078"><a id="__codelineno-0-1078" name="__codelineno-0-1078"></a>
</span><span id="__span-0-1079"><a id="__codelineno-0-1079" name="__codelineno-0-1079"></a><span class="sd">    Automatically switches to `GrunwaldLetnikovMultitermSNN` if any layer has multi-term alpha.</span>
</span><span id="__span-0-1080"><a id="__codelineno-0-1080" name="__codelineno-0-1080"></a><span class="sd">    Suitable for Riemann-Liouville formulations.</span>
</span><span id="__span-0-1081"><a id="__codelineno-0-1081" name="__codelineno-0-1081"></a>
</span><span id="__span-0-1082"><a id="__codelineno-0-1082" name="__codelineno-0-1082"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1083"><a id="__codelineno-0-1083" name="__codelineno-0-1083"></a><span class="sd">        ode_func: Function `f(t, y_tuple)` returning derivatives.</span>
</span><span id="__span-0-1084"><a id="__codelineno-0-1084" name="__codelineno-0-1084"></a><span class="sd">        y0_tuple: Initial state tuple.</span>
</span><span id="__span-0-1085"><a id="__codelineno-0-1085" name="__codelineno-0-1085"></a><span class="sd">        per_layer_alpha: List of alpha values, one per integrated component.</span>
</span><span id="__span-0-1086"><a id="__codelineno-0-1086" name="__codelineno-0-1086"></a><span class="sd">                         Each can be scalar (single-term) or list/tensor (multi-term).</span>
</span><span id="__span-0-1087"><a id="__codelineno-0-1087" name="__codelineno-0-1087"></a><span class="sd">        t_grid: Time points tensor.</span>
</span><span id="__span-0-1088"><a id="__codelineno-0-1088" name="__codelineno-0-1088"></a><span class="sd">        memory: Optional memory truncation length.</span>
</span><span id="__span-0-1089"><a id="__codelineno-0-1089" name="__codelineno-0-1089"></a><span class="sd">        per_layer_coefficient: Coefficients for multi-term layers.</span>
</span><span id="__span-0-1090"><a id="__codelineno-0-1090" name="__codelineno-0-1090"></a>
</span><span id="__span-0-1091"><a id="__codelineno-0-1091" name="__codelineno-0-1091"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1092"><a id="__codelineno-0-1092" name="__codelineno-0-1092"></a><span class="sd">        List of lists containing the state trajectory.</span>
</span><span id="__span-0-1093"><a id="__codelineno-0-1093" name="__codelineno-0-1093"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-1094"><a id="__codelineno-0-1094" name="__codelineno-0-1094"></a>    <span class="n">solver</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_get_solver_with_multiterm_fallback</span><span class="p">(</span>
</span><span id="__span-0-1095"><a id="__codelineno-0-1095" name="__codelineno-0-1095"></a>        <span class="s2">&quot;gl&quot;</span><span class="p">,</span> <span class="n">per_layer_alpha</span><span class="p">,</span> <span class="n">per_layer_coefficient</span>
</span><span id="__span-0-1096"><a id="__codelineno-0-1096" name="__codelineno-0-1096"></a>    <span class="p">)</span>
</span><span id="__span-0-1097"><a id="__codelineno-0-1097" name="__codelineno-0-1097"></a>    <span class="k">return</span> <span class="n">snn_solve</span><span class="p">(</span>
</span><span id="__span-0-1098"><a id="__codelineno-0-1098" name="__codelineno-0-1098"></a>        <span class="n">ode_func</span><span class="p">,</span>
</span><span id="__span-0-1099"><a id="__codelineno-0-1099" name="__codelineno-0-1099"></a>        <span class="n">y0_tuple</span><span class="p">,</span>
</span><span id="__span-0-1100"><a id="__codelineno-0-1100" name="__codelineno-0-1100"></a>        <span class="n">per_layer_alpha</span><span class="p">,</span>
</span><span id="__span-0-1101"><a id="__codelineno-0-1101" name="__codelineno-0-1101"></a>        <span class="n">t_grid</span><span class="p">,</span>
</span><span id="__span-0-1102"><a id="__codelineno-0-1102" name="__codelineno-0-1102"></a>        <span class="n">solver</span><span class="p">,</span>
</span><span id="__span-0-1103"><a id="__codelineno-0-1103" name="__codelineno-0-1103"></a>        <span class="n">memory</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span>
</span><span id="__span-0-1104"><a id="__codelineno-0-1104" name="__codelineno-0-1104"></a>        <span class="n">per_layer_coefficient</span><span class="o">=</span><span class="n">per_layer_coefficient</span><span class="p">,</span>
</span><span id="__span-0-1105"><a id="__codelineno-0-1105" name="__codelineno-0-1105"></a>    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.trap_integrate_tuple" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">trap_integrate_tuple</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">trap_integrate_tuple</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">per_layer_alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">],</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">per_layer_coefficient</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Solves FDEs using the Product Trapezoidal method with per-layer alpha support.</p>


<details class="note" open>
  <summary>Note</summary>
  <p>If any layer has multi-term alpha, automatically falls back to GL multiterm
with a warning. Offers higher accuracy (<span class="arithmatex">\(O(h^2)\)</span>) for single-term Riemann-Liouville equations.</p>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></code>)
          –
          <div class="doc-md-description">
            <p>Function <code>f(t, y_tuple)</code> returning derivatives.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y0_tuple</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]</code>)
          –
          <div class="doc-md-description">
            <p>Initial state tuple.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>per_layer_alpha</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a>]</code>)
          –
          <div class="doc-md-description">
            <p>List of alpha values.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Time points tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Optional memory truncation length.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>per_layer_coefficient</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a> | None] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Coefficients for multi-term layers.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>
          –
          <div class="doc-md-description">
            <p>List of lists containing the state trajectory.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1108">1108</a></span>
<span class="normal"><a href="#__codelineno-0-1109">1109</a></span>
<span class="normal"><a href="#__codelineno-0-1110">1110</a></span>
<span class="normal"><a href="#__codelineno-0-1111">1111</a></span>
<span class="normal"><a href="#__codelineno-0-1112">1112</a></span>
<span class="normal"><a href="#__codelineno-0-1113">1113</a></span>
<span class="normal"><a href="#__codelineno-0-1114">1114</a></span>
<span class="normal"><a href="#__codelineno-0-1115">1115</a></span>
<span class="normal"><a href="#__codelineno-0-1116">1116</a></span>
<span class="normal"><a href="#__codelineno-0-1117">1117</a></span>
<span class="normal"><a href="#__codelineno-0-1118">1118</a></span>
<span class="normal"><a href="#__codelineno-0-1119">1119</a></span>
<span class="normal"><a href="#__codelineno-0-1120">1120</a></span>
<span class="normal"><a href="#__codelineno-0-1121">1121</a></span>
<span class="normal"><a href="#__codelineno-0-1122">1122</a></span>
<span class="normal"><a href="#__codelineno-0-1123">1123</a></span>
<span class="normal"><a href="#__codelineno-0-1124">1124</a></span>
<span class="normal"><a href="#__codelineno-0-1125">1125</a></span>
<span class="normal"><a href="#__codelineno-0-1126">1126</a></span>
<span class="normal"><a href="#__codelineno-0-1127">1127</a></span>
<span class="normal"><a href="#__codelineno-0-1128">1128</a></span>
<span class="normal"><a href="#__codelineno-0-1129">1129</a></span>
<span class="normal"><a href="#__codelineno-0-1130">1130</a></span>
<span class="normal"><a href="#__codelineno-0-1131">1131</a></span>
<span class="normal"><a href="#__codelineno-0-1132">1132</a></span>
<span class="normal"><a href="#__codelineno-0-1133">1133</a></span>
<span class="normal"><a href="#__codelineno-0-1134">1134</a></span>
<span class="normal"><a href="#__codelineno-0-1135">1135</a></span>
<span class="normal"><a href="#__codelineno-0-1136">1136</a></span>
<span class="normal"><a href="#__codelineno-0-1137">1137</a></span>
<span class="normal"><a href="#__codelineno-0-1138">1138</a></span>
<span class="normal"><a href="#__codelineno-0-1139">1139</a></span>
<span class="normal"><a href="#__codelineno-0-1140">1140</a></span>
<span class="normal"><a href="#__codelineno-0-1141">1141</a></span>
<span class="normal"><a href="#__codelineno-0-1142">1142</a></span>
<span class="normal"><a href="#__codelineno-0-1143">1143</a></span>
<span class="normal"><a href="#__codelineno-0-1144">1144</a></span>
<span class="normal"><a href="#__codelineno-0-1145">1145</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1108"><a id="__codelineno-0-1108" name="__codelineno-0-1108"></a><span class="k">def</span><span class="w"> </span><span class="nf">trap_integrate_tuple</span><span class="p">(</span>
</span><span id="__span-0-1109"><a id="__codelineno-0-1109" name="__codelineno-0-1109"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
</span><span id="__span-0-1110"><a id="__codelineno-0-1110" name="__codelineno-0-1110"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-1111"><a id="__codelineno-0-1111" name="__codelineno-0-1111"></a>    <span class="n">per_layer_alpha</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
</span><span id="__span-0-1112"><a id="__codelineno-0-1112" name="__codelineno-0-1112"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-1113"><a id="__codelineno-0-1113" name="__codelineno-0-1113"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1114"><a id="__codelineno-0-1114" name="__codelineno-0-1114"></a>    <span class="n">per_layer_coefficient</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1115"><a id="__codelineno-0-1115" name="__codelineno-0-1115"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="__span-0-1116"><a id="__codelineno-0-1116" name="__codelineno-0-1116"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-1117"><a id="__codelineno-0-1117" name="__codelineno-0-1117"></a><span class="sd">    Solves FDEs using the Product Trapezoidal method with per-layer alpha support.</span>
</span><span id="__span-0-1118"><a id="__codelineno-0-1118" name="__codelineno-0-1118"></a>
</span><span id="__span-0-1119"><a id="__codelineno-0-1119" name="__codelineno-0-1119"></a><span class="sd">    Note:</span>
</span><span id="__span-0-1120"><a id="__codelineno-0-1120" name="__codelineno-0-1120"></a><span class="sd">        If any layer has multi-term alpha, automatically falls back to GL multiterm</span>
</span><span id="__span-0-1121"><a id="__codelineno-0-1121" name="__codelineno-0-1121"></a><span class="sd">        with a warning. Offers higher accuracy ($O(h^2)$) for single-term Riemann-Liouville equations.</span>
</span><span id="__span-0-1122"><a id="__codelineno-0-1122" name="__codelineno-0-1122"></a>
</span><span id="__span-0-1123"><a id="__codelineno-0-1123" name="__codelineno-0-1123"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1124"><a id="__codelineno-0-1124" name="__codelineno-0-1124"></a><span class="sd">        ode_func: Function `f(t, y_tuple)` returning derivatives.</span>
</span><span id="__span-0-1125"><a id="__codelineno-0-1125" name="__codelineno-0-1125"></a><span class="sd">        y0_tuple: Initial state tuple.</span>
</span><span id="__span-0-1126"><a id="__codelineno-0-1126" name="__codelineno-0-1126"></a><span class="sd">        per_layer_alpha: List of alpha values.</span>
</span><span id="__span-0-1127"><a id="__codelineno-0-1127" name="__codelineno-0-1127"></a><span class="sd">        t_grid: Time points tensor.</span>
</span><span id="__span-0-1128"><a id="__codelineno-0-1128" name="__codelineno-0-1128"></a><span class="sd">        memory: Optional memory truncation length.</span>
</span><span id="__span-0-1129"><a id="__codelineno-0-1129" name="__codelineno-0-1129"></a><span class="sd">        per_layer_coefficient: Coefficients for multi-term layers.</span>
</span><span id="__span-0-1130"><a id="__codelineno-0-1130" name="__codelineno-0-1130"></a>
</span><span id="__span-0-1131"><a id="__codelineno-0-1131" name="__codelineno-0-1131"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1132"><a id="__codelineno-0-1132" name="__codelineno-0-1132"></a><span class="sd">        List of lists containing the state trajectory.</span>
</span><span id="__span-0-1133"><a id="__codelineno-0-1133" name="__codelineno-0-1133"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-1134"><a id="__codelineno-0-1134" name="__codelineno-0-1134"></a>    <span class="n">solver</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_get_solver_with_multiterm_fallback</span><span class="p">(</span>
</span><span id="__span-0-1135"><a id="__codelineno-0-1135" name="__codelineno-0-1135"></a>        <span class="s2">&quot;trap&quot;</span><span class="p">,</span> <span class="n">per_layer_alpha</span><span class="p">,</span> <span class="n">per_layer_coefficient</span>
</span><span id="__span-0-1136"><a id="__codelineno-0-1136" name="__codelineno-0-1136"></a>    <span class="p">)</span>
</span><span id="__span-0-1137"><a id="__codelineno-0-1137" name="__codelineno-0-1137"></a>    <span class="k">return</span> <span class="n">snn_solve</span><span class="p">(</span>
</span><span id="__span-0-1138"><a id="__codelineno-0-1138" name="__codelineno-0-1138"></a>        <span class="n">ode_func</span><span class="p">,</span>
</span><span id="__span-0-1139"><a id="__codelineno-0-1139" name="__codelineno-0-1139"></a>        <span class="n">y0_tuple</span><span class="p">,</span>
</span><span id="__span-0-1140"><a id="__codelineno-0-1140" name="__codelineno-0-1140"></a>        <span class="n">per_layer_alpha</span><span class="p">,</span>
</span><span id="__span-0-1141"><a id="__codelineno-0-1141" name="__codelineno-0-1141"></a>        <span class="n">t_grid</span><span class="p">,</span>
</span><span id="__span-0-1142"><a id="__codelineno-0-1142" name="__codelineno-0-1142"></a>        <span class="n">solver</span><span class="p">,</span>
</span><span id="__span-0-1143"><a id="__codelineno-0-1143" name="__codelineno-0-1143"></a>        <span class="n">memory</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span>
</span><span id="__span-0-1144"><a id="__codelineno-0-1144" name="__codelineno-0-1144"></a>        <span class="n">per_layer_coefficient</span><span class="o">=</span><span class="n">per_layer_coefficient</span><span class="p">,</span>
</span><span id="__span-0-1145"><a id="__codelineno-0-1145" name="__codelineno-0-1145"></a>    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.l1_integrate_tuple" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">l1_integrate_tuple</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">l1_integrate_tuple</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">per_layer_alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">],</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">per_layer_coefficient</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Solves FDEs using the L1 scheme with per-layer alpha support.</p>


<details class="note" open>
  <summary>Note</summary>
  <p>If any layer has multi-term alpha, automatically falls back to GL multiterm
with a warning. Commonly used for Caputo formulations with accuracy <span class="arithmatex">\(O(h^{2-\alpha})\)</span>.</p>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></code>)
          –
          <div class="doc-md-description">
            <p>Function <code>f(t, y_tuple)</code> returning derivatives.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y0_tuple</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]</code>)
          –
          <div class="doc-md-description">
            <p>Initial state tuple.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>per_layer_alpha</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a>]</code>)
          –
          <div class="doc-md-description">
            <p>List of alpha values.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Time points tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Optional memory truncation length.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>per_layer_coefficient</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a> | None] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Coefficients for multi-term layers.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>
          –
          <div class="doc-md-description">
            <p>List of lists containing the state trajectory.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1148">1148</a></span>
<span class="normal"><a href="#__codelineno-0-1149">1149</a></span>
<span class="normal"><a href="#__codelineno-0-1150">1150</a></span>
<span class="normal"><a href="#__codelineno-0-1151">1151</a></span>
<span class="normal"><a href="#__codelineno-0-1152">1152</a></span>
<span class="normal"><a href="#__codelineno-0-1153">1153</a></span>
<span class="normal"><a href="#__codelineno-0-1154">1154</a></span>
<span class="normal"><a href="#__codelineno-0-1155">1155</a></span>
<span class="normal"><a href="#__codelineno-0-1156">1156</a></span>
<span class="normal"><a href="#__codelineno-0-1157">1157</a></span>
<span class="normal"><a href="#__codelineno-0-1158">1158</a></span>
<span class="normal"><a href="#__codelineno-0-1159">1159</a></span>
<span class="normal"><a href="#__codelineno-0-1160">1160</a></span>
<span class="normal"><a href="#__codelineno-0-1161">1161</a></span>
<span class="normal"><a href="#__codelineno-0-1162">1162</a></span>
<span class="normal"><a href="#__codelineno-0-1163">1163</a></span>
<span class="normal"><a href="#__codelineno-0-1164">1164</a></span>
<span class="normal"><a href="#__codelineno-0-1165">1165</a></span>
<span class="normal"><a href="#__codelineno-0-1166">1166</a></span>
<span class="normal"><a href="#__codelineno-0-1167">1167</a></span>
<span class="normal"><a href="#__codelineno-0-1168">1168</a></span>
<span class="normal"><a href="#__codelineno-0-1169">1169</a></span>
<span class="normal"><a href="#__codelineno-0-1170">1170</a></span>
<span class="normal"><a href="#__codelineno-0-1171">1171</a></span>
<span class="normal"><a href="#__codelineno-0-1172">1172</a></span>
<span class="normal"><a href="#__codelineno-0-1173">1173</a></span>
<span class="normal"><a href="#__codelineno-0-1174">1174</a></span>
<span class="normal"><a href="#__codelineno-0-1175">1175</a></span>
<span class="normal"><a href="#__codelineno-0-1176">1176</a></span>
<span class="normal"><a href="#__codelineno-0-1177">1177</a></span>
<span class="normal"><a href="#__codelineno-0-1178">1178</a></span>
<span class="normal"><a href="#__codelineno-0-1179">1179</a></span>
<span class="normal"><a href="#__codelineno-0-1180">1180</a></span>
<span class="normal"><a href="#__codelineno-0-1181">1181</a></span>
<span class="normal"><a href="#__codelineno-0-1182">1182</a></span>
<span class="normal"><a href="#__codelineno-0-1183">1183</a></span>
<span class="normal"><a href="#__codelineno-0-1184">1184</a></span>
<span class="normal"><a href="#__codelineno-0-1185">1185</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1148"><a id="__codelineno-0-1148" name="__codelineno-0-1148"></a><span class="k">def</span><span class="w"> </span><span class="nf">l1_integrate_tuple</span><span class="p">(</span>
</span><span id="__span-0-1149"><a id="__codelineno-0-1149" name="__codelineno-0-1149"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
</span><span id="__span-0-1150"><a id="__codelineno-0-1150" name="__codelineno-0-1150"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-1151"><a id="__codelineno-0-1151" name="__codelineno-0-1151"></a>    <span class="n">per_layer_alpha</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
</span><span id="__span-0-1152"><a id="__codelineno-0-1152" name="__codelineno-0-1152"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-1153"><a id="__codelineno-0-1153" name="__codelineno-0-1153"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1154"><a id="__codelineno-0-1154" name="__codelineno-0-1154"></a>    <span class="n">per_layer_coefficient</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1155"><a id="__codelineno-0-1155" name="__codelineno-0-1155"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="__span-0-1156"><a id="__codelineno-0-1156" name="__codelineno-0-1156"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-1157"><a id="__codelineno-0-1157" name="__codelineno-0-1157"></a><span class="sd">    Solves FDEs using the L1 scheme with per-layer alpha support.</span>
</span><span id="__span-0-1158"><a id="__codelineno-0-1158" name="__codelineno-0-1158"></a>
</span><span id="__span-0-1159"><a id="__codelineno-0-1159" name="__codelineno-0-1159"></a><span class="sd">    Note:</span>
</span><span id="__span-0-1160"><a id="__codelineno-0-1160" name="__codelineno-0-1160"></a><span class="sd">        If any layer has multi-term alpha, automatically falls back to GL multiterm</span>
</span><span id="__span-0-1161"><a id="__codelineno-0-1161" name="__codelineno-0-1161"></a><span class="sd">        with a warning. Commonly used for Caputo formulations with accuracy $O(h^{2-\alpha})$.</span>
</span><span id="__span-0-1162"><a id="__codelineno-0-1162" name="__codelineno-0-1162"></a>
</span><span id="__span-0-1163"><a id="__codelineno-0-1163" name="__codelineno-0-1163"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1164"><a id="__codelineno-0-1164" name="__codelineno-0-1164"></a><span class="sd">        ode_func: Function `f(t, y_tuple)` returning derivatives.</span>
</span><span id="__span-0-1165"><a id="__codelineno-0-1165" name="__codelineno-0-1165"></a><span class="sd">        y0_tuple: Initial state tuple.</span>
</span><span id="__span-0-1166"><a id="__codelineno-0-1166" name="__codelineno-0-1166"></a><span class="sd">        per_layer_alpha: List of alpha values.</span>
</span><span id="__span-0-1167"><a id="__codelineno-0-1167" name="__codelineno-0-1167"></a><span class="sd">        t_grid: Time points tensor.</span>
</span><span id="__span-0-1168"><a id="__codelineno-0-1168" name="__codelineno-0-1168"></a><span class="sd">        memory: Optional memory truncation length.</span>
</span><span id="__span-0-1169"><a id="__codelineno-0-1169" name="__codelineno-0-1169"></a><span class="sd">        per_layer_coefficient: Coefficients for multi-term layers.</span>
</span><span id="__span-0-1170"><a id="__codelineno-0-1170" name="__codelineno-0-1170"></a>
</span><span id="__span-0-1171"><a id="__codelineno-0-1171" name="__codelineno-0-1171"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1172"><a id="__codelineno-0-1172" name="__codelineno-0-1172"></a><span class="sd">        List of lists containing the state trajectory.</span>
</span><span id="__span-0-1173"><a id="__codelineno-0-1173" name="__codelineno-0-1173"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-1174"><a id="__codelineno-0-1174" name="__codelineno-0-1174"></a>    <span class="n">solver</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_get_solver_with_multiterm_fallback</span><span class="p">(</span>
</span><span id="__span-0-1175"><a id="__codelineno-0-1175" name="__codelineno-0-1175"></a>        <span class="s2">&quot;l1&quot;</span><span class="p">,</span> <span class="n">per_layer_alpha</span><span class="p">,</span> <span class="n">per_layer_coefficient</span>
</span><span id="__span-0-1176"><a id="__codelineno-0-1176" name="__codelineno-0-1176"></a>    <span class="p">)</span>
</span><span id="__span-0-1177"><a id="__codelineno-0-1177" name="__codelineno-0-1177"></a>    <span class="k">return</span> <span class="n">snn_solve</span><span class="p">(</span>
</span><span id="__span-0-1178"><a id="__codelineno-0-1178" name="__codelineno-0-1178"></a>        <span class="n">ode_func</span><span class="p">,</span>
</span><span id="__span-0-1179"><a id="__codelineno-0-1179" name="__codelineno-0-1179"></a>        <span class="n">y0_tuple</span><span class="p">,</span>
</span><span id="__span-0-1180"><a id="__codelineno-0-1180" name="__codelineno-0-1180"></a>        <span class="n">per_layer_alpha</span><span class="p">,</span>
</span><span id="__span-0-1181"><a id="__codelineno-0-1181" name="__codelineno-0-1181"></a>        <span class="n">t_grid</span><span class="p">,</span>
</span><span id="__span-0-1182"><a id="__codelineno-0-1182" name="__codelineno-0-1182"></a>        <span class="n">solver</span><span class="p">,</span>
</span><span id="__span-0-1183"><a id="__codelineno-0-1183" name="__codelineno-0-1183"></a>        <span class="n">memory</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span>
</span><span id="__span-0-1184"><a id="__codelineno-0-1184" name="__codelineno-0-1184"></a>        <span class="n">per_layer_coefficient</span><span class="o">=</span><span class="n">per_layer_coefficient</span><span class="p">,</span>
</span><span id="__span-0-1185"><a id="__codelineno-0-1185" name="__codelineno-0-1185"></a>    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.pred_integrate_tuple" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">pred_integrate_tuple</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">pred_integrate_tuple</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">per_layer_alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">],</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">per_layer_coefficient</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Solves FDEs using the Adams-Bashforth predictor with per-layer alpha support.</p>


<details class="note" open>
  <summary>Note</summary>
  <p>If any layer has multi-term alpha, automatically falls back to GL multiterm
with a warning. Uses <span class="arithmatex">\(f\)</span>-history instead of <span class="arithmatex">\(y\)</span>-history.</p>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></code>)
          –
          <div class="doc-md-description">
            <p>Function <code>f(t, y_tuple)</code> returning derivatives.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y0_tuple</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]</code>)
          –
          <div class="doc-md-description">
            <p>Initial state tuple.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>per_layer_alpha</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a>]</code>)
          –
          <div class="doc-md-description">
            <p>List of alpha values.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Time points tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Optional memory truncation length.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>per_layer_coefficient</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a> | None] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Coefficients for multi-term layers.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>
          –
          <div class="doc-md-description">
            <p>List of lists containing the state trajectory.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1188">1188</a></span>
<span class="normal"><a href="#__codelineno-0-1189">1189</a></span>
<span class="normal"><a href="#__codelineno-0-1190">1190</a></span>
<span class="normal"><a href="#__codelineno-0-1191">1191</a></span>
<span class="normal"><a href="#__codelineno-0-1192">1192</a></span>
<span class="normal"><a href="#__codelineno-0-1193">1193</a></span>
<span class="normal"><a href="#__codelineno-0-1194">1194</a></span>
<span class="normal"><a href="#__codelineno-0-1195">1195</a></span>
<span class="normal"><a href="#__codelineno-0-1196">1196</a></span>
<span class="normal"><a href="#__codelineno-0-1197">1197</a></span>
<span class="normal"><a href="#__codelineno-0-1198">1198</a></span>
<span class="normal"><a href="#__codelineno-0-1199">1199</a></span>
<span class="normal"><a href="#__codelineno-0-1200">1200</a></span>
<span class="normal"><a href="#__codelineno-0-1201">1201</a></span>
<span class="normal"><a href="#__codelineno-0-1202">1202</a></span>
<span class="normal"><a href="#__codelineno-0-1203">1203</a></span>
<span class="normal"><a href="#__codelineno-0-1204">1204</a></span>
<span class="normal"><a href="#__codelineno-0-1205">1205</a></span>
<span class="normal"><a href="#__codelineno-0-1206">1206</a></span>
<span class="normal"><a href="#__codelineno-0-1207">1207</a></span>
<span class="normal"><a href="#__codelineno-0-1208">1208</a></span>
<span class="normal"><a href="#__codelineno-0-1209">1209</a></span>
<span class="normal"><a href="#__codelineno-0-1210">1210</a></span>
<span class="normal"><a href="#__codelineno-0-1211">1211</a></span>
<span class="normal"><a href="#__codelineno-0-1212">1212</a></span>
<span class="normal"><a href="#__codelineno-0-1213">1213</a></span>
<span class="normal"><a href="#__codelineno-0-1214">1214</a></span>
<span class="normal"><a href="#__codelineno-0-1215">1215</a></span>
<span class="normal"><a href="#__codelineno-0-1216">1216</a></span>
<span class="normal"><a href="#__codelineno-0-1217">1217</a></span>
<span class="normal"><a href="#__codelineno-0-1218">1218</a></span>
<span class="normal"><a href="#__codelineno-0-1219">1219</a></span>
<span class="normal"><a href="#__codelineno-0-1220">1220</a></span>
<span class="normal"><a href="#__codelineno-0-1221">1221</a></span>
<span class="normal"><a href="#__codelineno-0-1222">1222</a></span>
<span class="normal"><a href="#__codelineno-0-1223">1223</a></span>
<span class="normal"><a href="#__codelineno-0-1224">1224</a></span>
<span class="normal"><a href="#__codelineno-0-1225">1225</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1188"><a id="__codelineno-0-1188" name="__codelineno-0-1188"></a><span class="k">def</span><span class="w"> </span><span class="nf">pred_integrate_tuple</span><span class="p">(</span>
</span><span id="__span-0-1189"><a id="__codelineno-0-1189" name="__codelineno-0-1189"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
</span><span id="__span-0-1190"><a id="__codelineno-0-1190" name="__codelineno-0-1190"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-1191"><a id="__codelineno-0-1191" name="__codelineno-0-1191"></a>    <span class="n">per_layer_alpha</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
</span><span id="__span-0-1192"><a id="__codelineno-0-1192" name="__codelineno-0-1192"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-1193"><a id="__codelineno-0-1193" name="__codelineno-0-1193"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1194"><a id="__codelineno-0-1194" name="__codelineno-0-1194"></a>    <span class="n">per_layer_coefficient</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1195"><a id="__codelineno-0-1195" name="__codelineno-0-1195"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="__span-0-1196"><a id="__codelineno-0-1196" name="__codelineno-0-1196"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-1197"><a id="__codelineno-0-1197" name="__codelineno-0-1197"></a><span class="sd">    Solves FDEs using the Adams-Bashforth predictor with per-layer alpha support.</span>
</span><span id="__span-0-1198"><a id="__codelineno-0-1198" name="__codelineno-0-1198"></a>
</span><span id="__span-0-1199"><a id="__codelineno-0-1199" name="__codelineno-0-1199"></a><span class="sd">    Note:</span>
</span><span id="__span-0-1200"><a id="__codelineno-0-1200" name="__codelineno-0-1200"></a><span class="sd">        If any layer has multi-term alpha, automatically falls back to GL multiterm</span>
</span><span id="__span-0-1201"><a id="__codelineno-0-1201" name="__codelineno-0-1201"></a><span class="sd">        with a warning. Uses $f$-history instead of $y$-history.</span>
</span><span id="__span-0-1202"><a id="__codelineno-0-1202" name="__codelineno-0-1202"></a>
</span><span id="__span-0-1203"><a id="__codelineno-0-1203" name="__codelineno-0-1203"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1204"><a id="__codelineno-0-1204" name="__codelineno-0-1204"></a><span class="sd">        ode_func: Function `f(t, y_tuple)` returning derivatives.</span>
</span><span id="__span-0-1205"><a id="__codelineno-0-1205" name="__codelineno-0-1205"></a><span class="sd">        y0_tuple: Initial state tuple.</span>
</span><span id="__span-0-1206"><a id="__codelineno-0-1206" name="__codelineno-0-1206"></a><span class="sd">        per_layer_alpha: List of alpha values.</span>
</span><span id="__span-0-1207"><a id="__codelineno-0-1207" name="__codelineno-0-1207"></a><span class="sd">        t_grid: Time points tensor.</span>
</span><span id="__span-0-1208"><a id="__codelineno-0-1208" name="__codelineno-0-1208"></a><span class="sd">        memory: Optional memory truncation length.</span>
</span><span id="__span-0-1209"><a id="__codelineno-0-1209" name="__codelineno-0-1209"></a><span class="sd">        per_layer_coefficient: Coefficients for multi-term layers.</span>
</span><span id="__span-0-1210"><a id="__codelineno-0-1210" name="__codelineno-0-1210"></a>
</span><span id="__span-0-1211"><a id="__codelineno-0-1211" name="__codelineno-0-1211"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1212"><a id="__codelineno-0-1212" name="__codelineno-0-1212"></a><span class="sd">        List of lists containing the state trajectory.</span>
</span><span id="__span-0-1213"><a id="__codelineno-0-1213" name="__codelineno-0-1213"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-1214"><a id="__codelineno-0-1214" name="__codelineno-0-1214"></a>    <span class="n">solver</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_get_solver_with_multiterm_fallback</span><span class="p">(</span>
</span><span id="__span-0-1215"><a id="__codelineno-0-1215" name="__codelineno-0-1215"></a>        <span class="s2">&quot;pred&quot;</span><span class="p">,</span> <span class="n">per_layer_alpha</span><span class="p">,</span> <span class="n">per_layer_coefficient</span>
</span><span id="__span-0-1216"><a id="__codelineno-0-1216" name="__codelineno-0-1216"></a>    <span class="p">)</span>
</span><span id="__span-0-1217"><a id="__codelineno-0-1217" name="__codelineno-0-1217"></a>    <span class="k">return</span> <span class="n">snn_solve</span><span class="p">(</span>
</span><span id="__span-0-1218"><a id="__codelineno-0-1218" name="__codelineno-0-1218"></a>        <span class="n">ode_func</span><span class="p">,</span>
</span><span id="__span-0-1219"><a id="__codelineno-0-1219" name="__codelineno-0-1219"></a>        <span class="n">y0_tuple</span><span class="p">,</span>
</span><span id="__span-0-1220"><a id="__codelineno-0-1220" name="__codelineno-0-1220"></a>        <span class="n">per_layer_alpha</span><span class="p">,</span>
</span><span id="__span-0-1221"><a id="__codelineno-0-1221" name="__codelineno-0-1221"></a>        <span class="n">t_grid</span><span class="p">,</span>
</span><span id="__span-0-1222"><a id="__codelineno-0-1222" name="__codelineno-0-1222"></a>        <span class="n">solver</span><span class="p">,</span>
</span><span id="__span-0-1223"><a id="__codelineno-0-1223" name="__codelineno-0-1223"></a>        <span class="n">memory</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span>
</span><span id="__span-0-1224"><a id="__codelineno-0-1224" name="__codelineno-0-1224"></a>        <span class="n">per_layer_coefficient</span><span class="o">=</span><span class="n">per_layer_coefficient</span><span class="p">,</span>
</span><span id="__span-0-1225"><a id="__codelineno-0-1225" name="__codelineno-0-1225"></a>    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.fdeint_adjoint" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">fdeint_adjoint</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">fdeint_adjoint</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">[[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Tuple" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">]],</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">]],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span><span class="p">],</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">method</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Solves a Fractional Differential Equation (FDE) with adjoint sensitivity analysis.</p>
<p>This function enables gradient-based optimization of both the initial states <span class="arithmatex">\(y_0\)</span> and
the parameters of the ODE function <code>func</code> (e.g., neural network weights) with respect to
a loss function defined on the solution trajectory. It uses the continuous adjoint method
adapted for fractional calculus.</p>
<p>The workflow involves:</p>
<ol>
<li><strong>Forward Pass</strong>: Solving <span class="arithmatex">\(D^\alpha y(t) = f(t, y(t), \theta)\)</span> to obtain <span class="arithmatex">\(y(T)\)</span>.</li>
<li><strong>Backward Pass</strong>: Solving the augmented adjoint equation to compute <span class="arithmatex">\(\frac{\partial L}{\partial y_0}\)</span>
   and <span class="arithmatex">\(\frac{\partial L}{\partial \theta}\)</span>.</li>
</ol>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a>[[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, <a class="autorefs autorefs-external" title="typing.Tuple" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]], <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]]</code>)
          –
          <div class="doc-md-description">
            <p>The ODE function <span class="arithmatex">\(f(t, y, \theta)\)</span>. Must accept <code>(t, y_tuple)</code> and return a tuple of tensors.
  Parameters <span class="arithmatex">\(\theta\)</span> are implicitly captured from the function's scope or registered modules.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y0_tuple</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]</code>)
          –
          <div class="doc-md-description">
            <p>A tuple of initial state tensors <span class="arithmatex">\((y_1^0, \dots, y_N^0)\)</span>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>alpha</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a> | <a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a> | <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a>]</code>)
          –
          <div class="doc-md-description">
            <p>The fractional order(s). Can be a scalar, a tensor, or a list depending on the solver configuration.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>A 1D tensor of time points <span class="arithmatex">\([t_0, t_1, \dots, t_T]\)</span> defining the integration interval.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>method</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></code>)
          –
          <div class="doc-md-description">
            <p>The numerical integration scheme identifier (e.g., <code>'gl-f'</code>, <code>'trap-f'</code>, <code>'l1-f'</code>).
    Suffixes <code>-f</code> indicate full history storage required for adjoint, <code>-o</code> for optimized/no-history.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Optional integer to limit the memory length for convolution sums (short-memory principle).
    If <code>None</code>, full history is used.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]</code>
          –
          <div class="doc-md-description">
            <p>A tuple of tensors representing the solution at the final time point <span class="arithmatex">\(y(t_T)\)</span>, compatible with <code>torch.autograd</code> for backpropagation.</p>
          </div>
        </li>
    </ul>


<details class="note" open>
  <summary>Note</summary>
  <p>This function wraps <code>FDEAdjointMethod.apply</code>. Ensure <code>func</code> contains parameters that require gradients if parameter optimization is desired.</p>
</details>
          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1362">1362</a></span>
<span class="normal"><a href="#__codelineno-0-1363">1363</a></span>
<span class="normal"><a href="#__codelineno-0-1364">1364</a></span>
<span class="normal"><a href="#__codelineno-0-1365">1365</a></span>
<span class="normal"><a href="#__codelineno-0-1366">1366</a></span>
<span class="normal"><a href="#__codelineno-0-1367">1367</a></span>
<span class="normal"><a href="#__codelineno-0-1368">1368</a></span>
<span class="normal"><a href="#__codelineno-0-1369">1369</a></span>
<span class="normal"><a href="#__codelineno-0-1370">1370</a></span>
<span class="normal"><a href="#__codelineno-0-1371">1371</a></span>
<span class="normal"><a href="#__codelineno-0-1372">1372</a></span>
<span class="normal"><a href="#__codelineno-0-1373">1373</a></span>
<span class="normal"><a href="#__codelineno-0-1374">1374</a></span>
<span class="normal"><a href="#__codelineno-0-1375">1375</a></span>
<span class="normal"><a href="#__codelineno-0-1376">1376</a></span>
<span class="normal"><a href="#__codelineno-0-1377">1377</a></span>
<span class="normal"><a href="#__codelineno-0-1378">1378</a></span>
<span class="normal"><a href="#__codelineno-0-1379">1379</a></span>
<span class="normal"><a href="#__codelineno-0-1380">1380</a></span>
<span class="normal"><a href="#__codelineno-0-1381">1381</a></span>
<span class="normal"><a href="#__codelineno-0-1382">1382</a></span>
<span class="normal"><a href="#__codelineno-0-1383">1383</a></span>
<span class="normal"><a href="#__codelineno-0-1384">1384</a></span>
<span class="normal"><a href="#__codelineno-0-1385">1385</a></span>
<span class="normal"><a href="#__codelineno-0-1386">1386</a></span>
<span class="normal"><a href="#__codelineno-0-1387">1387</a></span>
<span class="normal"><a href="#__codelineno-0-1388">1388</a></span>
<span class="normal"><a href="#__codelineno-0-1389">1389</a></span>
<span class="normal"><a href="#__codelineno-0-1390">1390</a></span>
<span class="normal"><a href="#__codelineno-0-1391">1391</a></span>
<span class="normal"><a href="#__codelineno-0-1392">1392</a></span>
<span class="normal"><a href="#__codelineno-0-1393">1393</a></span>
<span class="normal"><a href="#__codelineno-0-1394">1394</a></span>
<span class="normal"><a href="#__codelineno-0-1395">1395</a></span>
<span class="normal"><a href="#__codelineno-0-1396">1396</a></span>
<span class="normal"><a href="#__codelineno-0-1397">1397</a></span>
<span class="normal"><a href="#__codelineno-0-1398">1398</a></span>
<span class="normal"><a href="#__codelineno-0-1399">1399</a></span>
<span class="normal"><a href="#__codelineno-0-1400">1400</a></span>
<span class="normal"><a href="#__codelineno-0-1401">1401</a></span>
<span class="normal"><a href="#__codelineno-0-1402">1402</a></span>
<span class="normal"><a href="#__codelineno-0-1403">1403</a></span>
<span class="normal"><a href="#__codelineno-0-1404">1404</a></span>
<span class="normal"><a href="#__codelineno-0-1405">1405</a></span>
<span class="normal"><a href="#__codelineno-0-1406">1406</a></span>
<span class="normal"><a href="#__codelineno-0-1407">1407</a></span>
<span class="normal"><a href="#__codelineno-0-1408">1408</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1362"><a id="__codelineno-0-1362" name="__codelineno-0-1362"></a><span class="k">def</span><span class="w"> </span><span class="nf">fdeint_adjoint</span><span class="p">(</span>
</span><span id="__span-0-1363"><a id="__codelineno-0-1363" name="__codelineno-0-1363"></a>    <span class="n">func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]],</span>
</span><span id="__span-0-1364"><a id="__codelineno-0-1364" name="__codelineno-0-1364"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-1365"><a id="__codelineno-0-1365" name="__codelineno-0-1365"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]],</span>
</span><span id="__span-0-1366"><a id="__codelineno-0-1366" name="__codelineno-0-1366"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-1367"><a id="__codelineno-0-1367" name="__codelineno-0-1367"></a>    <span class="n">method</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="__span-0-1368"><a id="__codelineno-0-1368" name="__codelineno-0-1368"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1369"><a id="__codelineno-0-1369" name="__codelineno-0-1369"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
</span><span id="__span-0-1370"><a id="__codelineno-0-1370" name="__codelineno-0-1370"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-1371"><a id="__codelineno-0-1371" name="__codelineno-0-1371"></a><span class="sd">    Solves a Fractional Differential Equation (FDE) with adjoint sensitivity analysis.</span>
</span><span id="__span-0-1372"><a id="__codelineno-0-1372" name="__codelineno-0-1372"></a>
</span><span id="__span-0-1373"><a id="__codelineno-0-1373" name="__codelineno-0-1373"></a><span class="sd">    This function enables gradient-based optimization of both the initial states $y_0$ and</span>
</span><span id="__span-0-1374"><a id="__codelineno-0-1374" name="__codelineno-0-1374"></a><span class="sd">    the parameters of the ODE function `func` (e.g., neural network weights) with respect to</span>
</span><span id="__span-0-1375"><a id="__codelineno-0-1375" name="__codelineno-0-1375"></a><span class="sd">    a loss function defined on the solution trajectory. It uses the continuous adjoint method</span>
</span><span id="__span-0-1376"><a id="__codelineno-0-1376" name="__codelineno-0-1376"></a><span class="sd">    adapted for fractional calculus.</span>
</span><span id="__span-0-1377"><a id="__codelineno-0-1377" name="__codelineno-0-1377"></a>
</span><span id="__span-0-1378"><a id="__codelineno-0-1378" name="__codelineno-0-1378"></a><span class="sd">    The workflow involves:</span>
</span><span id="__span-0-1379"><a id="__codelineno-0-1379" name="__codelineno-0-1379"></a>
</span><span id="__span-0-1380"><a id="__codelineno-0-1380" name="__codelineno-0-1380"></a><span class="sd">    1. **Forward Pass**: Solving $D^\alpha y(t) = f(t, y(t), \theta)$ to obtain $y(T)$.</span>
</span><span id="__span-0-1381"><a id="__codelineno-0-1381" name="__codelineno-0-1381"></a><span class="sd">    2. **Backward Pass**: Solving the augmented adjoint equation to compute $\frac{\partial L}{\partial y_0}$</span>
</span><span id="__span-0-1382"><a id="__codelineno-0-1382" name="__codelineno-0-1382"></a><span class="sd">       and $\frac{\partial L}{\partial \theta}$.</span>
</span><span id="__span-0-1383"><a id="__codelineno-0-1383" name="__codelineno-0-1383"></a>
</span><span id="__span-0-1384"><a id="__codelineno-0-1384" name="__codelineno-0-1384"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1385"><a id="__codelineno-0-1385" name="__codelineno-0-1385"></a><span class="sd">        func: The ODE function $f(t, y, \theta)$. Must accept `(t, y_tuple)` and return a tuple of tensors.</span>
</span><span id="__span-0-1386"><a id="__codelineno-0-1386" name="__codelineno-0-1386"></a><span class="sd">              Parameters $\theta$ are implicitly captured from the function&#39;s scope or registered modules.</span>
</span><span id="__span-0-1387"><a id="__codelineno-0-1387" name="__codelineno-0-1387"></a><span class="sd">        y0_tuple: A tuple of initial state tensors $(y_1^0, \dots, y_N^0)$.</span>
</span><span id="__span-0-1388"><a id="__codelineno-0-1388" name="__codelineno-0-1388"></a><span class="sd">        alpha: The fractional order(s). Can be a scalar, a tensor, or a list depending on the solver configuration.</span>
</span><span id="__span-0-1389"><a id="__codelineno-0-1389" name="__codelineno-0-1389"></a><span class="sd">        t_grid: A 1D tensor of time points $[t_0, t_1, \dots, t_T]$ defining the integration interval.</span>
</span><span id="__span-0-1390"><a id="__codelineno-0-1390" name="__codelineno-0-1390"></a><span class="sd">        method: The numerical integration scheme identifier (e.g., `&#39;gl-f&#39;`, `&#39;trap-f&#39;`, `&#39;l1-f&#39;`).</span>
</span><span id="__span-0-1391"><a id="__codelineno-0-1391" name="__codelineno-0-1391"></a><span class="sd">                Suffixes `-f` indicate full history storage required for adjoint, `-o` for optimized/no-history.</span>
</span><span id="__span-0-1392"><a id="__codelineno-0-1392" name="__codelineno-0-1392"></a><span class="sd">        memory: Optional integer to limit the memory length for convolution sums (short-memory principle).</span>
</span><span id="__span-0-1393"><a id="__codelineno-0-1393" name="__codelineno-0-1393"></a><span class="sd">                If `None`, full history is used.</span>
</span><span id="__span-0-1394"><a id="__codelineno-0-1394" name="__codelineno-0-1394"></a>
</span><span id="__span-0-1395"><a id="__codelineno-0-1395" name="__codelineno-0-1395"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1396"><a id="__codelineno-0-1396" name="__codelineno-0-1396"></a><span class="sd">        A tuple of tensors representing the solution at the final time point $y(t_T)$, compatible with `torch.autograd` for backpropagation.</span>
</span><span id="__span-0-1397"><a id="__codelineno-0-1397" name="__codelineno-0-1397"></a>
</span><span id="__span-0-1398"><a id="__codelineno-0-1398" name="__codelineno-0-1398"></a><span class="sd">    Note:</span>
</span><span id="__span-0-1399"><a id="__codelineno-0-1399" name="__codelineno-0-1399"></a><span class="sd">        This function wraps `FDEAdjointMethod.apply`. Ensure `func` contains parameters that require gradients if parameter optimization is desired.</span>
</span><span id="__span-0-1400"><a id="__codelineno-0-1400" name="__codelineno-0-1400"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-1401"><a id="__codelineno-0-1401" name="__codelineno-0-1401"></a>    <span class="c1"># params = tuple(p for p in func.parameters())  # 或只取 requires_grad=True 的</span>
</span><span id="__span-0-1402"><a id="__codelineno-0-1402" name="__codelineno-0-1402"></a>    <span class="n">params</span> <span class="o">=</span> <span class="n">find_parameters</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
</span><span id="__span-0-1403"><a id="__codelineno-0-1403" name="__codelineno-0-1403"></a>    <span class="n">n_state</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">)</span>
</span><span id="__span-0-1404"><a id="__codelineno-0-1404" name="__codelineno-0-1404"></a>    <span class="n">n_params</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</span><span id="__span-0-1405"><a id="__codelineno-0-1405" name="__codelineno-0-1405"></a>    <span class="c1"># 注意：apply 不接受关键字参数；把计数放在前两位最简单</span>
</span><span id="__span-0-1406"><a id="__codelineno-0-1406" name="__codelineno-0-1406"></a>    <span class="k">return</span> <span class="n">FDEAdjointMethod</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
</span><span id="__span-0-1407"><a id="__codelineno-0-1407" name="__codelineno-0-1407"></a>        <span class="n">func</span><span class="p">,</span> <span class="n">n_state</span><span class="p">,</span> <span class="n">n_params</span><span class="p">,</span> <span class="o">*</span><span class="n">y0_tuple</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">t_grid</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="o">*</span><span class="n">params</span><span class="p">,</span> <span class="n">memory</span>
</span><span id="__span-0-1408"><a id="__codelineno-0-1408" name="__codelineno-0-1408"></a>    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.forward_euler_wo_history" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">forward_euler_wo_history</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">forward_euler_wo_history</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Explicit Euler integration without storing full history.</p>
<p>Solves <span class="arithmatex">\(y_{k+1} = y_k + h \cdot f(t_k, y_k)\)</span>.
This variant is memory-efficient (<span class="arithmatex">\(O(1)\)</span>) but insufficient for methods requiring
history-dependent adjoints unless combined with checkpointing. Used primarily for
integer-order baselines or specific optimized paths.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></code>)
          –
          <div class="doc-md-description">
            <p>Function <span class="arithmatex">\(f(t, y)\)</span>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y0_tuple</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]</code>)
          –
          <div class="doc-md-description">
            <p>Initial state tuple.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>alpha</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></code>)
          –
          <div class="doc-md-description">
            <p>Fractional order (unused in standard Euler, kept for signature compatibility).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Time grid tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Unused.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]</code>
          –
          <div class="doc-md-description">
            <p>List of final state tensors (not a list of lists).</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1646">1646</a></span>
<span class="normal"><a href="#__codelineno-0-1647">1647</a></span>
<span class="normal"><a href="#__codelineno-0-1648">1648</a></span>
<span class="normal"><a href="#__codelineno-0-1649">1649</a></span>
<span class="normal"><a href="#__codelineno-0-1650">1650</a></span>
<span class="normal"><a href="#__codelineno-0-1651">1651</a></span>
<span class="normal"><a href="#__codelineno-0-1652">1652</a></span>
<span class="normal"><a href="#__codelineno-0-1653">1653</a></span>
<span class="normal"><a href="#__codelineno-0-1654">1654</a></span>
<span class="normal"><a href="#__codelineno-0-1655">1655</a></span>
<span class="normal"><a href="#__codelineno-0-1656">1656</a></span>
<span class="normal"><a href="#__codelineno-0-1657">1657</a></span>
<span class="normal"><a href="#__codelineno-0-1658">1658</a></span>
<span class="normal"><a href="#__codelineno-0-1659">1659</a></span>
<span class="normal"><a href="#__codelineno-0-1660">1660</a></span>
<span class="normal"><a href="#__codelineno-0-1661">1661</a></span>
<span class="normal"><a href="#__codelineno-0-1662">1662</a></span>
<span class="normal"><a href="#__codelineno-0-1663">1663</a></span>
<span class="normal"><a href="#__codelineno-0-1664">1664</a></span>
<span class="normal"><a href="#__codelineno-0-1665">1665</a></span>
<span class="normal"><a href="#__codelineno-0-1666">1666</a></span>
<span class="normal"><a href="#__codelineno-0-1667">1667</a></span>
<span class="normal"><a href="#__codelineno-0-1668">1668</a></span>
<span class="normal"><a href="#__codelineno-0-1669">1669</a></span>
<span class="normal"><a href="#__codelineno-0-1670">1670</a></span>
<span class="normal"><a href="#__codelineno-0-1671">1671</a></span>
<span class="normal"><a href="#__codelineno-0-1672">1672</a></span>
<span class="normal"><a href="#__codelineno-0-1673">1673</a></span>
<span class="normal"><a href="#__codelineno-0-1674">1674</a></span>
<span class="normal"><a href="#__codelineno-0-1675">1675</a></span>
<span class="normal"><a href="#__codelineno-0-1676">1676</a></span>
<span class="normal"><a href="#__codelineno-0-1677">1677</a></span>
<span class="normal"><a href="#__codelineno-0-1678">1678</a></span>
<span class="normal"><a href="#__codelineno-0-1679">1679</a></span>
<span class="normal"><a href="#__codelineno-0-1680">1680</a></span>
<span class="normal"><a href="#__codelineno-0-1681">1681</a></span>
<span class="normal"><a href="#__codelineno-0-1682">1682</a></span>
<span class="normal"><a href="#__codelineno-0-1683">1683</a></span>
<span class="normal"><a href="#__codelineno-0-1684">1684</a></span>
<span class="normal"><a href="#__codelineno-0-1685">1685</a></span>
<span class="normal"><a href="#__codelineno-0-1686">1686</a></span>
<span class="normal"><a href="#__codelineno-0-1687">1687</a></span>
<span class="normal"><a href="#__codelineno-0-1688">1688</a></span>
<span class="normal"><a href="#__codelineno-0-1689">1689</a></span>
<span class="normal"><a href="#__codelineno-0-1690">1690</a></span>
<span class="normal"><a href="#__codelineno-0-1691">1691</a></span>
<span class="normal"><a href="#__codelineno-0-1692">1692</a></span>
<span class="normal"><a href="#__codelineno-0-1693">1693</a></span>
<span class="normal"><a href="#__codelineno-0-1694">1694</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1646"><a id="__codelineno-0-1646" name="__codelineno-0-1646"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward_euler_wo_history</span><span class="p">(</span>
</span><span id="__span-0-1647"><a id="__codelineno-0-1647" name="__codelineno-0-1647"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
</span><span id="__span-0-1648"><a id="__codelineno-0-1648" name="__codelineno-0-1648"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-1649"><a id="__codelineno-0-1649" name="__codelineno-0-1649"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span id="__span-0-1650"><a id="__codelineno-0-1650" name="__codelineno-0-1650"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-1651"><a id="__codelineno-0-1651" name="__codelineno-0-1651"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1652"><a id="__codelineno-0-1652" name="__codelineno-0-1652"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="__span-0-1653"><a id="__codelineno-0-1653" name="__codelineno-0-1653"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-1654"><a id="__codelineno-0-1654" name="__codelineno-0-1654"></a><span class="sd">    Explicit Euler integration without storing full history.</span>
</span><span id="__span-0-1655"><a id="__codelineno-0-1655" name="__codelineno-0-1655"></a>
</span><span id="__span-0-1656"><a id="__codelineno-0-1656" name="__codelineno-0-1656"></a><span class="sd">    Solves $y_{k+1} = y_k + h \cdot f(t_k, y_k)$.</span>
</span><span id="__span-0-1657"><a id="__codelineno-0-1657" name="__codelineno-0-1657"></a><span class="sd">    This variant is memory-efficient ($O(1)$) but insufficient for methods requiring</span>
</span><span id="__span-0-1658"><a id="__codelineno-0-1658" name="__codelineno-0-1658"></a><span class="sd">    history-dependent adjoints unless combined with checkpointing. Used primarily for</span>
</span><span id="__span-0-1659"><a id="__codelineno-0-1659" name="__codelineno-0-1659"></a><span class="sd">    integer-order baselines or specific optimized paths.</span>
</span><span id="__span-0-1660"><a id="__codelineno-0-1660" name="__codelineno-0-1660"></a>
</span><span id="__span-0-1661"><a id="__codelineno-0-1661" name="__codelineno-0-1661"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1662"><a id="__codelineno-0-1662" name="__codelineno-0-1662"></a><span class="sd">        ode_func: Function $f(t, y)$.</span>
</span><span id="__span-0-1663"><a id="__codelineno-0-1663" name="__codelineno-0-1663"></a><span class="sd">        y0_tuple: Initial state tuple.</span>
</span><span id="__span-0-1664"><a id="__codelineno-0-1664" name="__codelineno-0-1664"></a><span class="sd">        alpha: Fractional order (unused in standard Euler, kept for signature compatibility).</span>
</span><span id="__span-0-1665"><a id="__codelineno-0-1665" name="__codelineno-0-1665"></a><span class="sd">        t_grid: Time grid tensor.</span>
</span><span id="__span-0-1666"><a id="__codelineno-0-1666" name="__codelineno-0-1666"></a><span class="sd">        memory: Unused.</span>
</span><span id="__span-0-1667"><a id="__codelineno-0-1667" name="__codelineno-0-1667"></a>
</span><span id="__span-0-1668"><a id="__codelineno-0-1668" name="__codelineno-0-1668"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1669"><a id="__codelineno-0-1669" name="__codelineno-0-1669"></a><span class="sd">        List of final state tensors (not a list of lists).</span>
</span><span id="__span-0-1670"><a id="__codelineno-0-1670" name="__codelineno-0-1670"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-1671"><a id="__codelineno-0-1671" name="__codelineno-0-1671"></a>    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
</span><span id="__span-0-1672"><a id="__codelineno-0-1672" name="__codelineno-0-1672"></a>    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_grid</span><span class="p">)</span>
</span><span id="__span-0-1673"><a id="__codelineno-0-1673" name="__codelineno-0-1673"></a>    <span class="k">assert</span> <span class="n">N</span> <span class="o">&gt;=</span> <span class="mi">2</span>
</span><span id="__span-0-1674"><a id="__codelineno-0-1674" name="__codelineno-0-1674"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">y0_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
</span><span id="__span-0-1675"><a id="__codelineno-0-1675" name="__codelineno-0-1675"></a>    <span class="n">dtype</span> <span class="o">=</span> <span class="n">y0_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-1676"><a id="__codelineno-0-1676" name="__codelineno-0-1676"></a>    <span class="n">t_grid</span> <span class="o">=</span> <span class="n">t_grid</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-1677"><a id="__codelineno-0-1677" name="__codelineno-0-1677"></a>
</span><span id="__span-0-1678"><a id="__codelineno-0-1678" name="__codelineno-0-1678"></a>    <span class="c1"># Initialize history lists for each component</span>
</span><span id="__span-0-1679"><a id="__codelineno-0-1679" name="__codelineno-0-1679"></a>
</span><span id="__span-0-1680"><a id="__codelineno-0-1680" name="__codelineno-0-1680"></a>    <span class="c1"># Clone initial values</span>
</span><span id="__span-0-1681"><a id="__codelineno-0-1681" name="__codelineno-0-1681"></a>    <span class="n">y</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">)</span>
</span><span id="__span-0-1682"><a id="__codelineno-0-1682" name="__codelineno-0-1682"></a>
</span><span id="__span-0-1683"><a id="__codelineno-0-1683" name="__codelineno-0-1683"></a>    <span class="c1"># Euler integration: y_{k+1} = y_k + dt * f(t_k, y_k)</span>
</span><span id="__span-0-1684"><a id="__codelineno-0-1684" name="__codelineno-0-1684"></a>    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-1685"><a id="__codelineno-0-1685" name="__codelineno-0-1685"></a>        <span class="n">tk</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
</span><span id="__span-0-1686"><a id="__codelineno-0-1686" name="__codelineno-0-1686"></a>        <span class="n">dt</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># Scalar tensor, will broadcast automatically</span>
</span><span id="__span-0-1687"><a id="__codelineno-0-1687" name="__codelineno-0-1687"></a>        <span class="n">dy</span> <span class="o">=</span> <span class="n">ode_func</span><span class="p">(</span><span class="n">tk</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>  <span class="c1"># Expect tuple return, consistent with y structure</span>
</span><span id="__span-0-1688"><a id="__codelineno-0-1688" name="__codelineno-0-1688"></a>        <span class="c1"># assert isinstance(dy, tuple) and len(dy) == len(y)</span>
</span><span id="__span-0-1689"><a id="__codelineno-0-1689" name="__codelineno-0-1689"></a>        <span class="c1"># Update all integrated components except the last one</span>
</span><span id="__span-0-1690"><a id="__codelineno-0-1690" name="__codelineno-0-1690"></a>        <span class="c1"># for i in range(len(y)):</span>
</span><span id="__span-0-1691"><a id="__codelineno-0-1691" name="__codelineno-0-1691"></a>        <span class="c1">#     y[i] = y[i] + dt * dy[i]</span>
</span><span id="__span-0-1692"><a id="__codelineno-0-1692" name="__codelineno-0-1692"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)):</span>
</span><span id="__span-0-1693"><a id="__codelineno-0-1693" name="__codelineno-0-1693"></a>            <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">dy</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="n">dt</span><span class="p">)</span>
</span><span id="__span-0-1694"><a id="__codelineno-0-1694" name="__codelineno-0-1694"></a>    <span class="k">return</span> <span class="n">y</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.backward_euler_wo_history" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">backward_euler_wo_history</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">backward_euler_wo_history</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y_aug</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">y_finalstate</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">],</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Backward integration for Euler method without full history dependency.</p>
<p>Since Euler has no memory term, the backward pass simply integrates the adjoint
equation using the reconstructed forward trajectory (or re-evaluation).</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></code>)
          –
          <div class="doc-md-description">
            <p>Augmented dynamics function.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y_aug</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>, <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>, <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>]</code>)
          –
          <div class="doc-md-description">
            <p>Initial augmented state <code>(dummy_y, adj_y0, adj_params0)</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>alpha</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></code>)
          –
          <div class="doc-md-description">
            <p>Unused.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Flipped time grid.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y_finalstate</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]</code>)
          –
          <div class="doc-md-description">
            <p>Final state from forward pass (used as starting point for reconstruction if needed).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Unused.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>], <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>
          –
          <div class="doc-md-description">
            <p>Tuple of <code>(final_adj_y, final_adj_params)</code>.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1697">1697</a></span>
<span class="normal"><a href="#__codelineno-0-1698">1698</a></span>
<span class="normal"><a href="#__codelineno-0-1699">1699</a></span>
<span class="normal"><a href="#__codelineno-0-1700">1700</a></span>
<span class="normal"><a href="#__codelineno-0-1701">1701</a></span>
<span class="normal"><a href="#__codelineno-0-1702">1702</a></span>
<span class="normal"><a href="#__codelineno-0-1703">1703</a></span>
<span class="normal"><a href="#__codelineno-0-1704">1704</a></span>
<span class="normal"><a href="#__codelineno-0-1705">1705</a></span>
<span class="normal"><a href="#__codelineno-0-1706">1706</a></span>
<span class="normal"><a href="#__codelineno-0-1707">1707</a></span>
<span class="normal"><a href="#__codelineno-0-1708">1708</a></span>
<span class="normal"><a href="#__codelineno-0-1709">1709</a></span>
<span class="normal"><a href="#__codelineno-0-1710">1710</a></span>
<span class="normal"><a href="#__codelineno-0-1711">1711</a></span>
<span class="normal"><a href="#__codelineno-0-1712">1712</a></span>
<span class="normal"><a href="#__codelineno-0-1713">1713</a></span>
<span class="normal"><a href="#__codelineno-0-1714">1714</a></span>
<span class="normal"><a href="#__codelineno-0-1715">1715</a></span>
<span class="normal"><a href="#__codelineno-0-1716">1716</a></span>
<span class="normal"><a href="#__codelineno-0-1717">1717</a></span>
<span class="normal"><a href="#__codelineno-0-1718">1718</a></span>
<span class="normal"><a href="#__codelineno-0-1719">1719</a></span>
<span class="normal"><a href="#__codelineno-0-1720">1720</a></span>
<span class="normal"><a href="#__codelineno-0-1721">1721</a></span>
<span class="normal"><a href="#__codelineno-0-1722">1722</a></span>
<span class="normal"><a href="#__codelineno-0-1723">1723</a></span>
<span class="normal"><a href="#__codelineno-0-1724">1724</a></span>
<span class="normal"><a href="#__codelineno-0-1725">1725</a></span>
<span class="normal"><a href="#__codelineno-0-1726">1726</a></span>
<span class="normal"><a href="#__codelineno-0-1727">1727</a></span>
<span class="normal"><a href="#__codelineno-0-1728">1728</a></span>
<span class="normal"><a href="#__codelineno-0-1729">1729</a></span>
<span class="normal"><a href="#__codelineno-0-1730">1730</a></span>
<span class="normal"><a href="#__codelineno-0-1731">1731</a></span>
<span class="normal"><a href="#__codelineno-0-1732">1732</a></span>
<span class="normal"><a href="#__codelineno-0-1733">1733</a></span>
<span class="normal"><a href="#__codelineno-0-1734">1734</a></span>
<span class="normal"><a href="#__codelineno-0-1735">1735</a></span>
<span class="normal"><a href="#__codelineno-0-1736">1736</a></span>
<span class="normal"><a href="#__codelineno-0-1737">1737</a></span>
<span class="normal"><a href="#__codelineno-0-1738">1738</a></span>
<span class="normal"><a href="#__codelineno-0-1739">1739</a></span>
<span class="normal"><a href="#__codelineno-0-1740">1740</a></span>
<span class="normal"><a href="#__codelineno-0-1741">1741</a></span>
<span class="normal"><a href="#__codelineno-0-1742">1742</a></span>
<span class="normal"><a href="#__codelineno-0-1743">1743</a></span>
<span class="normal"><a href="#__codelineno-0-1744">1744</a></span>
<span class="normal"><a href="#__codelineno-0-1745">1745</a></span>
<span class="normal"><a href="#__codelineno-0-1746">1746</a></span>
<span class="normal"><a href="#__codelineno-0-1747">1747</a></span>
<span class="normal"><a href="#__codelineno-0-1748">1748</a></span>
<span class="normal"><a href="#__codelineno-0-1749">1749</a></span>
<span class="normal"><a href="#__codelineno-0-1750">1750</a></span>
<span class="normal"><a href="#__codelineno-0-1751">1751</a></span>
<span class="normal"><a href="#__codelineno-0-1752">1752</a></span>
<span class="normal"><a href="#__codelineno-0-1753">1753</a></span>
<span class="normal"><a href="#__codelineno-0-1754">1754</a></span>
<span class="normal"><a href="#__codelineno-0-1755">1755</a></span>
<span class="normal"><a href="#__codelineno-0-1756">1756</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1697"><a id="__codelineno-0-1697" name="__codelineno-0-1697"></a><span class="k">def</span><span class="w"> </span><span class="nf">backward_euler_wo_history</span><span class="p">(</span>
</span><span id="__span-0-1698"><a id="__codelineno-0-1698" name="__codelineno-0-1698"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
</span><span id="__span-0-1699"><a id="__codelineno-0-1699" name="__codelineno-0-1699"></a>    <span class="n">y_aug</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">],</span>
</span><span id="__span-0-1700"><a id="__codelineno-0-1700" name="__codelineno-0-1700"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span id="__span-0-1701"><a id="__codelineno-0-1701" name="__codelineno-0-1701"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-1702"><a id="__codelineno-0-1702" name="__codelineno-0-1702"></a>    <span class="n">y_finalstate</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="__span-0-1703"><a id="__codelineno-0-1703" name="__codelineno-0-1703"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1704"><a id="__codelineno-0-1704" name="__codelineno-0-1704"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="__span-0-1705"><a id="__codelineno-0-1705" name="__codelineno-0-1705"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-1706"><a id="__codelineno-0-1706" name="__codelineno-0-1706"></a><span class="sd">    Backward integration for Euler method without full history dependency.</span>
</span><span id="__span-0-1707"><a id="__codelineno-0-1707" name="__codelineno-0-1707"></a>
</span><span id="__span-0-1708"><a id="__codelineno-0-1708" name="__codelineno-0-1708"></a><span class="sd">    Since Euler has no memory term, the backward pass simply integrates the adjoint</span>
</span><span id="__span-0-1709"><a id="__codelineno-0-1709" name="__codelineno-0-1709"></a><span class="sd">    equation using the reconstructed forward trajectory (or re-evaluation).</span>
</span><span id="__span-0-1710"><a id="__codelineno-0-1710" name="__codelineno-0-1710"></a>
</span><span id="__span-0-1711"><a id="__codelineno-0-1711" name="__codelineno-0-1711"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1712"><a id="__codelineno-0-1712" name="__codelineno-0-1712"></a><span class="sd">        ode_func: Augmented dynamics function.</span>
</span><span id="__span-0-1713"><a id="__codelineno-0-1713" name="__codelineno-0-1713"></a><span class="sd">        y_aug: Initial augmented state `(dummy_y, adj_y0, adj_params0)`.</span>
</span><span id="__span-0-1714"><a id="__codelineno-0-1714" name="__codelineno-0-1714"></a><span class="sd">        alpha: Unused.</span>
</span><span id="__span-0-1715"><a id="__codelineno-0-1715" name="__codelineno-0-1715"></a><span class="sd">        t_grid: Flipped time grid.</span>
</span><span id="__span-0-1716"><a id="__codelineno-0-1716" name="__codelineno-0-1716"></a><span class="sd">        y_finalstate: Final state from forward pass (used as starting point for reconstruction if needed).</span>
</span><span id="__span-0-1717"><a id="__codelineno-0-1717" name="__codelineno-0-1717"></a><span class="sd">        memory: Unused.</span>
</span><span id="__span-0-1718"><a id="__codelineno-0-1718" name="__codelineno-0-1718"></a>
</span><span id="__span-0-1719"><a id="__codelineno-0-1719" name="__codelineno-0-1719"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1720"><a id="__codelineno-0-1720" name="__codelineno-0-1720"></a><span class="sd">        Tuple of `(final_adj_y, final_adj_params)`.</span>
</span><span id="__span-0-1721"><a id="__codelineno-0-1721" name="__codelineno-0-1721"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-1722"><a id="__codelineno-0-1722" name="__codelineno-0-1722"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="__span-0-1723"><a id="__codelineno-0-1723" name="__codelineno-0-1723"></a>        <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_grid</span><span class="p">)</span>
</span><span id="__span-0-1724"><a id="__codelineno-0-1724" name="__codelineno-0-1724"></a>        <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]))</span>  <span class="c1"># uniform step size</span>
</span><span id="__span-0-1725"><a id="__codelineno-0-1725" name="__codelineno-0-1725"></a>        <span class="n">h</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
</span><span id="__span-0-1726"><a id="__codelineno-0-1726" name="__codelineno-0-1726"></a>
</span><span id="__span-0-1727"><a id="__codelineno-0-1727" name="__codelineno-0-1727"></a>        <span class="n">_</span><span class="p">,</span> <span class="n">adj_y0</span><span class="p">,</span> <span class="n">adj_params0</span> <span class="o">=</span> <span class="n">y_aug</span>
</span><span id="__span-0-1728"><a id="__codelineno-0-1728" name="__codelineno-0-1728"></a>        <span class="c1"># 初始化</span>
</span><span id="__span-0-1729"><a id="__codelineno-0-1729" name="__codelineno-0-1729"></a>        <span class="c1"># y_state = [x.detach().clone() for x in y_finalstate]</span>
</span><span id="__span-0-1730"><a id="__codelineno-0-1730" name="__codelineno-0-1730"></a>        <span class="c1"># adj_y = [x.detach().clone() for x in adj_y0]</span>
</span><span id="__span-0-1731"><a id="__codelineno-0-1731" name="__codelineno-0-1731"></a>        <span class="c1"># adj_params = tuple(p.detach().clone() for p in adj_params0) if adj_params0 else ()</span>
</span><span id="__span-0-1732"><a id="__codelineno-0-1732" name="__codelineno-0-1732"></a>        <span class="n">y_state</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_finalstate</span><span class="p">)</span>
</span><span id="__span-0-1733"><a id="__codelineno-0-1733" name="__codelineno-0-1733"></a>        <span class="n">adj_y</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">adj_y0</span><span class="p">)</span>
</span><span id="__span-0-1734"><a id="__codelineno-0-1734" name="__codelineno-0-1734"></a>        <span class="n">adj_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">adj_params0</span><span class="p">)</span>
</span><span id="__span-0-1735"><a id="__codelineno-0-1735" name="__codelineno-0-1735"></a>
</span><span id="__span-0-1736"><a id="__codelineno-0-1736" name="__codelineno-0-1736"></a>        <span class="c1"># return [x.detach().clone() for x in adj_y0], [x.detach().clone() for x in adj_params0]</span>
</span><span id="__span-0-1737"><a id="__codelineno-0-1737" name="__codelineno-0-1737"></a>
</span><span id="__span-0-1738"><a id="__codelineno-0-1738" name="__codelineno-0-1738"></a>        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-1739"><a id="__codelineno-0-1739" name="__codelineno-0-1739"></a>            <span class="n">tk</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
</span><span id="__span-0-1740"><a id="__codelineno-0-1740" name="__codelineno-0-1740"></a>
</span><span id="__span-0-1741"><a id="__codelineno-0-1741" name="__codelineno-0-1741"></a>            <span class="c1"># 调用 augmented dynamics</span>
</span><span id="__span-0-1742"><a id="__codelineno-0-1742" name="__codelineno-0-1742"></a>            <span class="n">func_eval</span><span class="p">,</span> <span class="n">vjp_y</span><span class="p">,</span> <span class="n">vjp_params</span> <span class="o">=</span> <span class="n">ode_func</span><span class="p">(</span><span class="n">tk</span><span class="p">,</span> <span class="p">(</span><span class="n">y_state</span><span class="p">,</span> <span class="n">adj_y</span><span class="p">,</span> <span class="n">adj_params</span><span class="p">))</span>
</span><span id="__span-0-1743"><a id="__codelineno-0-1743" name="__codelineno-0-1743"></a>
</span><span id="__span-0-1744"><a id="__codelineno-0-1744" name="__codelineno-0-1744"></a>            <span class="c1"># 更新状态</span>
</span><span id="__span-0-1745"><a id="__codelineno-0-1745" name="__codelineno-0-1745"></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">adj_y</span><span class="p">)):</span>
</span><span id="__span-0-1746"><a id="__codelineno-0-1746" name="__codelineno-0-1746"></a>                <span class="c1"># adj_y[i] = adj_y[i] + h * vjp_y[i]</span>
</span><span id="__span-0-1747"><a id="__codelineno-0-1747" name="__codelineno-0-1747"></a>                <span class="c1"># y_state[i] = y_state[i] - h * func_eval[i]</span>
</span><span id="__span-0-1748"><a id="__codelineno-0-1748" name="__codelineno-0-1748"></a>                <span class="n">adj_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">vjp_y</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="n">h</span><span class="p">)</span>
</span><span id="__span-0-1749"><a id="__codelineno-0-1749" name="__codelineno-0-1749"></a>                <span class="n">y_state</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">func_eval</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=-</span><span class="n">h</span><span class="p">)</span>  <span class="c1"># 注意这里是 -h（减法）</span>
</span><span id="__span-0-1750"><a id="__codelineno-0-1750" name="__codelineno-0-1750"></a>
</span><span id="__span-0-1751"><a id="__codelineno-0-1751" name="__codelineno-0-1751"></a>            <span class="c1"># 更新参数梯度</span>
</span><span id="__span-0-1752"><a id="__codelineno-0-1752" name="__codelineno-0-1752"></a>            <span class="k">if</span> <span class="n">adj_params</span> <span class="ow">and</span> <span class="n">vjp_params</span><span class="p">:</span>
</span><span id="__span-0-1753"><a id="__codelineno-0-1753" name="__codelineno-0-1753"></a>                <span class="k">for</span> <span class="n">ap</span><span class="p">,</span> <span class="n">vp</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">adj_params</span><span class="p">,</span> <span class="n">vjp_params</span><span class="p">):</span>
</span><span id="__span-0-1754"><a id="__codelineno-0-1754" name="__codelineno-0-1754"></a>                    <span class="n">ap</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">vp</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">h</span><span class="p">)</span>  <span class="c1"># 直接修改 tuple 中的张量</span>
</span><span id="__span-0-1755"><a id="__codelineno-0-1755" name="__codelineno-0-1755"></a>
</span><span id="__span-0-1756"><a id="__codelineno-0-1756" name="__codelineno-0-1756"></a>    <span class="k">return</span> <span class="n">adj_y</span><span class="p">,</span> <span class="n">adj_params</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.forward_euler_w_history" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">forward_euler_w_history</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">forward_euler_w_history</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Explicit Euler integration storing full history.</p>
<p>Required for adjoint methods that expect a history list structure consistent with
fractional solvers, even if the method itself is memory-less.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></code>)
          –
          <div class="doc-md-description">
            <p>Function <span class="arithmatex">\(f(t, y)\)</span>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y0_tuple</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]</code>)
          –
          <div class="doc-md-description">
            <p>Initial state tuple.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>alpha</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></code>)
          –
          <div class="doc-md-description">
            <p>Unused.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Time grid.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Unused.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>
          –
          <div class="doc-md-description">
            <p>List of lists, where each inner list contains the trajectory of one state component.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1759">1759</a></span>
<span class="normal"><a href="#__codelineno-0-1760">1760</a></span>
<span class="normal"><a href="#__codelineno-0-1761">1761</a></span>
<span class="normal"><a href="#__codelineno-0-1762">1762</a></span>
<span class="normal"><a href="#__codelineno-0-1763">1763</a></span>
<span class="normal"><a href="#__codelineno-0-1764">1764</a></span>
<span class="normal"><a href="#__codelineno-0-1765">1765</a></span>
<span class="normal"><a href="#__codelineno-0-1766">1766</a></span>
<span class="normal"><a href="#__codelineno-0-1767">1767</a></span>
<span class="normal"><a href="#__codelineno-0-1768">1768</a></span>
<span class="normal"><a href="#__codelineno-0-1769">1769</a></span>
<span class="normal"><a href="#__codelineno-0-1770">1770</a></span>
<span class="normal"><a href="#__codelineno-0-1771">1771</a></span>
<span class="normal"><a href="#__codelineno-0-1772">1772</a></span>
<span class="normal"><a href="#__codelineno-0-1773">1773</a></span>
<span class="normal"><a href="#__codelineno-0-1774">1774</a></span>
<span class="normal"><a href="#__codelineno-0-1775">1775</a></span>
<span class="normal"><a href="#__codelineno-0-1776">1776</a></span>
<span class="normal"><a href="#__codelineno-0-1777">1777</a></span>
<span class="normal"><a href="#__codelineno-0-1778">1778</a></span>
<span class="normal"><a href="#__codelineno-0-1779">1779</a></span>
<span class="normal"><a href="#__codelineno-0-1780">1780</a></span>
<span class="normal"><a href="#__codelineno-0-1781">1781</a></span>
<span class="normal"><a href="#__codelineno-0-1782">1782</a></span>
<span class="normal"><a href="#__codelineno-0-1783">1783</a></span>
<span class="normal"><a href="#__codelineno-0-1784">1784</a></span>
<span class="normal"><a href="#__codelineno-0-1785">1785</a></span>
<span class="normal"><a href="#__codelineno-0-1786">1786</a></span>
<span class="normal"><a href="#__codelineno-0-1787">1787</a></span>
<span class="normal"><a href="#__codelineno-0-1788">1788</a></span>
<span class="normal"><a href="#__codelineno-0-1789">1789</a></span>
<span class="normal"><a href="#__codelineno-0-1790">1790</a></span>
<span class="normal"><a href="#__codelineno-0-1791">1791</a></span>
<span class="normal"><a href="#__codelineno-0-1792">1792</a></span>
<span class="normal"><a href="#__codelineno-0-1793">1793</a></span>
<span class="normal"><a href="#__codelineno-0-1794">1794</a></span>
<span class="normal"><a href="#__codelineno-0-1795">1795</a></span>
<span class="normal"><a href="#__codelineno-0-1796">1796</a></span>
<span class="normal"><a href="#__codelineno-0-1797">1797</a></span>
<span class="normal"><a href="#__codelineno-0-1798">1798</a></span>
<span class="normal"><a href="#__codelineno-0-1799">1799</a></span>
<span class="normal"><a href="#__codelineno-0-1800">1800</a></span>
<span class="normal"><a href="#__codelineno-0-1801">1801</a></span>
<span class="normal"><a href="#__codelineno-0-1802">1802</a></span>
<span class="normal"><a href="#__codelineno-0-1803">1803</a></span>
<span class="normal"><a href="#__codelineno-0-1804">1804</a></span>
<span class="normal"><a href="#__codelineno-0-1805">1805</a></span>
<span class="normal"><a href="#__codelineno-0-1806">1806</a></span>
<span class="normal"><a href="#__codelineno-0-1807">1807</a></span>
<span class="normal"><a href="#__codelineno-0-1808">1808</a></span>
<span class="normal"><a href="#__codelineno-0-1809">1809</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1759"><a id="__codelineno-0-1759" name="__codelineno-0-1759"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward_euler_w_history</span><span class="p">(</span>
</span><span id="__span-0-1760"><a id="__codelineno-0-1760" name="__codelineno-0-1760"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
</span><span id="__span-0-1761"><a id="__codelineno-0-1761" name="__codelineno-0-1761"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-1762"><a id="__codelineno-0-1762" name="__codelineno-0-1762"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span id="__span-0-1763"><a id="__codelineno-0-1763" name="__codelineno-0-1763"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-1764"><a id="__codelineno-0-1764" name="__codelineno-0-1764"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1765"><a id="__codelineno-0-1765" name="__codelineno-0-1765"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="__span-0-1766"><a id="__codelineno-0-1766" name="__codelineno-0-1766"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-1767"><a id="__codelineno-0-1767" name="__codelineno-0-1767"></a><span class="sd">    Explicit Euler integration storing full history.</span>
</span><span id="__span-0-1768"><a id="__codelineno-0-1768" name="__codelineno-0-1768"></a>
</span><span id="__span-0-1769"><a id="__codelineno-0-1769" name="__codelineno-0-1769"></a><span class="sd">    Required for adjoint methods that expect a history list structure consistent with</span>
</span><span id="__span-0-1770"><a id="__codelineno-0-1770" name="__codelineno-0-1770"></a><span class="sd">    fractional solvers, even if the method itself is memory-less.</span>
</span><span id="__span-0-1771"><a id="__codelineno-0-1771" name="__codelineno-0-1771"></a>
</span><span id="__span-0-1772"><a id="__codelineno-0-1772" name="__codelineno-0-1772"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1773"><a id="__codelineno-0-1773" name="__codelineno-0-1773"></a><span class="sd">        ode_func: Function $f(t, y)$.</span>
</span><span id="__span-0-1774"><a id="__codelineno-0-1774" name="__codelineno-0-1774"></a><span class="sd">        y0_tuple: Initial state tuple.</span>
</span><span id="__span-0-1775"><a id="__codelineno-0-1775" name="__codelineno-0-1775"></a><span class="sd">        alpha: Unused.</span>
</span><span id="__span-0-1776"><a id="__codelineno-0-1776" name="__codelineno-0-1776"></a><span class="sd">        t_grid: Time grid.</span>
</span><span id="__span-0-1777"><a id="__codelineno-0-1777" name="__codelineno-0-1777"></a><span class="sd">        memory: Unused.</span>
</span><span id="__span-0-1778"><a id="__codelineno-0-1778" name="__codelineno-0-1778"></a>
</span><span id="__span-0-1779"><a id="__codelineno-0-1779" name="__codelineno-0-1779"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1780"><a id="__codelineno-0-1780" name="__codelineno-0-1780"></a><span class="sd">        List of lists, where each inner list contains the trajectory of one state component.</span>
</span><span id="__span-0-1781"><a id="__codelineno-0-1781" name="__codelineno-0-1781"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-1782"><a id="__codelineno-0-1782" name="__codelineno-0-1782"></a>    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
</span><span id="__span-0-1783"><a id="__codelineno-0-1783" name="__codelineno-0-1783"></a>    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_grid</span><span class="p">)</span>
</span><span id="__span-0-1784"><a id="__codelineno-0-1784" name="__codelineno-0-1784"></a>    <span class="k">assert</span> <span class="n">N</span> <span class="o">&gt;=</span> <span class="mi">2</span>
</span><span id="__span-0-1785"><a id="__codelineno-0-1785" name="__codelineno-0-1785"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">y0_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
</span><span id="__span-0-1786"><a id="__codelineno-0-1786" name="__codelineno-0-1786"></a>    <span class="n">dtype</span> <span class="o">=</span> <span class="n">y0_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-1787"><a id="__codelineno-0-1787" name="__codelineno-0-1787"></a>    <span class="n">t_grid</span> <span class="o">=</span> <span class="n">t_grid</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-1788"><a id="__codelineno-0-1788" name="__codelineno-0-1788"></a>
</span><span id="__span-0-1789"><a id="__codelineno-0-1789" name="__codelineno-0-1789"></a>    <span class="c1"># Initialize history lists for each component</span>
</span><span id="__span-0-1790"><a id="__codelineno-0-1790" name="__codelineno-0-1790"></a>
</span><span id="__span-0-1791"><a id="__codelineno-0-1791" name="__codelineno-0-1791"></a>    <span class="c1"># Clone initial values</span>
</span><span id="__span-0-1792"><a id="__codelineno-0-1792" name="__codelineno-0-1792"></a>    <span class="n">y_current</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">)</span>
</span><span id="__span-0-1793"><a id="__codelineno-0-1793" name="__codelineno-0-1793"></a>    <span class="n">y_history</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">y0_tuple</span><span class="p">]</span>
</span><span id="__span-0-1794"><a id="__codelineno-0-1794" name="__codelineno-0-1794"></a>
</span><span id="__span-0-1795"><a id="__codelineno-0-1795" name="__codelineno-0-1795"></a>    <span class="c1"># Euler integration: y_{k+1} = y_k + dt * f(t_k, y_k)</span>
</span><span id="__span-0-1796"><a id="__codelineno-0-1796" name="__codelineno-0-1796"></a>    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-1797"><a id="__codelineno-0-1797" name="__codelineno-0-1797"></a>        <span class="n">tk</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
</span><span id="__span-0-1798"><a id="__codelineno-0-1798" name="__codelineno-0-1798"></a>        <span class="n">dt</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># Scalar tensor, will broadcast automatically</span>
</span><span id="__span-0-1799"><a id="__codelineno-0-1799" name="__codelineno-0-1799"></a>        <span class="n">dy</span> <span class="o">=</span> <span class="n">ode_func</span><span class="p">(</span>
</span><span id="__span-0-1800"><a id="__codelineno-0-1800" name="__codelineno-0-1800"></a>            <span class="n">tk</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">y_current</span><span class="p">)</span>
</span><span id="__span-0-1801"><a id="__codelineno-0-1801" name="__codelineno-0-1801"></a>        <span class="p">)</span>  <span class="c1"># Expect tuple return, consistent with y structure</span>
</span><span id="__span-0-1802"><a id="__codelineno-0-1802" name="__codelineno-0-1802"></a>        <span class="c1"># assert isinstance(dy, tuple) and len(dy) == len(y)</span>
</span><span id="__span-0-1803"><a id="__codelineno-0-1803" name="__codelineno-0-1803"></a>
</span><span id="__span-0-1804"><a id="__codelineno-0-1804" name="__codelineno-0-1804"></a>        <span class="c1"># Update all integrated components except the last one</span>
</span><span id="__span-0-1805"><a id="__codelineno-0-1805" name="__codelineno-0-1805"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_current</span><span class="p">)):</span>
</span><span id="__span-0-1806"><a id="__codelineno-0-1806" name="__codelineno-0-1806"></a>            <span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">dy</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="__span-0-1807"><a id="__codelineno-0-1807" name="__codelineno-0-1807"></a>            <span class="c1"># Final element is the output spike (pass-through)</span>
</span><span id="__span-0-1808"><a id="__codelineno-0-1808" name="__codelineno-0-1808"></a>            <span class="n">y_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="__span-0-1809"><a id="__codelineno-0-1809" name="__codelineno-0-1809"></a>    <span class="k">return</span> <span class="n">y_history</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.backward_euler_w_history" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">backward_euler_w_history</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">backward_euler_w_history</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y_aug</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">yhistory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]],</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Backward integration for Euler method using stored history.</p>
<p>Iterates backwards through the provided <code>yhistory</code> to compute adjoint updates.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></code>)
          –
          <div class="doc-md-description">
            <p>Augmented dynamics.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y_aug</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>, <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>, <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>]</code>)
          –
          <div class="doc-md-description">
            <p>Initial augmented state.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>alpha</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></code>)
          –
          <div class="doc-md-description">
            <p>Unused.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Flipped time grid.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>yhistory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>)
          –
          <div class="doc-md-description">
            <p>Full forward trajectory.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Unused.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>], <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>
          –
          <div class="doc-md-description">
            <p>Tuple of <code>(final_adj_y, final_adj_params)</code>.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1812">1812</a></span>
<span class="normal"><a href="#__codelineno-0-1813">1813</a></span>
<span class="normal"><a href="#__codelineno-0-1814">1814</a></span>
<span class="normal"><a href="#__codelineno-0-1815">1815</a></span>
<span class="normal"><a href="#__codelineno-0-1816">1816</a></span>
<span class="normal"><a href="#__codelineno-0-1817">1817</a></span>
<span class="normal"><a href="#__codelineno-0-1818">1818</a></span>
<span class="normal"><a href="#__codelineno-0-1819">1819</a></span>
<span class="normal"><a href="#__codelineno-0-1820">1820</a></span>
<span class="normal"><a href="#__codelineno-0-1821">1821</a></span>
<span class="normal"><a href="#__codelineno-0-1822">1822</a></span>
<span class="normal"><a href="#__codelineno-0-1823">1823</a></span>
<span class="normal"><a href="#__codelineno-0-1824">1824</a></span>
<span class="normal"><a href="#__codelineno-0-1825">1825</a></span>
<span class="normal"><a href="#__codelineno-0-1826">1826</a></span>
<span class="normal"><a href="#__codelineno-0-1827">1827</a></span>
<span class="normal"><a href="#__codelineno-0-1828">1828</a></span>
<span class="normal"><a href="#__codelineno-0-1829">1829</a></span>
<span class="normal"><a href="#__codelineno-0-1830">1830</a></span>
<span class="normal"><a href="#__codelineno-0-1831">1831</a></span>
<span class="normal"><a href="#__codelineno-0-1832">1832</a></span>
<span class="normal"><a href="#__codelineno-0-1833">1833</a></span>
<span class="normal"><a href="#__codelineno-0-1834">1834</a></span>
<span class="normal"><a href="#__codelineno-0-1835">1835</a></span>
<span class="normal"><a href="#__codelineno-0-1836">1836</a></span>
<span class="normal"><a href="#__codelineno-0-1837">1837</a></span>
<span class="normal"><a href="#__codelineno-0-1838">1838</a></span>
<span class="normal"><a href="#__codelineno-0-1839">1839</a></span>
<span class="normal"><a href="#__codelineno-0-1840">1840</a></span>
<span class="normal"><a href="#__codelineno-0-1841">1841</a></span>
<span class="normal"><a href="#__codelineno-0-1842">1842</a></span>
<span class="normal"><a href="#__codelineno-0-1843">1843</a></span>
<span class="normal"><a href="#__codelineno-0-1844">1844</a></span>
<span class="normal"><a href="#__codelineno-0-1845">1845</a></span>
<span class="normal"><a href="#__codelineno-0-1846">1846</a></span>
<span class="normal"><a href="#__codelineno-0-1847">1847</a></span>
<span class="normal"><a href="#__codelineno-0-1848">1848</a></span>
<span class="normal"><a href="#__codelineno-0-1849">1849</a></span>
<span class="normal"><a href="#__codelineno-0-1850">1850</a></span>
<span class="normal"><a href="#__codelineno-0-1851">1851</a></span>
<span class="normal"><a href="#__codelineno-0-1852">1852</a></span>
<span class="normal"><a href="#__codelineno-0-1853">1853</a></span>
<span class="normal"><a href="#__codelineno-0-1854">1854</a></span>
<span class="normal"><a href="#__codelineno-0-1855">1855</a></span>
<span class="normal"><a href="#__codelineno-0-1856">1856</a></span>
<span class="normal"><a href="#__codelineno-0-1857">1857</a></span>
<span class="normal"><a href="#__codelineno-0-1858">1858</a></span>
<span class="normal"><a href="#__codelineno-0-1859">1859</a></span>
<span class="normal"><a href="#__codelineno-0-1860">1860</a></span>
<span class="normal"><a href="#__codelineno-0-1861">1861</a></span>
<span class="normal"><a href="#__codelineno-0-1862">1862</a></span>
<span class="normal"><a href="#__codelineno-0-1863">1863</a></span>
<span class="normal"><a href="#__codelineno-0-1864">1864</a></span>
<span class="normal"><a href="#__codelineno-0-1865">1865</a></span>
<span class="normal"><a href="#__codelineno-0-1866">1866</a></span>
<span class="normal"><a href="#__codelineno-0-1867">1867</a></span>
<span class="normal"><a href="#__codelineno-0-1868">1868</a></span>
<span class="normal"><a href="#__codelineno-0-1869">1869</a></span>
<span class="normal"><a href="#__codelineno-0-1870">1870</a></span>
<span class="normal"><a href="#__codelineno-0-1871">1871</a></span>
<span class="normal"><a href="#__codelineno-0-1872">1872</a></span>
<span class="normal"><a href="#__codelineno-0-1873">1873</a></span>
<span class="normal"><a href="#__codelineno-0-1874">1874</a></span>
<span class="normal"><a href="#__codelineno-0-1875">1875</a></span>
<span class="normal"><a href="#__codelineno-0-1876">1876</a></span>
<span class="normal"><a href="#__codelineno-0-1877">1877</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1812"><a id="__codelineno-0-1812" name="__codelineno-0-1812"></a><span class="k">def</span><span class="w"> </span><span class="nf">backward_euler_w_history</span><span class="p">(</span>
</span><span id="__span-0-1813"><a id="__codelineno-0-1813" name="__codelineno-0-1813"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
</span><span id="__span-0-1814"><a id="__codelineno-0-1814" name="__codelineno-0-1814"></a>    <span class="n">y_aug</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">],</span>
</span><span id="__span-0-1815"><a id="__codelineno-0-1815" name="__codelineno-0-1815"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span id="__span-0-1816"><a id="__codelineno-0-1816" name="__codelineno-0-1816"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-1817"><a id="__codelineno-0-1817" name="__codelineno-0-1817"></a>    <span class="n">yhistory</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
</span><span id="__span-0-1818"><a id="__codelineno-0-1818" name="__codelineno-0-1818"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1819"><a id="__codelineno-0-1819" name="__codelineno-0-1819"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="__span-0-1820"><a id="__codelineno-0-1820" name="__codelineno-0-1820"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-1821"><a id="__codelineno-0-1821" name="__codelineno-0-1821"></a><span class="sd">    Backward integration for Euler method using stored history.</span>
</span><span id="__span-0-1822"><a id="__codelineno-0-1822" name="__codelineno-0-1822"></a>
</span><span id="__span-0-1823"><a id="__codelineno-0-1823" name="__codelineno-0-1823"></a><span class="sd">    Iterates backwards through the provided `yhistory` to compute adjoint updates.</span>
</span><span id="__span-0-1824"><a id="__codelineno-0-1824" name="__codelineno-0-1824"></a>
</span><span id="__span-0-1825"><a id="__codelineno-0-1825" name="__codelineno-0-1825"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1826"><a id="__codelineno-0-1826" name="__codelineno-0-1826"></a><span class="sd">        ode_func: Augmented dynamics.</span>
</span><span id="__span-0-1827"><a id="__codelineno-0-1827" name="__codelineno-0-1827"></a><span class="sd">        y_aug: Initial augmented state.</span>
</span><span id="__span-0-1828"><a id="__codelineno-0-1828" name="__codelineno-0-1828"></a><span class="sd">        alpha: Unused.</span>
</span><span id="__span-0-1829"><a id="__codelineno-0-1829" name="__codelineno-0-1829"></a><span class="sd">        t_grid: Flipped time grid.</span>
</span><span id="__span-0-1830"><a id="__codelineno-0-1830" name="__codelineno-0-1830"></a><span class="sd">        yhistory: Full forward trajectory.</span>
</span><span id="__span-0-1831"><a id="__codelineno-0-1831" name="__codelineno-0-1831"></a><span class="sd">        memory: Unused.</span>
</span><span id="__span-0-1832"><a id="__codelineno-0-1832" name="__codelineno-0-1832"></a>
</span><span id="__span-0-1833"><a id="__codelineno-0-1833" name="__codelineno-0-1833"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1834"><a id="__codelineno-0-1834" name="__codelineno-0-1834"></a><span class="sd">        Tuple of `(final_adj_y, final_adj_params)`.</span>
</span><span id="__span-0-1835"><a id="__codelineno-0-1835" name="__codelineno-0-1835"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-1836"><a id="__codelineno-0-1836" name="__codelineno-0-1836"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="__span-0-1837"><a id="__codelineno-0-1837" name="__codelineno-0-1837"></a>        <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_grid</span><span class="p">)</span>
</span><span id="__span-0-1838"><a id="__codelineno-0-1838" name="__codelineno-0-1838"></a>        <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]))</span>  <span class="c1"># uniform step size</span>
</span><span id="__span-0-1839"><a id="__codelineno-0-1839" name="__codelineno-0-1839"></a>        <span class="n">h</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
</span><span id="__span-0-1840"><a id="__codelineno-0-1840" name="__codelineno-0-1840"></a>
</span><span id="__span-0-1841"><a id="__codelineno-0-1841" name="__codelineno-0-1841"></a>        <span class="n">_</span><span class="p">,</span> <span class="n">adj_y0</span><span class="p">,</span> <span class="n">adj_params0</span> <span class="o">=</span> <span class="n">y_aug</span>
</span><span id="__span-0-1842"><a id="__codelineno-0-1842" name="__codelineno-0-1842"></a>
</span><span id="__span-0-1843"><a id="__codelineno-0-1843" name="__codelineno-0-1843"></a>        <span class="n">adj_y</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">adj_y0</span><span class="p">)</span>  <span class="c1"># [y0.clone() for y0 in y0_tuple]</span>
</span><span id="__span-0-1844"><a id="__codelineno-0-1844" name="__codelineno-0-1844"></a>        <span class="n">adj_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">adj_params0</span><span class="p">)</span>
</span><span id="__span-0-1845"><a id="__codelineno-0-1845" name="__codelineno-0-1845"></a>
</span><span id="__span-0-1846"><a id="__codelineno-0-1846" name="__codelineno-0-1846"></a>        <span class="c1"># return tuple(y_i.clone() for y_i in adj_y0), tuple(y_i.clone() for y_i in adj_params0)</span>
</span><span id="__span-0-1847"><a id="__codelineno-0-1847" name="__codelineno-0-1847"></a>
</span><span id="__span-0-1848"><a id="__codelineno-0-1848" name="__codelineno-0-1848"></a>        <span class="c1"># for k in range(N - 1):</span>
</span><span id="__span-0-1849"><a id="__codelineno-0-1849" name="__codelineno-0-1849"></a>        <span class="c1">#     tk = t_grid[k]</span>
</span><span id="__span-0-1850"><a id="__codelineno-0-1850" name="__codelineno-0-1850"></a>        <span class="c1">#     y_state = list([y[-1-k] for y in yhistory])</span>
</span><span id="__span-0-1851"><a id="__codelineno-0-1851" name="__codelineno-0-1851"></a>        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">2</span><span class="p">):</span>
</span><span id="__span-0-1852"><a id="__codelineno-0-1852" name="__codelineno-0-1852"></a>            <span class="n">tk</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
</span><span id="__span-0-1853"><a id="__codelineno-0-1853" name="__codelineno-0-1853"></a>            <span class="c1"># t_grid_flip = t_grid.flip(0) recal that t has been flipped already</span>
</span><span id="__span-0-1854"><a id="__codelineno-0-1854" name="__codelineno-0-1854"></a>            <span class="c1"># y_state = list([y[-k - 1] for y in yhistory])</span>
</span><span id="__span-0-1855"><a id="__codelineno-0-1855" name="__codelineno-0-1855"></a>            <span class="n">y_state</span> <span class="o">=</span> <span class="nb">list</span><span class="p">([</span><span class="n">y</span><span class="p">[</span><span class="o">-</span><span class="n">k</span> <span class="o">-</span> <span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">yhistory</span><span class="p">])</span>
</span><span id="__span-0-1856"><a id="__codelineno-0-1856" name="__codelineno-0-1856"></a>            <span class="c1"># 调用 augmented dynamics</span>
</span><span id="__span-0-1857"><a id="__codelineno-0-1857" name="__codelineno-0-1857"></a>            <span class="n">func_eval</span><span class="p">,</span> <span class="n">vjp_y</span><span class="p">,</span> <span class="n">vjp_params</span> <span class="o">=</span> <span class="n">ode_func</span><span class="p">(</span><span class="n">tk</span><span class="p">,</span> <span class="p">(</span><span class="n">y_state</span><span class="p">,</span> <span class="n">adj_y</span><span class="p">,</span> <span class="n">adj_params</span><span class="p">))</span>
</span><span id="__span-0-1858"><a id="__codelineno-0-1858" name="__codelineno-0-1858"></a>            <span class="c1"># vjp_y = tuple(torch.zeros_like(y_i) for y_i in adj_y)</span>
</span><span id="__span-0-1859"><a id="__codelineno-0-1859" name="__codelineno-0-1859"></a>            <span class="c1"># vjp_params = tuple(torch.zeros_like(y_i) for y_i in adj_params)</span>
</span><span id="__span-0-1860"><a id="__codelineno-0-1860" name="__codelineno-0-1860"></a>            <span class="c1"># 更新状态</span>
</span><span id="__span-0-1861"><a id="__codelineno-0-1861" name="__codelineno-0-1861"></a>            <span class="c1"># for i in range(len(adj_y)):</span>
</span><span id="__span-0-1862"><a id="__codelineno-0-1862" name="__codelineno-0-1862"></a>            <span class="c1">#     adj_y[i] = adj_y[i] + h * vjp_y[i]</span>
</span><span id="__span-0-1863"><a id="__codelineno-0-1863" name="__codelineno-0-1863"></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">adj_y</span><span class="p">)):</span>
</span><span id="__span-0-1864"><a id="__codelineno-0-1864" name="__codelineno-0-1864"></a>                <span class="n">adj_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">vjp_y</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="n">h</span><span class="p">)</span>
</span><span id="__span-0-1865"><a id="__codelineno-0-1865" name="__codelineno-0-1865"></a>
</span><span id="__span-0-1866"><a id="__codelineno-0-1866" name="__codelineno-0-1866"></a>            <span class="c1"># 更新参数梯度</span>
</span><span id="__span-0-1867"><a id="__codelineno-0-1867" name="__codelineno-0-1867"></a>            <span class="c1"># if adj_params and vjp_params:</span>
</span><span id="__span-0-1868"><a id="__codelineno-0-1868" name="__codelineno-0-1868"></a>            <span class="c1">#     adj_params = tuple(</span>
</span><span id="__span-0-1869"><a id="__codelineno-0-1869" name="__codelineno-0-1869"></a>            <span class="c1">#         ap + h * vp for ap, vp in zip(adj_params, vjp_params)</span>
</span><span id="__span-0-1870"><a id="__codelineno-0-1870" name="__codelineno-0-1870"></a>            <span class="c1">#     )</span>
</span><span id="__span-0-1871"><a id="__codelineno-0-1871" name="__codelineno-0-1871"></a>            <span class="k">if</span> <span class="n">adj_params</span> <span class="ow">and</span> <span class="n">vjp_params</span><span class="p">:</span>
</span><span id="__span-0-1872"><a id="__codelineno-0-1872" name="__codelineno-0-1872"></a>                <span class="k">for</span> <span class="n">ap</span><span class="p">,</span> <span class="n">vp</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">adj_params</span><span class="p">,</span> <span class="n">vjp_params</span><span class="p">):</span>
</span><span id="__span-0-1873"><a id="__codelineno-0-1873" name="__codelineno-0-1873"></a>                    <span class="n">ap</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">vp</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">h</span><span class="p">)</span>  <span class="c1"># 直接修改 tuple 中的张量</span>
</span><span id="__span-0-1874"><a id="__codelineno-0-1874" name="__codelineno-0-1874"></a>
</span><span id="__span-0-1875"><a id="__codelineno-0-1875" name="__codelineno-0-1875"></a>    <span class="k">del</span> <span class="n">yhistory</span><span class="p">,</span> <span class="n">vjp_params</span><span class="p">,</span> <span class="n">func_eval</span><span class="p">,</span> <span class="n">vjp_y</span>
</span><span id="__span-0-1876"><a id="__codelineno-0-1876" name="__codelineno-0-1876"></a>
</span><span id="__span-0-1877"><a id="__codelineno-0-1877" name="__codelineno-0-1877"></a>    <span class="k">return</span> <span class="n">adj_y</span><span class="p">,</span> <span class="n">adj_params</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.forward_gl" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">forward_gl</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">forward_gl</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Forward Grünwald-Letnikov (GL) integration.</p>
<p>Implements the Riemann-Liouville approximation:</p>
<div class="arithmatex">\[y_{k+1} = h^\alpha f(t_k, y_k) - \sum_{j=0}^{k} c_{k-j}^{(\alpha)} y_j\]</div>
<p>where coefficients <span class="arithmatex">\(c_j^{(\alpha)}\)</span> are computed recursively.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></code>)
          –
          <div class="doc-md-description">
            <p>Function <span class="arithmatex">\(f(t, y)\)</span>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y0_tuple</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]</code>)
          –
          <div class="doc-md-description">
            <p>Initial state tuple.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>alpha</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a> | <a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Fractional order <span class="arithmatex">\(\alpha \in (0, 1)\)</span>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Uniform time grid.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Max history length for truncation.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>
          –
          <div class="doc-md-description">
            <p>List of lists containing the state trajectory.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1880">1880</a></span>
<span class="normal"><a href="#__codelineno-0-1881">1881</a></span>
<span class="normal"><a href="#__codelineno-0-1882">1882</a></span>
<span class="normal"><a href="#__codelineno-0-1883">1883</a></span>
<span class="normal"><a href="#__codelineno-0-1884">1884</a></span>
<span class="normal"><a href="#__codelineno-0-1885">1885</a></span>
<span class="normal"><a href="#__codelineno-0-1886">1886</a></span>
<span class="normal"><a href="#__codelineno-0-1887">1887</a></span>
<span class="normal"><a href="#__codelineno-0-1888">1888</a></span>
<span class="normal"><a href="#__codelineno-0-1889">1889</a></span>
<span class="normal"><a href="#__codelineno-0-1890">1890</a></span>
<span class="normal"><a href="#__codelineno-0-1891">1891</a></span>
<span class="normal"><a href="#__codelineno-0-1892">1892</a></span>
<span class="normal"><a href="#__codelineno-0-1893">1893</a></span>
<span class="normal"><a href="#__codelineno-0-1894">1894</a></span>
<span class="normal"><a href="#__codelineno-0-1895">1895</a></span>
<span class="normal"><a href="#__codelineno-0-1896">1896</a></span>
<span class="normal"><a href="#__codelineno-0-1897">1897</a></span>
<span class="normal"><a href="#__codelineno-0-1898">1898</a></span>
<span class="normal"><a href="#__codelineno-0-1899">1899</a></span>
<span class="normal"><a href="#__codelineno-0-1900">1900</a></span>
<span class="normal"><a href="#__codelineno-0-1901">1901</a></span>
<span class="normal"><a href="#__codelineno-0-1902">1902</a></span>
<span class="normal"><a href="#__codelineno-0-1903">1903</a></span>
<span class="normal"><a href="#__codelineno-0-1904">1904</a></span>
<span class="normal"><a href="#__codelineno-0-1905">1905</a></span>
<span class="normal"><a href="#__codelineno-0-1906">1906</a></span>
<span class="normal"><a href="#__codelineno-0-1907">1907</a></span>
<span class="normal"><a href="#__codelineno-0-1908">1908</a></span>
<span class="normal"><a href="#__codelineno-0-1909">1909</a></span>
<span class="normal"><a href="#__codelineno-0-1910">1910</a></span>
<span class="normal"><a href="#__codelineno-0-1911">1911</a></span>
<span class="normal"><a href="#__codelineno-0-1912">1912</a></span>
<span class="normal"><a href="#__codelineno-0-1913">1913</a></span>
<span class="normal"><a href="#__codelineno-0-1914">1914</a></span>
<span class="normal"><a href="#__codelineno-0-1915">1915</a></span>
<span class="normal"><a href="#__codelineno-0-1916">1916</a></span>
<span class="normal"><a href="#__codelineno-0-1917">1917</a></span>
<span class="normal"><a href="#__codelineno-0-1918">1918</a></span>
<span class="normal"><a href="#__codelineno-0-1919">1919</a></span>
<span class="normal"><a href="#__codelineno-0-1920">1920</a></span>
<span class="normal"><a href="#__codelineno-0-1921">1921</a></span>
<span class="normal"><a href="#__codelineno-0-1922">1922</a></span>
<span class="normal"><a href="#__codelineno-0-1923">1923</a></span>
<span class="normal"><a href="#__codelineno-0-1924">1924</a></span>
<span class="normal"><a href="#__codelineno-0-1925">1925</a></span>
<span class="normal"><a href="#__codelineno-0-1926">1926</a></span>
<span class="normal"><a href="#__codelineno-0-1927">1927</a></span>
<span class="normal"><a href="#__codelineno-0-1928">1928</a></span>
<span class="normal"><a href="#__codelineno-0-1929">1929</a></span>
<span class="normal"><a href="#__codelineno-0-1930">1930</a></span>
<span class="normal"><a href="#__codelineno-0-1931">1931</a></span>
<span class="normal"><a href="#__codelineno-0-1932">1932</a></span>
<span class="normal"><a href="#__codelineno-0-1933">1933</a></span>
<span class="normal"><a href="#__codelineno-0-1934">1934</a></span>
<span class="normal"><a href="#__codelineno-0-1935">1935</a></span>
<span class="normal"><a href="#__codelineno-0-1936">1936</a></span>
<span class="normal"><a href="#__codelineno-0-1937">1937</a></span>
<span class="normal"><a href="#__codelineno-0-1938">1938</a></span>
<span class="normal"><a href="#__codelineno-0-1939">1939</a></span>
<span class="normal"><a href="#__codelineno-0-1940">1940</a></span>
<span class="normal"><a href="#__codelineno-0-1941">1941</a></span>
<span class="normal"><a href="#__codelineno-0-1942">1942</a></span>
<span class="normal"><a href="#__codelineno-0-1943">1943</a></span>
<span class="normal"><a href="#__codelineno-0-1944">1944</a></span>
<span class="normal"><a href="#__codelineno-0-1945">1945</a></span>
<span class="normal"><a href="#__codelineno-0-1946">1946</a></span>
<span class="normal"><a href="#__codelineno-0-1947">1947</a></span>
<span class="normal"><a href="#__codelineno-0-1948">1948</a></span>
<span class="normal"><a href="#__codelineno-0-1949">1949</a></span>
<span class="normal"><a href="#__codelineno-0-1950">1950</a></span>
<span class="normal"><a href="#__codelineno-0-1951">1951</a></span>
<span class="normal"><a href="#__codelineno-0-1952">1952</a></span>
<span class="normal"><a href="#__codelineno-0-1953">1953</a></span>
<span class="normal"><a href="#__codelineno-0-1954">1954</a></span>
<span class="normal"><a href="#__codelineno-0-1955">1955</a></span>
<span class="normal"><a href="#__codelineno-0-1956">1956</a></span>
<span class="normal"><a href="#__codelineno-0-1957">1957</a></span>
<span class="normal"><a href="#__codelineno-0-1958">1958</a></span>
<span class="normal"><a href="#__codelineno-0-1959">1959</a></span>
<span class="normal"><a href="#__codelineno-0-1960">1960</a></span>
<span class="normal"><a href="#__codelineno-0-1961">1961</a></span>
<span class="normal"><a href="#__codelineno-0-1962">1962</a></span>
<span class="normal"><a href="#__codelineno-0-1963">1963</a></span>
<span class="normal"><a href="#__codelineno-0-1964">1964</a></span>
<span class="normal"><a href="#__codelineno-0-1965">1965</a></span>
<span class="normal"><a href="#__codelineno-0-1966">1966</a></span>
<span class="normal"><a href="#__codelineno-0-1967">1967</a></span>
<span class="normal"><a href="#__codelineno-0-1968">1968</a></span>
<span class="normal"><a href="#__codelineno-0-1969">1969</a></span>
<span class="normal"><a href="#__codelineno-0-1970">1970</a></span>
<span class="normal"><a href="#__codelineno-0-1971">1971</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1880"><a id="__codelineno-0-1880" name="__codelineno-0-1880"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward_gl</span><span class="p">(</span>
</span><span id="__span-0-1881"><a id="__codelineno-0-1881" name="__codelineno-0-1881"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
</span><span id="__span-0-1882"><a id="__codelineno-0-1882" name="__codelineno-0-1882"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-1883"><a id="__codelineno-0-1883" name="__codelineno-0-1883"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="__span-0-1884"><a id="__codelineno-0-1884" name="__codelineno-0-1884"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-1885"><a id="__codelineno-0-1885" name="__codelineno-0-1885"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1886"><a id="__codelineno-0-1886" name="__codelineno-0-1886"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="__span-0-1887"><a id="__codelineno-0-1887" name="__codelineno-0-1887"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-1888"><a id="__codelineno-0-1888" name="__codelineno-0-1888"></a><span class="sd">    Forward Grünwald-Letnikov (GL) integration.</span>
</span><span id="__span-0-1889"><a id="__codelineno-0-1889" name="__codelineno-0-1889"></a>
</span><span id="__span-0-1890"><a id="__codelineno-0-1890" name="__codelineno-0-1890"></a><span class="sd">    Implements the Riemann-Liouville approximation:</span>
</span><span id="__span-0-1891"><a id="__codelineno-0-1891" name="__codelineno-0-1891"></a>
</span><span id="__span-0-1892"><a id="__codelineno-0-1892" name="__codelineno-0-1892"></a><span class="sd">    $$y_{k+1} = h^\alpha f(t_k, y_k) - \sum_{j=0}^{k} c_{k-j}^{(\alpha)} y_j$$</span>
</span><span id="__span-0-1893"><a id="__codelineno-0-1893" name="__codelineno-0-1893"></a>
</span><span id="__span-0-1894"><a id="__codelineno-0-1894" name="__codelineno-0-1894"></a><span class="sd">    where coefficients $c_j^{(\alpha)}$ are computed recursively.</span>
</span><span id="__span-0-1895"><a id="__codelineno-0-1895" name="__codelineno-0-1895"></a>
</span><span id="__span-0-1896"><a id="__codelineno-0-1896" name="__codelineno-0-1896"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1897"><a id="__codelineno-0-1897" name="__codelineno-0-1897"></a><span class="sd">        ode_func: Function $f(t, y)$.</span>
</span><span id="__span-0-1898"><a id="__codelineno-0-1898" name="__codelineno-0-1898"></a><span class="sd">        y0_tuple: Initial state tuple.</span>
</span><span id="__span-0-1899"><a id="__codelineno-0-1899" name="__codelineno-0-1899"></a><span class="sd">        alpha: Fractional order $\alpha \in (0, 1)$.</span>
</span><span id="__span-0-1900"><a id="__codelineno-0-1900" name="__codelineno-0-1900"></a><span class="sd">        t_grid: Uniform time grid.</span>
</span><span id="__span-0-1901"><a id="__codelineno-0-1901" name="__codelineno-0-1901"></a><span class="sd">        memory: Max history length for truncation.</span>
</span><span id="__span-0-1902"><a id="__codelineno-0-1902" name="__codelineno-0-1902"></a>
</span><span id="__span-0-1903"><a id="__codelineno-0-1903" name="__codelineno-0-1903"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1904"><a id="__codelineno-0-1904" name="__codelineno-0-1904"></a><span class="sd">        List of lists containing the state trajectory.</span>
</span><span id="__span-0-1905"><a id="__codelineno-0-1905" name="__codelineno-0-1905"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-1906"><a id="__codelineno-0-1906" name="__codelineno-0-1906"></a>    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
</span><span id="__span-0-1907"><a id="__codelineno-0-1907" name="__codelineno-0-1907"></a>    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_grid</span><span class="p">)</span>
</span><span id="__span-0-1908"><a id="__codelineno-0-1908" name="__codelineno-0-1908"></a>    <span class="k">assert</span> <span class="n">N</span> <span class="o">&gt;=</span> <span class="mi">2</span>
</span><span id="__span-0-1909"><a id="__codelineno-0-1909" name="__codelineno-0-1909"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">y0_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
</span><span id="__span-0-1910"><a id="__codelineno-0-1910" name="__codelineno-0-1910"></a>    <span class="n">dtype</span> <span class="o">=</span> <span class="n">y0_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-1911"><a id="__codelineno-0-1911" name="__codelineno-0-1911"></a>    <span class="n">t_grid</span> <span class="o">=</span> <span class="n">t_grid</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-1912"><a id="__codelineno-0-1912" name="__codelineno-0-1912"></a>    <span class="n">h</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># uniform step size</span>
</span><span id="__span-0-1913"><a id="__codelineno-0-1913" name="__codelineno-0-1913"></a>    <span class="n">h_alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
</span><span id="__span-0-1914"><a id="__codelineno-0-1914" name="__codelineno-0-1914"></a>
</span><span id="__span-0-1915"><a id="__codelineno-0-1915" name="__codelineno-0-1915"></a>    <span class="c1"># GL coefficients: need up to c[N]</span>
</span><span id="__span-0-1916"><a id="__codelineno-0-1916" name="__codelineno-0-1916"></a>    <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-1917"><a id="__codelineno-0-1917" name="__codelineno-0-1917"></a>    <span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="__span-0-1918"><a id="__codelineno-0-1918" name="__codelineno-0-1918"></a>    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-1919"><a id="__codelineno-0-1919" name="__codelineno-0-1919"></a>        <span class="n">c</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="n">j</span><span class="p">)</span> <span class="o">*</span> <span class="n">c</span><span class="p">[</span><span class="n">j</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
</span><span id="__span-0-1920"><a id="__codelineno-0-1920" name="__codelineno-0-1920"></a>
</span><span id="__span-0-1921"><a id="__codelineno-0-1921" name="__codelineno-0-1921"></a>    <span class="c1"># Initialize with y_0 (clone to avoid modifying input)</span>
</span><span id="__span-0-1922"><a id="__codelineno-0-1922" name="__codelineno-0-1922"></a>    <span class="n">y_current</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">)</span>  <span class="c1"># tuple(y.clone() for y in y0_tuple)</span>
</span><span id="__span-0-1923"><a id="__codelineno-0-1923" name="__codelineno-0-1923"></a>    <span class="c1"># History: y_history[i][j] stores y_j for component i</span>
</span><span id="__span-0-1924"><a id="__codelineno-0-1924" name="__codelineno-0-1924"></a>    <span class="c1"># Initialize with y_0</span>
</span><span id="__span-0-1925"><a id="__codelineno-0-1925" name="__codelineno-0-1925"></a>    <span class="c1"># y_history = [[y, ] for y in y0_tuple]</span>
</span><span id="__span-0-1926"><a id="__codelineno-0-1926" name="__codelineno-0-1926"></a>    <span class="n">y_history</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">y0_tuple</span><span class="p">]</span>
</span><span id="__span-0-1927"><a id="__codelineno-0-1927" name="__codelineno-0-1927"></a>    <span class="c1"># y_history = [[y.clone()] for y in y0_tuple]</span>
</span><span id="__span-0-1928"><a id="__codelineno-0-1928" name="__codelineno-0-1928"></a>
</span><span id="__span-0-1929"><a id="__codelineno-0-1929" name="__codelineno-0-1929"></a>    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-1930"><a id="__codelineno-0-1930" name="__codelineno-0-1930"></a>        <span class="n">t_k</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
</span><span id="__span-0-1931"><a id="__codelineno-0-1931" name="__codelineno-0-1931"></a>        <span class="c1"># Evaluate f(t_k, y_k)</span>
</span><span id="__span-0-1932"><a id="__codelineno-0-1932" name="__codelineno-0-1932"></a>
</span><span id="__span-0-1933"><a id="__codelineno-0-1933" name="__codelineno-0-1933"></a>        <span class="n">dy</span> <span class="o">=</span> <span class="n">ode_func</span><span class="p">(</span><span class="n">t_k</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">y_current</span><span class="p">))</span>
</span><span id="__span-0-1934"><a id="__codelineno-0-1934" name="__codelineno-0-1934"></a>        <span class="c1"># assert isinstance(dy, tuple) and len(dy) == len(y_current)</span>
</span><span id="__span-0-1935"><a id="__codelineno-0-1935" name="__codelineno-0-1935"></a>
</span><span id="__span-0-1936"><a id="__codelineno-0-1936" name="__codelineno-0-1936"></a>        <span class="c1"># Determine memory range</span>
</span><span id="__span-0-1937"><a id="__codelineno-0-1937" name="__codelineno-0-1937"></a>        <span class="k">if</span> <span class="n">memory</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">memory</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
</span><span id="__span-0-1938"><a id="__codelineno-0-1938" name="__codelineno-0-1938"></a>            <span class="n">memory_length</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Use all available history</span>
</span><span id="__span-0-1939"><a id="__codelineno-0-1939" name="__codelineno-0-1939"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-1940"><a id="__codelineno-0-1940" name="__codelineno-0-1940"></a>            <span class="n">memory_length</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-1941"><a id="__codelineno-0-1941" name="__codelineno-0-1941"></a>
</span><span id="__span-0-1942"><a id="__codelineno-0-1942" name="__codelineno-0-1942"></a>        <span class="n">start_idx</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">memory_length</span><span class="p">)</span>
</span><span id="__span-0-1943"><a id="__codelineno-0-1943" name="__codelineno-0-1943"></a>
</span><span id="__span-0-1944"><a id="__codelineno-0-1944" name="__codelineno-0-1944"></a>        <span class="c1"># Update all integrated components</span>
</span><span id="__span-0-1945"><a id="__codelineno-0-1945" name="__codelineno-0-1945"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_current</span><span class="p">)):</span>
</span><span id="__span-0-1946"><a id="__codelineno-0-1946" name="__codelineno-0-1946"></a>            <span class="c1"># Accumulate: Σ c_{k+1-j} * y_j for j from start_idx to k</span>
</span><span id="__span-0-1947"><a id="__codelineno-0-1947" name="__codelineno-0-1947"></a>            <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="__span-0-1948"><a id="__codelineno-0-1948" name="__codelineno-0-1948"></a>                <span class="n">convolution_sum</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># torch.zeros_like(y[i])</span>
</span><span id="__span-0-1949"><a id="__codelineno-0-1949" name="__codelineno-0-1949"></a>                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
</span><span id="__span-0-1950"><a id="__codelineno-0-1950" name="__codelineno-0-1950"></a>                    <span class="c1"># GL coefficient for this lag</span>
</span><span id="__span-0-1951"><a id="__codelineno-0-1951" name="__codelineno-0-1951"></a>                    <span class="c1"># convolution_sum = convolution_sum + c[k+1-j] * y_history[i][j]</span>
</span><span id="__span-0-1952"><a id="__codelineno-0-1952" name="__codelineno-0-1952"></a>                    <span class="n">convolution_sum</span> <span class="o">=</span> <span class="n">convolution_sum</span> <span class="o">+</span> <span class="n">c</span><span class="p">[</span><span class="n">k</span> <span class="o">-</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">y_history</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
</span><span id="__span-0-1953"><a id="__codelineno-0-1953" name="__codelineno-0-1953"></a>                <span class="c1"># here we assume at time k, we have k elements (without y0=0)</span>
</span><span id="__span-0-1954"><a id="__codelineno-0-1954" name="__codelineno-0-1954"></a>                <span class="c1"># the most restrict formulation should be convolution_sum + c[k-j] * y_history[i][j]</span>
</span><span id="__span-0-1955"><a id="__codelineno-0-1955" name="__codelineno-0-1955"></a>                <span class="c1"># which however seems do have have good numerical stability</span>
</span><span id="__span-0-1956"><a id="__codelineno-0-1956" name="__codelineno-0-1956"></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-1957"><a id="__codelineno-0-1957" name="__codelineno-0-1957"></a>                <span class="n">convolution_sum</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-0-1958"><a id="__codelineno-0-1958" name="__codelineno-0-1958"></a>
</span><span id="__span-0-1959"><a id="__codelineno-0-1959" name="__codelineno-0-1959"></a>            <span class="c1"># convolution_sum = None</span>
</span><span id="__span-0-1960"><a id="__codelineno-0-1960" name="__codelineno-0-1960"></a>            <span class="c1"># for j in range(start_idx, k+1):</span>
</span><span id="__span-0-1961"><a id="__codelineno-0-1961" name="__codelineno-0-1961"></a>            <span class="c1"># # # GL coefficient for this lag</span>
</span><span id="__span-0-1962"><a id="__codelineno-0-1962" name="__codelineno-0-1962"></a>            <span class="c1">#     if convolution_sum is None:</span>
</span><span id="__span-0-1963"><a id="__codelineno-0-1963" name="__codelineno-0-1963"></a>            <span class="c1">#         convolution_sum = c[k+1-j] * y_history[i][j]</span>
</span><span id="__span-0-1964"><a id="__codelineno-0-1964" name="__codelineno-0-1964"></a>            <span class="c1">#     else:</span>
</span><span id="__span-0-1965"><a id="__codelineno-0-1965" name="__codelineno-0-1965"></a>            <span class="c1">#         convolution_sum = convolution_sum + c[k+1-j] * y_history[i][j]</span>
</span><span id="__span-0-1966"><a id="__codelineno-0-1966" name="__codelineno-0-1966"></a>
</span><span id="__span-0-1967"><a id="__codelineno-0-1967" name="__codelineno-0-1967"></a>            <span class="c1"># y_{k+1} = h^alpha * f_k - convolution_sum</span>
</span><span id="__span-0-1968"><a id="__codelineno-0-1968" name="__codelineno-0-1968"></a>            <span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">h_alpha</span> <span class="o">*</span> <span class="n">dy</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">convolution_sum</span>
</span><span id="__span-0-1969"><a id="__codelineno-0-1969" name="__codelineno-0-1969"></a>            <span class="n">y_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="__span-0-1970"><a id="__codelineno-0-1970" name="__codelineno-0-1970"></a>
</span><span id="__span-0-1971"><a id="__codelineno-0-1971" name="__codelineno-0-1971"></a>    <span class="k">return</span> <span class="n">y_history</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.backward_gl" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">backward_gl</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">backward_gl</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y_aug</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">yhistory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]],</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Backward Grünwald-Letnikov integration for adjoint sensitivity.</p>
<p>Solves the adjoint equation using the same GL discretization structure,
accumulating gradients from the future (which is the past in reversed time).</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></code>)
          –
          <div class="doc-md-description">
            <p>Augmented dynamics.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y_aug</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>, <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>, <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>]</code>)
          –
          <div class="doc-md-description">
            <p>Initial augmented state (at reversed <span class="arithmatex">\(t=0\)</span>, i.e., forward <span class="arithmatex">\(t=T\)</span>).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>alpha</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a> | <a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Fractional order.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Flipped time grid.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>yhistory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>)
          –
          <div class="doc-md-description">
            <p>Forward trajectory (accessed in reverse).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Memory truncation limit.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>], <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>
          –
          <div class="doc-md-description">
            <p>Tuple of <code>(final_adj_y, final_adj_params)</code>.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1974">1974</a></span>
<span class="normal"><a href="#__codelineno-0-1975">1975</a></span>
<span class="normal"><a href="#__codelineno-0-1976">1976</a></span>
<span class="normal"><a href="#__codelineno-0-1977">1977</a></span>
<span class="normal"><a href="#__codelineno-0-1978">1978</a></span>
<span class="normal"><a href="#__codelineno-0-1979">1979</a></span>
<span class="normal"><a href="#__codelineno-0-1980">1980</a></span>
<span class="normal"><a href="#__codelineno-0-1981">1981</a></span>
<span class="normal"><a href="#__codelineno-0-1982">1982</a></span>
<span class="normal"><a href="#__codelineno-0-1983">1983</a></span>
<span class="normal"><a href="#__codelineno-0-1984">1984</a></span>
<span class="normal"><a href="#__codelineno-0-1985">1985</a></span>
<span class="normal"><a href="#__codelineno-0-1986">1986</a></span>
<span class="normal"><a href="#__codelineno-0-1987">1987</a></span>
<span class="normal"><a href="#__codelineno-0-1988">1988</a></span>
<span class="normal"><a href="#__codelineno-0-1989">1989</a></span>
<span class="normal"><a href="#__codelineno-0-1990">1990</a></span>
<span class="normal"><a href="#__codelineno-0-1991">1991</a></span>
<span class="normal"><a href="#__codelineno-0-1992">1992</a></span>
<span class="normal"><a href="#__codelineno-0-1993">1993</a></span>
<span class="normal"><a href="#__codelineno-0-1994">1994</a></span>
<span class="normal"><a href="#__codelineno-0-1995">1995</a></span>
<span class="normal"><a href="#__codelineno-0-1996">1996</a></span>
<span class="normal"><a href="#__codelineno-0-1997">1997</a></span>
<span class="normal"><a href="#__codelineno-0-1998">1998</a></span>
<span class="normal"><a href="#__codelineno-0-1999">1999</a></span>
<span class="normal"><a href="#__codelineno-0-2000">2000</a></span>
<span class="normal"><a href="#__codelineno-0-2001">2001</a></span>
<span class="normal"><a href="#__codelineno-0-2002">2002</a></span>
<span class="normal"><a href="#__codelineno-0-2003">2003</a></span>
<span class="normal"><a href="#__codelineno-0-2004">2004</a></span>
<span class="normal"><a href="#__codelineno-0-2005">2005</a></span>
<span class="normal"><a href="#__codelineno-0-2006">2006</a></span>
<span class="normal"><a href="#__codelineno-0-2007">2007</a></span>
<span class="normal"><a href="#__codelineno-0-2008">2008</a></span>
<span class="normal"><a href="#__codelineno-0-2009">2009</a></span>
<span class="normal"><a href="#__codelineno-0-2010">2010</a></span>
<span class="normal"><a href="#__codelineno-0-2011">2011</a></span>
<span class="normal"><a href="#__codelineno-0-2012">2012</a></span>
<span class="normal"><a href="#__codelineno-0-2013">2013</a></span>
<span class="normal"><a href="#__codelineno-0-2014">2014</a></span>
<span class="normal"><a href="#__codelineno-0-2015">2015</a></span>
<span class="normal"><a href="#__codelineno-0-2016">2016</a></span>
<span class="normal"><a href="#__codelineno-0-2017">2017</a></span>
<span class="normal"><a href="#__codelineno-0-2018">2018</a></span>
<span class="normal"><a href="#__codelineno-0-2019">2019</a></span>
<span class="normal"><a href="#__codelineno-0-2020">2020</a></span>
<span class="normal"><a href="#__codelineno-0-2021">2021</a></span>
<span class="normal"><a href="#__codelineno-0-2022">2022</a></span>
<span class="normal"><a href="#__codelineno-0-2023">2023</a></span>
<span class="normal"><a href="#__codelineno-0-2024">2024</a></span>
<span class="normal"><a href="#__codelineno-0-2025">2025</a></span>
<span class="normal"><a href="#__codelineno-0-2026">2026</a></span>
<span class="normal"><a href="#__codelineno-0-2027">2027</a></span>
<span class="normal"><a href="#__codelineno-0-2028">2028</a></span>
<span class="normal"><a href="#__codelineno-0-2029">2029</a></span>
<span class="normal"><a href="#__codelineno-0-2030">2030</a></span>
<span class="normal"><a href="#__codelineno-0-2031">2031</a></span>
<span class="normal"><a href="#__codelineno-0-2032">2032</a></span>
<span class="normal"><a href="#__codelineno-0-2033">2033</a></span>
<span class="normal"><a href="#__codelineno-0-2034">2034</a></span>
<span class="normal"><a href="#__codelineno-0-2035">2035</a></span>
<span class="normal"><a href="#__codelineno-0-2036">2036</a></span>
<span class="normal"><a href="#__codelineno-0-2037">2037</a></span>
<span class="normal"><a href="#__codelineno-0-2038">2038</a></span>
<span class="normal"><a href="#__codelineno-0-2039">2039</a></span>
<span class="normal"><a href="#__codelineno-0-2040">2040</a></span>
<span class="normal"><a href="#__codelineno-0-2041">2041</a></span>
<span class="normal"><a href="#__codelineno-0-2042">2042</a></span>
<span class="normal"><a href="#__codelineno-0-2043">2043</a></span>
<span class="normal"><a href="#__codelineno-0-2044">2044</a></span>
<span class="normal"><a href="#__codelineno-0-2045">2045</a></span>
<span class="normal"><a href="#__codelineno-0-2046">2046</a></span>
<span class="normal"><a href="#__codelineno-0-2047">2047</a></span>
<span class="normal"><a href="#__codelineno-0-2048">2048</a></span>
<span class="normal"><a href="#__codelineno-0-2049">2049</a></span>
<span class="normal"><a href="#__codelineno-0-2050">2050</a></span>
<span class="normal"><a href="#__codelineno-0-2051">2051</a></span>
<span class="normal"><a href="#__codelineno-0-2052">2052</a></span>
<span class="normal"><a href="#__codelineno-0-2053">2053</a></span>
<span class="normal"><a href="#__codelineno-0-2054">2054</a></span>
<span class="normal"><a href="#__codelineno-0-2055">2055</a></span>
<span class="normal"><a href="#__codelineno-0-2056">2056</a></span>
<span class="normal"><a href="#__codelineno-0-2057">2057</a></span>
<span class="normal"><a href="#__codelineno-0-2058">2058</a></span>
<span class="normal"><a href="#__codelineno-0-2059">2059</a></span>
<span class="normal"><a href="#__codelineno-0-2060">2060</a></span>
<span class="normal"><a href="#__codelineno-0-2061">2061</a></span>
<span class="normal"><a href="#__codelineno-0-2062">2062</a></span>
<span class="normal"><a href="#__codelineno-0-2063">2063</a></span>
<span class="normal"><a href="#__codelineno-0-2064">2064</a></span>
<span class="normal"><a href="#__codelineno-0-2065">2065</a></span>
<span class="normal"><a href="#__codelineno-0-2066">2066</a></span>
<span class="normal"><a href="#__codelineno-0-2067">2067</a></span>
<span class="normal"><a href="#__codelineno-0-2068">2068</a></span>
<span class="normal"><a href="#__codelineno-0-2069">2069</a></span>
<span class="normal"><a href="#__codelineno-0-2070">2070</a></span>
<span class="normal"><a href="#__codelineno-0-2071">2071</a></span>
<span class="normal"><a href="#__codelineno-0-2072">2072</a></span>
<span class="normal"><a href="#__codelineno-0-2073">2073</a></span>
<span class="normal"><a href="#__codelineno-0-2074">2074</a></span>
<span class="normal"><a href="#__codelineno-0-2075">2075</a></span>
<span class="normal"><a href="#__codelineno-0-2076">2076</a></span>
<span class="normal"><a href="#__codelineno-0-2077">2077</a></span>
<span class="normal"><a href="#__codelineno-0-2078">2078</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1974"><a id="__codelineno-0-1974" name="__codelineno-0-1974"></a><span class="k">def</span><span class="w"> </span><span class="nf">backward_gl</span><span class="p">(</span>
</span><span id="__span-0-1975"><a id="__codelineno-0-1975" name="__codelineno-0-1975"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
</span><span id="__span-0-1976"><a id="__codelineno-0-1976" name="__codelineno-0-1976"></a>    <span class="n">y_aug</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">],</span>
</span><span id="__span-0-1977"><a id="__codelineno-0-1977" name="__codelineno-0-1977"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="__span-0-1978"><a id="__codelineno-0-1978" name="__codelineno-0-1978"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-1979"><a id="__codelineno-0-1979" name="__codelineno-0-1979"></a>    <span class="n">yhistory</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
</span><span id="__span-0-1980"><a id="__codelineno-0-1980" name="__codelineno-0-1980"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1981"><a id="__codelineno-0-1981" name="__codelineno-0-1981"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="__span-0-1982"><a id="__codelineno-0-1982" name="__codelineno-0-1982"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-1983"><a id="__codelineno-0-1983" name="__codelineno-0-1983"></a><span class="sd">    Backward Grünwald-Letnikov integration for adjoint sensitivity.</span>
</span><span id="__span-0-1984"><a id="__codelineno-0-1984" name="__codelineno-0-1984"></a>
</span><span id="__span-0-1985"><a id="__codelineno-0-1985" name="__codelineno-0-1985"></a><span class="sd">    Solves the adjoint equation using the same GL discretization structure,</span>
</span><span id="__span-0-1986"><a id="__codelineno-0-1986" name="__codelineno-0-1986"></a><span class="sd">    accumulating gradients from the future (which is the past in reversed time).</span>
</span><span id="__span-0-1987"><a id="__codelineno-0-1987" name="__codelineno-0-1987"></a>
</span><span id="__span-0-1988"><a id="__codelineno-0-1988" name="__codelineno-0-1988"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1989"><a id="__codelineno-0-1989" name="__codelineno-0-1989"></a><span class="sd">        ode_func: Augmented dynamics.</span>
</span><span id="__span-0-1990"><a id="__codelineno-0-1990" name="__codelineno-0-1990"></a><span class="sd">        y_aug: Initial augmented state (at reversed $t=0$, i.e., forward $t=T$).</span>
</span><span id="__span-0-1991"><a id="__codelineno-0-1991" name="__codelineno-0-1991"></a><span class="sd">        alpha: Fractional order.</span>
</span><span id="__span-0-1992"><a id="__codelineno-0-1992" name="__codelineno-0-1992"></a><span class="sd">        t_grid: Flipped time grid.</span>
</span><span id="__span-0-1993"><a id="__codelineno-0-1993" name="__codelineno-0-1993"></a><span class="sd">        yhistory: Forward trajectory (accessed in reverse).</span>
</span><span id="__span-0-1994"><a id="__codelineno-0-1994" name="__codelineno-0-1994"></a><span class="sd">        memory: Memory truncation limit.</span>
</span><span id="__span-0-1995"><a id="__codelineno-0-1995" name="__codelineno-0-1995"></a>
</span><span id="__span-0-1996"><a id="__codelineno-0-1996" name="__codelineno-0-1996"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1997"><a id="__codelineno-0-1997" name="__codelineno-0-1997"></a><span class="sd">        Tuple of `(final_adj_y, final_adj_params)`.</span>
</span><span id="__span-0-1998"><a id="__codelineno-0-1998" name="__codelineno-0-1998"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-1999"><a id="__codelineno-0-1999" name="__codelineno-0-1999"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="__span-0-2000"><a id="__codelineno-0-2000" name="__codelineno-0-2000"></a>        <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_grid</span><span class="p">)</span>
</span><span id="__span-0-2001"><a id="__codelineno-0-2001" name="__codelineno-0-2001"></a>        <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
</span><span id="__span-0-2002"><a id="__codelineno-0-2002" name="__codelineno-0-2002"></a>        <span class="n">h_alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
</span><span id="__span-0-2003"><a id="__codelineno-0-2003" name="__codelineno-0-2003"></a>
</span><span id="__span-0-2004"><a id="__codelineno-0-2004" name="__codelineno-0-2004"></a>        <span class="n">_</span><span class="p">,</span> <span class="n">adj_y0</span><span class="p">,</span> <span class="n">adj_params0</span> <span class="o">=</span> <span class="n">y_aug</span>
</span><span id="__span-0-2005"><a id="__codelineno-0-2005" name="__codelineno-0-2005"></a>        <span class="n">device</span> <span class="o">=</span> <span class="n">adj_y0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
</span><span id="__span-0-2006"><a id="__codelineno-0-2006" name="__codelineno-0-2006"></a>        <span class="n">dtype</span> <span class="o">=</span> <span class="n">adj_y0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-2007"><a id="__codelineno-0-2007" name="__codelineno-0-2007"></a>
</span><span id="__span-0-2008"><a id="__codelineno-0-2008" name="__codelineno-0-2008"></a>        <span class="c1"># GL coefficients</span>
</span><span id="__span-0-2009"><a id="__codelineno-0-2009" name="__codelineno-0-2009"></a>        <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-2010"><a id="__codelineno-0-2010" name="__codelineno-0-2010"></a>        <span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="__span-0-2011"><a id="__codelineno-0-2011" name="__codelineno-0-2011"></a>        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-2012"><a id="__codelineno-0-2012" name="__codelineno-0-2012"></a>            <span class="n">c</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="n">j</span><span class="p">)</span> <span class="o">*</span> <span class="n">c</span><span class="p">[</span><span class="n">j</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
</span><span id="__span-0-2013"><a id="__codelineno-0-2013" name="__codelineno-0-2013"></a>
</span><span id="__span-0-2014"><a id="__codelineno-0-2014" name="__codelineno-0-2014"></a>        <span class="c1"># Initialize adjoint history lists for each component</span>
</span><span id="__span-0-2015"><a id="__codelineno-0-2015" name="__codelineno-0-2015"></a>        <span class="n">adjy_history</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-0-2016"><a id="__codelineno-0-2016" name="__codelineno-0-2016"></a>            <span class="p">[</span>
</span><span id="__span-0-2017"><a id="__codelineno-0-2017" name="__codelineno-0-2017"></a>                <span class="n">xx</span><span class="p">,</span>
</span><span id="__span-0-2018"><a id="__codelineno-0-2018" name="__codelineno-0-2018"></a>            <span class="p">]</span>
</span><span id="__span-0-2019"><a id="__codelineno-0-2019" name="__codelineno-0-2019"></a>            <span class="k">for</span> <span class="n">xx</span> <span class="ow">in</span> <span class="n">adj_y0</span>
</span><span id="__span-0-2020"><a id="__codelineno-0-2020" name="__codelineno-0-2020"></a>        <span class="p">]</span>
</span><span id="__span-0-2021"><a id="__codelineno-0-2021" name="__codelineno-0-2021"></a>
</span><span id="__span-0-2022"><a id="__codelineno-0-2022" name="__codelineno-0-2022"></a>        <span class="c1"># Clone initial adjoint values</span>
</span><span id="__span-0-2023"><a id="__codelineno-0-2023" name="__codelineno-0-2023"></a>        <span class="n">adj_y</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">adj_y0</span><span class="p">)</span>
</span><span id="__span-0-2024"><a id="__codelineno-0-2024" name="__codelineno-0-2024"></a>        <span class="n">adj_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">adj_params0</span><span class="p">)</span>
</span><span id="__span-0-2025"><a id="__codelineno-0-2025" name="__codelineno-0-2025"></a>
</span><span id="__span-0-2026"><a id="__codelineno-0-2026" name="__codelineno-0-2026"></a>        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">2</span><span class="p">):</span>
</span><span id="__span-0-2027"><a id="__codelineno-0-2027" name="__codelineno-0-2027"></a>            <span class="n">tk</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
</span><span id="__span-0-2028"><a id="__codelineno-0-2028" name="__codelineno-0-2028"></a>            <span class="c1"># t_grid_flip = t_grid.flip(0) recal that t has been flipped already</span>
</span><span id="__span-0-2029"><a id="__codelineno-0-2029" name="__codelineno-0-2029"></a>            <span class="c1"># y_state = list([y[-k - 1] for y in yhistory])</span>
</span><span id="__span-0-2030"><a id="__codelineno-0-2030" name="__codelineno-0-2030"></a>            <span class="n">y_state</span> <span class="o">=</span> <span class="nb">list</span><span class="p">([</span><span class="n">y</span><span class="p">[</span><span class="o">-</span><span class="n">k</span> <span class="o">-</span> <span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">yhistory</span><span class="p">])</span>
</span><span id="__span-0-2031"><a id="__codelineno-0-2031" name="__codelineno-0-2031"></a>
</span><span id="__span-0-2032"><a id="__codelineno-0-2032" name="__codelineno-0-2032"></a>            <span class="n">func_eval</span><span class="p">,</span> <span class="n">vjp_y</span><span class="p">,</span> <span class="n">vjp_params</span> <span class="o">=</span> <span class="n">ode_func</span><span class="p">(</span><span class="n">tk</span><span class="p">,</span> <span class="p">(</span><span class="n">y_state</span><span class="p">,</span> <span class="n">adj_y</span><span class="p">,</span> <span class="n">adj_params</span><span class="p">))</span>
</span><span id="__span-0-2033"><a id="__codelineno-0-2033" name="__codelineno-0-2033"></a>
</span><span id="__span-0-2034"><a id="__codelineno-0-2034" name="__codelineno-0-2034"></a>            <span class="c1"># Determine memory range</span>
</span><span id="__span-0-2035"><a id="__codelineno-0-2035" name="__codelineno-0-2035"></a>            <span class="k">if</span> <span class="n">memory</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">memory</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
</span><span id="__span-0-2036"><a id="__codelineno-0-2036" name="__codelineno-0-2036"></a>                <span class="n">memory_length</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Use all available history</span>
</span><span id="__span-0-2037"><a id="__codelineno-0-2037" name="__codelineno-0-2037"></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-2038"><a id="__codelineno-0-2038" name="__codelineno-0-2038"></a>                <span class="n">memory_length</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-2039"><a id="__codelineno-0-2039" name="__codelineno-0-2039"></a>
</span><span id="__span-0-2040"><a id="__codelineno-0-2040" name="__codelineno-0-2040"></a>            <span class="n">start_idx</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">memory_length</span><span class="p">)</span>
</span><span id="__span-0-2041"><a id="__codelineno-0-2041" name="__codelineno-0-2041"></a>
</span><span id="__span-0-2042"><a id="__codelineno-0-2042" name="__codelineno-0-2042"></a>            <span class="c1"># Update all adjoint components</span>
</span><span id="__span-0-2043"><a id="__codelineno-0-2043" name="__codelineno-0-2043"></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">adj_y</span><span class="p">)):</span>
</span><span id="__span-0-2044"><a id="__codelineno-0-2044" name="__codelineno-0-2044"></a>                <span class="c1"># Calculate history sum</span>
</span><span id="__span-0-2045"><a id="__codelineno-0-2045" name="__codelineno-0-2045"></a>
</span><span id="__span-0-2046"><a id="__codelineno-0-2046" name="__codelineno-0-2046"></a>                <span class="k">if</span> <span class="kc">True</span><span class="p">:</span>  <span class="c1"># k &gt; 0:</span>
</span><span id="__span-0-2047"><a id="__codelineno-0-2047" name="__codelineno-0-2047"></a>                    <span class="n">convolution_sum</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># torch.zeros_like(y[i])</span>
</span><span id="__span-0-2048"><a id="__codelineno-0-2048" name="__codelineno-0-2048"></a>                    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-2049"><a id="__codelineno-0-2049" name="__codelineno-0-2049"></a>                        <span class="c1"># GL coefficient for this lag</span>
</span><span id="__span-0-2050"><a id="__codelineno-0-2050" name="__codelineno-0-2050"></a>                        <span class="n">convolution_sum</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-2051"><a id="__codelineno-0-2051" name="__codelineno-0-2051"></a>                            <span class="n">convolution_sum</span> <span class="o">+</span> <span class="n">c</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">adjy_history</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
</span><span id="__span-0-2052"><a id="__codelineno-0-2052" name="__codelineno-0-2052"></a>                        <span class="p">)</span>
</span><span id="__span-0-2053"><a id="__codelineno-0-2053" name="__codelineno-0-2053"></a>                    <span class="c1"># here we assume at time k, we have k elements (without y0=0)</span>
</span><span id="__span-0-2054"><a id="__codelineno-0-2054" name="__codelineno-0-2054"></a>                    <span class="c1"># the most restrict formulation should be convolution_sum + c[k-j] * y_history[i][j]</span>
</span><span id="__span-0-2055"><a id="__codelineno-0-2055" name="__codelineno-0-2055"></a>                    <span class="c1"># which however seems do have have good numerical stability</span>
</span><span id="__span-0-2056"><a id="__codelineno-0-2056" name="__codelineno-0-2056"></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-2057"><a id="__codelineno-0-2057" name="__codelineno-0-2057"></a>                    <span class="n">convolution_sum</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-0-2058"><a id="__codelineno-0-2058" name="__codelineno-0-2058"></a>
</span><span id="__span-0-2059"><a id="__codelineno-0-2059" name="__codelineno-0-2059"></a>                <span class="c1"># convolution_sum = None</span>
</span><span id="__span-0-2060"><a id="__codelineno-0-2060" name="__codelineno-0-2060"></a>                <span class="c1"># for j in range(start_idx, k+1):</span>
</span><span id="__span-0-2061"><a id="__codelineno-0-2061" name="__codelineno-0-2061"></a>                <span class="c1">#     # # GL coefficient for this lag</span>
</span><span id="__span-0-2062"><a id="__codelineno-0-2062" name="__codelineno-0-2062"></a>                <span class="c1">#     if convolution_sum is None:</span>
</span><span id="__span-0-2063"><a id="__codelineno-0-2063" name="__codelineno-0-2063"></a>                <span class="c1">#         convolution_sum = c[k + 1 - j] * adjy_history[i][j]</span>
</span><span id="__span-0-2064"><a id="__codelineno-0-2064" name="__codelineno-0-2064"></a>                <span class="c1">#     else:</span>
</span><span id="__span-0-2065"><a id="__codelineno-0-2065" name="__codelineno-0-2065"></a>                <span class="c1">#         convolution_sum = convolution_sum + c[k + 1  - j] * adjy_history[i][j]</span>
</span><span id="__span-0-2066"><a id="__codelineno-0-2066" name="__codelineno-0-2066"></a>
</span><span id="__span-0-2067"><a id="__codelineno-0-2067" name="__codelineno-0-2067"></a>                <span class="c1"># Update adjoint state</span>
</span><span id="__span-0-2068"><a id="__codelineno-0-2068" name="__codelineno-0-2068"></a>                <span class="n">adj_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">h_alpha</span> <span class="o">*</span> <span class="n">vjp_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">convolution_sum</span>
</span><span id="__span-0-2069"><a id="__codelineno-0-2069" name="__codelineno-0-2069"></a>                <span class="n">adjy_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">adj_y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="__span-0-2070"><a id="__codelineno-0-2070" name="__codelineno-0-2070"></a>
</span><span id="__span-0-2071"><a id="__codelineno-0-2071" name="__codelineno-0-2071"></a>            <span class="c1"># 更新参数梯度</span>
</span><span id="__span-0-2072"><a id="__codelineno-0-2072" name="__codelineno-0-2072"></a>            <span class="k">if</span> <span class="n">adj_params</span> <span class="ow">and</span> <span class="n">vjp_params</span><span class="p">:</span>
</span><span id="__span-0-2073"><a id="__codelineno-0-2073" name="__codelineno-0-2073"></a>                <span class="k">for</span> <span class="n">ap</span><span class="p">,</span> <span class="n">vp</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">adj_params</span><span class="p">,</span> <span class="n">vjp_params</span><span class="p">):</span>
</span><span id="__span-0-2074"><a id="__codelineno-0-2074" name="__codelineno-0-2074"></a>                    <span class="n">ap</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">vp</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">h</span><span class="p">)</span>  <span class="c1"># 直接修改 tuple 中的张量</span>
</span><span id="__span-0-2075"><a id="__codelineno-0-2075" name="__codelineno-0-2075"></a>
</span><span id="__span-0-2076"><a id="__codelineno-0-2076" name="__codelineno-0-2076"></a>    <span class="k">del</span> <span class="n">adjy_history</span><span class="p">,</span> <span class="n">yhistory</span>
</span><span id="__span-0-2077"><a id="__codelineno-0-2077" name="__codelineno-0-2077"></a>
</span><span id="__span-0-2078"><a id="__codelineno-0-2078" name="__codelineno-0-2078"></a>    <span class="k">return</span> <span class="n">adj_y</span><span class="p">,</span> <span class="n">adj_params</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.forward_trap" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">forward_trap</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">forward_trap</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Forward Product Trapezoidal method.</p>
<p>Provides <span class="arithmatex">\(O(h^2)\)</span> accuracy for Riemann-Liouville FDEs.
Formula:</p>
<div class="arithmatex">\[y_{k+1} = \frac{h^\alpha}{\Gamma(2-\alpha)} f_k - \sum_{j=0}^{k} A_{j,k+1} y_j\]</div>
<p>where weights <span class="arithmatex">\(A_{j,k+1}\)</span> depend on the distance from the current step.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></code>)
          –
          <div class="doc-md-description">
            <p>Function <span class="arithmatex">\(f(t, y)\)</span>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y0_tuple</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]</code>)
          –
          <div class="doc-md-description">
            <p>Initial state.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>alpha</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a> | <a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Fractional order.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Time grid.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Memory limit.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>
          –
          <div class="doc-md-description">
            <p>State trajectory.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-2081">2081</a></span>
<span class="normal"><a href="#__codelineno-0-2082">2082</a></span>
<span class="normal"><a href="#__codelineno-0-2083">2083</a></span>
<span class="normal"><a href="#__codelineno-0-2084">2084</a></span>
<span class="normal"><a href="#__codelineno-0-2085">2085</a></span>
<span class="normal"><a href="#__codelineno-0-2086">2086</a></span>
<span class="normal"><a href="#__codelineno-0-2087">2087</a></span>
<span class="normal"><a href="#__codelineno-0-2088">2088</a></span>
<span class="normal"><a href="#__codelineno-0-2089">2089</a></span>
<span class="normal"><a href="#__codelineno-0-2090">2090</a></span>
<span class="normal"><a href="#__codelineno-0-2091">2091</a></span>
<span class="normal"><a href="#__codelineno-0-2092">2092</a></span>
<span class="normal"><a href="#__codelineno-0-2093">2093</a></span>
<span class="normal"><a href="#__codelineno-0-2094">2094</a></span>
<span class="normal"><a href="#__codelineno-0-2095">2095</a></span>
<span class="normal"><a href="#__codelineno-0-2096">2096</a></span>
<span class="normal"><a href="#__codelineno-0-2097">2097</a></span>
<span class="normal"><a href="#__codelineno-0-2098">2098</a></span>
<span class="normal"><a href="#__codelineno-0-2099">2099</a></span>
<span class="normal"><a href="#__codelineno-0-2100">2100</a></span>
<span class="normal"><a href="#__codelineno-0-2101">2101</a></span>
<span class="normal"><a href="#__codelineno-0-2102">2102</a></span>
<span class="normal"><a href="#__codelineno-0-2103">2103</a></span>
<span class="normal"><a href="#__codelineno-0-2104">2104</a></span>
<span class="normal"><a href="#__codelineno-0-2105">2105</a></span>
<span class="normal"><a href="#__codelineno-0-2106">2106</a></span>
<span class="normal"><a href="#__codelineno-0-2107">2107</a></span>
<span class="normal"><a href="#__codelineno-0-2108">2108</a></span>
<span class="normal"><a href="#__codelineno-0-2109">2109</a></span>
<span class="normal"><a href="#__codelineno-0-2110">2110</a></span>
<span class="normal"><a href="#__codelineno-0-2111">2111</a></span>
<span class="normal"><a href="#__codelineno-0-2112">2112</a></span>
<span class="normal"><a href="#__codelineno-0-2113">2113</a></span>
<span class="normal"><a href="#__codelineno-0-2114">2114</a></span>
<span class="normal"><a href="#__codelineno-0-2115">2115</a></span>
<span class="normal"><a href="#__codelineno-0-2116">2116</a></span>
<span class="normal"><a href="#__codelineno-0-2117">2117</a></span>
<span class="normal"><a href="#__codelineno-0-2118">2118</a></span>
<span class="normal"><a href="#__codelineno-0-2119">2119</a></span>
<span class="normal"><a href="#__codelineno-0-2120">2120</a></span>
<span class="normal"><a href="#__codelineno-0-2121">2121</a></span>
<span class="normal"><a href="#__codelineno-0-2122">2122</a></span>
<span class="normal"><a href="#__codelineno-0-2123">2123</a></span>
<span class="normal"><a href="#__codelineno-0-2124">2124</a></span>
<span class="normal"><a href="#__codelineno-0-2125">2125</a></span>
<span class="normal"><a href="#__codelineno-0-2126">2126</a></span>
<span class="normal"><a href="#__codelineno-0-2127">2127</a></span>
<span class="normal"><a href="#__codelineno-0-2128">2128</a></span>
<span class="normal"><a href="#__codelineno-0-2129">2129</a></span>
<span class="normal"><a href="#__codelineno-0-2130">2130</a></span>
<span class="normal"><a href="#__codelineno-0-2131">2131</a></span>
<span class="normal"><a href="#__codelineno-0-2132">2132</a></span>
<span class="normal"><a href="#__codelineno-0-2133">2133</a></span>
<span class="normal"><a href="#__codelineno-0-2134">2134</a></span>
<span class="normal"><a href="#__codelineno-0-2135">2135</a></span>
<span class="normal"><a href="#__codelineno-0-2136">2136</a></span>
<span class="normal"><a href="#__codelineno-0-2137">2137</a></span>
<span class="normal"><a href="#__codelineno-0-2138">2138</a></span>
<span class="normal"><a href="#__codelineno-0-2139">2139</a></span>
<span class="normal"><a href="#__codelineno-0-2140">2140</a></span>
<span class="normal"><a href="#__codelineno-0-2141">2141</a></span>
<span class="normal"><a href="#__codelineno-0-2142">2142</a></span>
<span class="normal"><a href="#__codelineno-0-2143">2143</a></span>
<span class="normal"><a href="#__codelineno-0-2144">2144</a></span>
<span class="normal"><a href="#__codelineno-0-2145">2145</a></span>
<span class="normal"><a href="#__codelineno-0-2146">2146</a></span>
<span class="normal"><a href="#__codelineno-0-2147">2147</a></span>
<span class="normal"><a href="#__codelineno-0-2148">2148</a></span>
<span class="normal"><a href="#__codelineno-0-2149">2149</a></span>
<span class="normal"><a href="#__codelineno-0-2150">2150</a></span>
<span class="normal"><a href="#__codelineno-0-2151">2151</a></span>
<span class="normal"><a href="#__codelineno-0-2152">2152</a></span>
<span class="normal"><a href="#__codelineno-0-2153">2153</a></span>
<span class="normal"><a href="#__codelineno-0-2154">2154</a></span>
<span class="normal"><a href="#__codelineno-0-2155">2155</a></span>
<span class="normal"><a href="#__codelineno-0-2156">2156</a></span>
<span class="normal"><a href="#__codelineno-0-2157">2157</a></span>
<span class="normal"><a href="#__codelineno-0-2158">2158</a></span>
<span class="normal"><a href="#__codelineno-0-2159">2159</a></span>
<span class="normal"><a href="#__codelineno-0-2160">2160</a></span>
<span class="normal"><a href="#__codelineno-0-2161">2161</a></span>
<span class="normal"><a href="#__codelineno-0-2162">2162</a></span>
<span class="normal"><a href="#__codelineno-0-2163">2163</a></span>
<span class="normal"><a href="#__codelineno-0-2164">2164</a></span>
<span class="normal"><a href="#__codelineno-0-2165">2165</a></span>
<span class="normal"><a href="#__codelineno-0-2166">2166</a></span>
<span class="normal"><a href="#__codelineno-0-2167">2167</a></span>
<span class="normal"><a href="#__codelineno-0-2168">2168</a></span>
<span class="normal"><a href="#__codelineno-0-2169">2169</a></span>
<span class="normal"><a href="#__codelineno-0-2170">2170</a></span>
<span class="normal"><a href="#__codelineno-0-2171">2171</a></span>
<span class="normal"><a href="#__codelineno-0-2172">2172</a></span>
<span class="normal"><a href="#__codelineno-0-2173">2173</a></span>
<span class="normal"><a href="#__codelineno-0-2174">2174</a></span>
<span class="normal"><a href="#__codelineno-0-2175">2175</a></span>
<span class="normal"><a href="#__codelineno-0-2176">2176</a></span>
<span class="normal"><a href="#__codelineno-0-2177">2177</a></span>
<span class="normal"><a href="#__codelineno-0-2178">2178</a></span>
<span class="normal"><a href="#__codelineno-0-2179">2179</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-2081"><a id="__codelineno-0-2081" name="__codelineno-0-2081"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward_trap</span><span class="p">(</span>
</span><span id="__span-0-2082"><a id="__codelineno-0-2082" name="__codelineno-0-2082"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
</span><span id="__span-0-2083"><a id="__codelineno-0-2083" name="__codelineno-0-2083"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-2084"><a id="__codelineno-0-2084" name="__codelineno-0-2084"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="__span-0-2085"><a id="__codelineno-0-2085" name="__codelineno-0-2085"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-2086"><a id="__codelineno-0-2086" name="__codelineno-0-2086"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-2087"><a id="__codelineno-0-2087" name="__codelineno-0-2087"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="__span-0-2088"><a id="__codelineno-0-2088" name="__codelineno-0-2088"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-2089"><a id="__codelineno-0-2089" name="__codelineno-0-2089"></a><span class="sd">    Forward Product Trapezoidal method.</span>
</span><span id="__span-0-2090"><a id="__codelineno-0-2090" name="__codelineno-0-2090"></a>
</span><span id="__span-0-2091"><a id="__codelineno-0-2091" name="__codelineno-0-2091"></a><span class="sd">    Provides $O(h^2)$ accuracy for Riemann-Liouville FDEs.</span>
</span><span id="__span-0-2092"><a id="__codelineno-0-2092" name="__codelineno-0-2092"></a><span class="sd">    Formula:</span>
</span><span id="__span-0-2093"><a id="__codelineno-0-2093" name="__codelineno-0-2093"></a>
</span><span id="__span-0-2094"><a id="__codelineno-0-2094" name="__codelineno-0-2094"></a><span class="sd">    $$y_{k+1} = \frac{h^\alpha}{\Gamma(2-\alpha)} f_k - \sum_{j=0}^{k} A_{j,k+1} y_j$$</span>
</span><span id="__span-0-2095"><a id="__codelineno-0-2095" name="__codelineno-0-2095"></a>
</span><span id="__span-0-2096"><a id="__codelineno-0-2096" name="__codelineno-0-2096"></a><span class="sd">    where weights $A_{j,k+1}$ depend on the distance from the current step.</span>
</span><span id="__span-0-2097"><a id="__codelineno-0-2097" name="__codelineno-0-2097"></a>
</span><span id="__span-0-2098"><a id="__codelineno-0-2098" name="__codelineno-0-2098"></a><span class="sd">    Args:</span>
</span><span id="__span-0-2099"><a id="__codelineno-0-2099" name="__codelineno-0-2099"></a><span class="sd">        ode_func: Function $f(t, y)$.</span>
</span><span id="__span-0-2100"><a id="__codelineno-0-2100" name="__codelineno-0-2100"></a><span class="sd">        y0_tuple: Initial state.</span>
</span><span id="__span-0-2101"><a id="__codelineno-0-2101" name="__codelineno-0-2101"></a><span class="sd">        alpha: Fractional order.</span>
</span><span id="__span-0-2102"><a id="__codelineno-0-2102" name="__codelineno-0-2102"></a><span class="sd">        t_grid: Time grid.</span>
</span><span id="__span-0-2103"><a id="__codelineno-0-2103" name="__codelineno-0-2103"></a><span class="sd">        memory: Memory limit.</span>
</span><span id="__span-0-2104"><a id="__codelineno-0-2104" name="__codelineno-0-2104"></a>
</span><span id="__span-0-2105"><a id="__codelineno-0-2105" name="__codelineno-0-2105"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-2106"><a id="__codelineno-0-2106" name="__codelineno-0-2106"></a><span class="sd">        State trajectory.</span>
</span><span id="__span-0-2107"><a id="__codelineno-0-2107" name="__codelineno-0-2107"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-2108"><a id="__codelineno-0-2108" name="__codelineno-0-2108"></a>    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
</span><span id="__span-0-2109"><a id="__codelineno-0-2109" name="__codelineno-0-2109"></a>
</span><span id="__span-0-2110"><a id="__codelineno-0-2110" name="__codelineno-0-2110"></a>    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_grid</span><span class="p">)</span>
</span><span id="__span-0-2111"><a id="__codelineno-0-2111" name="__codelineno-0-2111"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">y0_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
</span><span id="__span-0-2112"><a id="__codelineno-0-2112" name="__codelineno-0-2112"></a>    <span class="n">dtype</span> <span class="o">=</span> <span class="n">y0_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-2113"><a id="__codelineno-0-2113" name="__codelineno-0-2113"></a>    <span class="n">t_grid</span> <span class="o">=</span> <span class="n">t_grid</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-2114"><a id="__codelineno-0-2114" name="__codelineno-0-2114"></a>
</span><span id="__span-0-2115"><a id="__codelineno-0-2115" name="__codelineno-0-2115"></a>    <span class="n">h</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># uniform step size</span>
</span><span id="__span-0-2116"><a id="__codelineno-0-2116" name="__codelineno-0-2116"></a>    <span class="n">h_alpha_gamma</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="mi">2</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span>
</span><span id="__span-0-2117"><a id="__codelineno-0-2117" name="__codelineno-0-2117"></a>    <span class="n">one_minus_alpha</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span>
</span><span id="__span-0-2118"><a id="__codelineno-0-2118" name="__codelineno-0-2118"></a>
</span><span id="__span-0-2119"><a id="__codelineno-0-2119" name="__codelineno-0-2119"></a>    <span class="c1"># Initialize with y_0</span>
</span><span id="__span-0-2120"><a id="__codelineno-0-2120" name="__codelineno-0-2120"></a>    <span class="n">y_current</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">)</span>
</span><span id="__span-0-2121"><a id="__codelineno-0-2121" name="__codelineno-0-2121"></a>    <span class="n">y_history</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">y0_tuple</span><span class="p">]</span>
</span><span id="__span-0-2122"><a id="__codelineno-0-2122" name="__codelineno-0-2122"></a>
</span><span id="__span-0-2123"><a id="__codelineno-0-2123" name="__codelineno-0-2123"></a>    <span class="c1"># Main loop: compute y_{k+1} for k = 0, 1, ..., N-2</span>
</span><span id="__span-0-2124"><a id="__codelineno-0-2124" name="__codelineno-0-2124"></a>    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-2125"><a id="__codelineno-0-2125" name="__codelineno-0-2125"></a>        <span class="n">t_k</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
</span><span id="__span-0-2126"><a id="__codelineno-0-2126" name="__codelineno-0-2126"></a>
</span><span id="__span-0-2127"><a id="__codelineno-0-2127" name="__codelineno-0-2127"></a>        <span class="c1"># Evaluate f(t_k, y_k)</span>
</span><span id="__span-0-2128"><a id="__codelineno-0-2128" name="__codelineno-0-2128"></a>        <span class="n">f_k</span> <span class="o">=</span> <span class="n">ode_func</span><span class="p">(</span><span class="n">t_k</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">y_current</span><span class="p">))</span>
</span><span id="__span-0-2129"><a id="__codelineno-0-2129" name="__codelineno-0-2129"></a>
</span><span id="__span-0-2130"><a id="__codelineno-0-2130" name="__codelineno-0-2130"></a>        <span class="c1"># Determine memory range</span>
</span><span id="__span-0-2131"><a id="__codelineno-0-2131" name="__codelineno-0-2131"></a>        <span class="k">if</span> <span class="n">memory</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-2132"><a id="__codelineno-0-2132" name="__codelineno-0-2132"></a>            <span class="n">memory_length</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="__span-0-2133"><a id="__codelineno-0-2133" name="__codelineno-0-2133"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-2134"><a id="__codelineno-0-2134" name="__codelineno-0-2134"></a>            <span class="n">memory_length</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-2135"><a id="__codelineno-0-2135" name="__codelineno-0-2135"></a>            <span class="k">assert</span> <span class="n">memory_length</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;memory must be greater than 0&quot;</span>
</span><span id="__span-0-2136"><a id="__codelineno-0-2136" name="__codelineno-0-2136"></a>
</span><span id="__span-0-2137"><a id="__codelineno-0-2137" name="__codelineno-0-2137"></a>        <span class="n">start_idx</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">memory_length</span><span class="p">)</span>
</span><span id="__span-0-2138"><a id="__codelineno-0-2138" name="__codelineno-0-2138"></a>
</span><span id="__span-0-2139"><a id="__codelineno-0-2139" name="__codelineno-0-2139"></a>        <span class="c1"># Compute A_{j,k+1} weights for indices from start_idx to k</span>
</span><span id="__span-0-2140"><a id="__codelineno-0-2140" name="__codelineno-0-2140"></a>        <span class="n">j_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-2141"><a id="__codelineno-0-2141" name="__codelineno-0-2141"></a>
</span><span id="__span-0-2142"><a id="__codelineno-0-2142" name="__codelineno-0-2142"></a>        <span class="c1"># General formula for j &gt;= 1:</span>
</span><span id="__span-0-2143"><a id="__codelineno-0-2143" name="__codelineno-0-2143"></a>        <span class="c1"># A_{j,k+1} = (k+2-j)^{1-α} + (k-j)^{1-α} - 2(k+1-j)^{1-α}</span>
</span><span id="__span-0-2144"><a id="__codelineno-0-2144" name="__codelineno-0-2144"></a>        <span class="n">kjp2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">j_vals</span><span class="p">,</span> <span class="n">one_minus_alpha</span><span class="p">)</span>
</span><span id="__span-0-2145"><a id="__codelineno-0-2145" name="__codelineno-0-2145"></a>        <span class="n">kj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">k</span> <span class="o">-</span> <span class="n">j_vals</span><span class="p">,</span> <span class="n">one_minus_alpha</span><span class="p">)</span>
</span><span id="__span-0-2146"><a id="__codelineno-0-2146" name="__codelineno-0-2146"></a>        <span class="n">kjp1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">j_vals</span><span class="p">,</span> <span class="n">one_minus_alpha</span><span class="p">)</span>
</span><span id="__span-0-2147"><a id="__codelineno-0-2147" name="__codelineno-0-2147"></a>        <span class="n">A_j_kp1</span> <span class="o">=</span> <span class="n">kjp2</span> <span class="o">+</span> <span class="n">kj</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">kjp1</span>
</span><span id="__span-0-2148"><a id="__codelineno-0-2148" name="__codelineno-0-2148"></a>
</span><span id="__span-0-2149"><a id="__codelineno-0-2149" name="__codelineno-0-2149"></a>        <span class="c1"># Special handling for j=0 if it&#39;s in the range:</span>
</span><span id="__span-0-2150"><a id="__codelineno-0-2150" name="__codelineno-0-2150"></a>        <span class="c1"># A_{0,k+1} = k^{1-α} - (k+α)(k+1)^{-α}</span>
</span><span id="__span-0-2151"><a id="__codelineno-0-2151" name="__codelineno-0-2151"></a>        <span class="k">if</span> <span class="n">start_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="__span-0-2152"><a id="__codelineno-0-2152" name="__codelineno-0-2152"></a>            <span class="n">k_power</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span>
</span><span id="__span-0-2153"><a id="__codelineno-0-2153" name="__codelineno-0-2153"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">one_minus_alpha</span>
</span><span id="__span-0-2154"><a id="__codelineno-0-2154" name="__codelineno-0-2154"></a>            <span class="p">)</span>
</span><span id="__span-0-2155"><a id="__codelineno-0-2155" name="__codelineno-0-2155"></a>            <span class="n">kp1_neg_alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span>
</span><span id="__span-0-2156"><a id="__codelineno-0-2156" name="__codelineno-0-2156"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="o">-</span><span class="n">alpha</span>
</span><span id="__span-0-2157"><a id="__codelineno-0-2157" name="__codelineno-0-2157"></a>            <span class="p">)</span>
</span><span id="__span-0-2158"><a id="__codelineno-0-2158" name="__codelineno-0-2158"></a>            <span class="n">A_j_kp1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">k_power</span> <span class="o">-</span> <span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">kp1_neg_alpha</span>
</span><span id="__span-0-2159"><a id="__codelineno-0-2159" name="__codelineno-0-2159"></a>
</span><span id="__span-0-2160"><a id="__codelineno-0-2160" name="__codelineno-0-2160"></a>        <span class="c1"># Update ALL state components (forward integrates all, not len-1)</span>
</span><span id="__span-0-2161"><a id="__codelineno-0-2161" name="__codelineno-0-2161"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_current</span><span class="p">)):</span>
</span><span id="__span-0-2162"><a id="__codelineno-0-2162" name="__codelineno-0-2162"></a>            <span class="c1"># Compute convolution sum: sum_{j=start_idx}^{k-1} A_{j,k+1} * y_j[i]</span>
</span><span id="__span-0-2163"><a id="__codelineno-0-2163" name="__codelineno-0-2163"></a>            <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="__span-0-2164"><a id="__codelineno-0-2164" name="__codelineno-0-2164"></a>                <span class="n">convolution_sum</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-0-2165"><a id="__codelineno-0-2165" name="__codelineno-0-2165"></a>                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
</span><span id="__span-0-2166"><a id="__codelineno-0-2166" name="__codelineno-0-2166"></a>                    <span class="c1"># local_idx = j - start_idx</span>
</span><span id="__span-0-2167"><a id="__codelineno-0-2167" name="__codelineno-0-2167"></a>                    <span class="n">local_idx</span> <span class="o">=</span> <span class="n">j</span> <span class="o">-</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="__span-0-2168"><a id="__codelineno-0-2168" name="__codelineno-0-2168"></a>                    <span class="c1"># the most restrict formulation should be local_idx = j - start_idx + 1</span>
</span><span id="__span-0-2169"><a id="__codelineno-0-2169" name="__codelineno-0-2169"></a>                    <span class="n">convolution_sum</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-2170"><a id="__codelineno-0-2170" name="__codelineno-0-2170"></a>                        <span class="n">convolution_sum</span> <span class="o">+</span> <span class="n">A_j_kp1</span><span class="p">[</span><span class="n">local_idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">y_history</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
</span><span id="__span-0-2171"><a id="__codelineno-0-2171" name="__codelineno-0-2171"></a>                    <span class="p">)</span>
</span><span id="__span-0-2172"><a id="__codelineno-0-2172" name="__codelineno-0-2172"></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-2173"><a id="__codelineno-0-2173" name="__codelineno-0-2173"></a>                <span class="n">convolution_sum</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-0-2174"><a id="__codelineno-0-2174" name="__codelineno-0-2174"></a>
</span><span id="__span-0-2175"><a id="__codelineno-0-2175" name="__codelineno-0-2175"></a>            <span class="c1"># y_{k+1} = Γ(2-α) * h^α * f_k - convolution_sum</span>
</span><span id="__span-0-2176"><a id="__codelineno-0-2176" name="__codelineno-0-2176"></a>            <span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">h_alpha_gamma</span> <span class="o">*</span> <span class="n">f_k</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">convolution_sum</span>
</span><span id="__span-0-2177"><a id="__codelineno-0-2177" name="__codelineno-0-2177"></a>            <span class="n">y_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="__span-0-2178"><a id="__codelineno-0-2178" name="__codelineno-0-2178"></a>
</span><span id="__span-0-2179"><a id="__codelineno-0-2179" name="__codelineno-0-2179"></a>    <span class="k">return</span> <span class="n">y_history</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.backward_trap" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">backward_trap</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">backward_trap</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y_aug</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">yhistory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]],</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Backward Product Trapezoidal method for adjoint sensitivity.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></code>)
          –
          <div class="doc-md-description">
            <p>Augmented dynamics.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y_aug</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>, <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>, <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>]</code>)
          –
          <div class="doc-md-description">
            <p>Initial augmented state.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>alpha</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a> | <a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Fractional order.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Flipped time grid.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>yhistory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>)
          –
          <div class="doc-md-description">
            <p>Forward trajectory.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Memory limit.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>], <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>
          –
          <div class="doc-md-description">
            <p>Final adjoint states and parameter gradients.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-2182">2182</a></span>
<span class="normal"><a href="#__codelineno-0-2183">2183</a></span>
<span class="normal"><a href="#__codelineno-0-2184">2184</a></span>
<span class="normal"><a href="#__codelineno-0-2185">2185</a></span>
<span class="normal"><a href="#__codelineno-0-2186">2186</a></span>
<span class="normal"><a href="#__codelineno-0-2187">2187</a></span>
<span class="normal"><a href="#__codelineno-0-2188">2188</a></span>
<span class="normal"><a href="#__codelineno-0-2189">2189</a></span>
<span class="normal"><a href="#__codelineno-0-2190">2190</a></span>
<span class="normal"><a href="#__codelineno-0-2191">2191</a></span>
<span class="normal"><a href="#__codelineno-0-2192">2192</a></span>
<span class="normal"><a href="#__codelineno-0-2193">2193</a></span>
<span class="normal"><a href="#__codelineno-0-2194">2194</a></span>
<span class="normal"><a href="#__codelineno-0-2195">2195</a></span>
<span class="normal"><a href="#__codelineno-0-2196">2196</a></span>
<span class="normal"><a href="#__codelineno-0-2197">2197</a></span>
<span class="normal"><a href="#__codelineno-0-2198">2198</a></span>
<span class="normal"><a href="#__codelineno-0-2199">2199</a></span>
<span class="normal"><a href="#__codelineno-0-2200">2200</a></span>
<span class="normal"><a href="#__codelineno-0-2201">2201</a></span>
<span class="normal"><a href="#__codelineno-0-2202">2202</a></span>
<span class="normal"><a href="#__codelineno-0-2203">2203</a></span>
<span class="normal"><a href="#__codelineno-0-2204">2204</a></span>
<span class="normal"><a href="#__codelineno-0-2205">2205</a></span>
<span class="normal"><a href="#__codelineno-0-2206">2206</a></span>
<span class="normal"><a href="#__codelineno-0-2207">2207</a></span>
<span class="normal"><a href="#__codelineno-0-2208">2208</a></span>
<span class="normal"><a href="#__codelineno-0-2209">2209</a></span>
<span class="normal"><a href="#__codelineno-0-2210">2210</a></span>
<span class="normal"><a href="#__codelineno-0-2211">2211</a></span>
<span class="normal"><a href="#__codelineno-0-2212">2212</a></span>
<span class="normal"><a href="#__codelineno-0-2213">2213</a></span>
<span class="normal"><a href="#__codelineno-0-2214">2214</a></span>
<span class="normal"><a href="#__codelineno-0-2215">2215</a></span>
<span class="normal"><a href="#__codelineno-0-2216">2216</a></span>
<span class="normal"><a href="#__codelineno-0-2217">2217</a></span>
<span class="normal"><a href="#__codelineno-0-2218">2218</a></span>
<span class="normal"><a href="#__codelineno-0-2219">2219</a></span>
<span class="normal"><a href="#__codelineno-0-2220">2220</a></span>
<span class="normal"><a href="#__codelineno-0-2221">2221</a></span>
<span class="normal"><a href="#__codelineno-0-2222">2222</a></span>
<span class="normal"><a href="#__codelineno-0-2223">2223</a></span>
<span class="normal"><a href="#__codelineno-0-2224">2224</a></span>
<span class="normal"><a href="#__codelineno-0-2225">2225</a></span>
<span class="normal"><a href="#__codelineno-0-2226">2226</a></span>
<span class="normal"><a href="#__codelineno-0-2227">2227</a></span>
<span class="normal"><a href="#__codelineno-0-2228">2228</a></span>
<span class="normal"><a href="#__codelineno-0-2229">2229</a></span>
<span class="normal"><a href="#__codelineno-0-2230">2230</a></span>
<span class="normal"><a href="#__codelineno-0-2231">2231</a></span>
<span class="normal"><a href="#__codelineno-0-2232">2232</a></span>
<span class="normal"><a href="#__codelineno-0-2233">2233</a></span>
<span class="normal"><a href="#__codelineno-0-2234">2234</a></span>
<span class="normal"><a href="#__codelineno-0-2235">2235</a></span>
<span class="normal"><a href="#__codelineno-0-2236">2236</a></span>
<span class="normal"><a href="#__codelineno-0-2237">2237</a></span>
<span class="normal"><a href="#__codelineno-0-2238">2238</a></span>
<span class="normal"><a href="#__codelineno-0-2239">2239</a></span>
<span class="normal"><a href="#__codelineno-0-2240">2240</a></span>
<span class="normal"><a href="#__codelineno-0-2241">2241</a></span>
<span class="normal"><a href="#__codelineno-0-2242">2242</a></span>
<span class="normal"><a href="#__codelineno-0-2243">2243</a></span>
<span class="normal"><a href="#__codelineno-0-2244">2244</a></span>
<span class="normal"><a href="#__codelineno-0-2245">2245</a></span>
<span class="normal"><a href="#__codelineno-0-2246">2246</a></span>
<span class="normal"><a href="#__codelineno-0-2247">2247</a></span>
<span class="normal"><a href="#__codelineno-0-2248">2248</a></span>
<span class="normal"><a href="#__codelineno-0-2249">2249</a></span>
<span class="normal"><a href="#__codelineno-0-2250">2250</a></span>
<span class="normal"><a href="#__codelineno-0-2251">2251</a></span>
<span class="normal"><a href="#__codelineno-0-2252">2252</a></span>
<span class="normal"><a href="#__codelineno-0-2253">2253</a></span>
<span class="normal"><a href="#__codelineno-0-2254">2254</a></span>
<span class="normal"><a href="#__codelineno-0-2255">2255</a></span>
<span class="normal"><a href="#__codelineno-0-2256">2256</a></span>
<span class="normal"><a href="#__codelineno-0-2257">2257</a></span>
<span class="normal"><a href="#__codelineno-0-2258">2258</a></span>
<span class="normal"><a href="#__codelineno-0-2259">2259</a></span>
<span class="normal"><a href="#__codelineno-0-2260">2260</a></span>
<span class="normal"><a href="#__codelineno-0-2261">2261</a></span>
<span class="normal"><a href="#__codelineno-0-2262">2262</a></span>
<span class="normal"><a href="#__codelineno-0-2263">2263</a></span>
<span class="normal"><a href="#__codelineno-0-2264">2264</a></span>
<span class="normal"><a href="#__codelineno-0-2265">2265</a></span>
<span class="normal"><a href="#__codelineno-0-2266">2266</a></span>
<span class="normal"><a href="#__codelineno-0-2267">2267</a></span>
<span class="normal"><a href="#__codelineno-0-2268">2268</a></span>
<span class="normal"><a href="#__codelineno-0-2269">2269</a></span>
<span class="normal"><a href="#__codelineno-0-2270">2270</a></span>
<span class="normal"><a href="#__codelineno-0-2271">2271</a></span>
<span class="normal"><a href="#__codelineno-0-2272">2272</a></span>
<span class="normal"><a href="#__codelineno-0-2273">2273</a></span>
<span class="normal"><a href="#__codelineno-0-2274">2274</a></span>
<span class="normal"><a href="#__codelineno-0-2275">2275</a></span>
<span class="normal"><a href="#__codelineno-0-2276">2276</a></span>
<span class="normal"><a href="#__codelineno-0-2277">2277</a></span>
<span class="normal"><a href="#__codelineno-0-2278">2278</a></span>
<span class="normal"><a href="#__codelineno-0-2279">2279</a></span>
<span class="normal"><a href="#__codelineno-0-2280">2280</a></span>
<span class="normal"><a href="#__codelineno-0-2281">2281</a></span>
<span class="normal"><a href="#__codelineno-0-2282">2282</a></span>
<span class="normal"><a href="#__codelineno-0-2283">2283</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-2182"><a id="__codelineno-0-2182" name="__codelineno-0-2182"></a><span class="k">def</span><span class="w"> </span><span class="nf">backward_trap</span><span class="p">(</span>
</span><span id="__span-0-2183"><a id="__codelineno-0-2183" name="__codelineno-0-2183"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
</span><span id="__span-0-2184"><a id="__codelineno-0-2184" name="__codelineno-0-2184"></a>    <span class="n">y_aug</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">],</span>
</span><span id="__span-0-2185"><a id="__codelineno-0-2185" name="__codelineno-0-2185"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="__span-0-2186"><a id="__codelineno-0-2186" name="__codelineno-0-2186"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-2187"><a id="__codelineno-0-2187" name="__codelineno-0-2187"></a>    <span class="n">yhistory</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
</span><span id="__span-0-2188"><a id="__codelineno-0-2188" name="__codelineno-0-2188"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-2189"><a id="__codelineno-0-2189" name="__codelineno-0-2189"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="__span-0-2190"><a id="__codelineno-0-2190" name="__codelineno-0-2190"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-2191"><a id="__codelineno-0-2191" name="__codelineno-0-2191"></a><span class="sd">    Backward Product Trapezoidal method for adjoint sensitivity.</span>
</span><span id="__span-0-2192"><a id="__codelineno-0-2192" name="__codelineno-0-2192"></a>
</span><span id="__span-0-2193"><a id="__codelineno-0-2193" name="__codelineno-0-2193"></a><span class="sd">    Args:</span>
</span><span id="__span-0-2194"><a id="__codelineno-0-2194" name="__codelineno-0-2194"></a><span class="sd">        ode_func: Augmented dynamics.</span>
</span><span id="__span-0-2195"><a id="__codelineno-0-2195" name="__codelineno-0-2195"></a><span class="sd">        y_aug: Initial augmented state.</span>
</span><span id="__span-0-2196"><a id="__codelineno-0-2196" name="__codelineno-0-2196"></a><span class="sd">        alpha: Fractional order.</span>
</span><span id="__span-0-2197"><a id="__codelineno-0-2197" name="__codelineno-0-2197"></a><span class="sd">        t_grid: Flipped time grid.</span>
</span><span id="__span-0-2198"><a id="__codelineno-0-2198" name="__codelineno-0-2198"></a><span class="sd">        yhistory: Forward trajectory.</span>
</span><span id="__span-0-2199"><a id="__codelineno-0-2199" name="__codelineno-0-2199"></a><span class="sd">        memory: Memory limit.</span>
</span><span id="__span-0-2200"><a id="__codelineno-0-2200" name="__codelineno-0-2200"></a>
</span><span id="__span-0-2201"><a id="__codelineno-0-2201" name="__codelineno-0-2201"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-2202"><a id="__codelineno-0-2202" name="__codelineno-0-2202"></a><span class="sd">        Final adjoint states and parameter gradients.</span>
</span><span id="__span-0-2203"><a id="__codelineno-0-2203" name="__codelineno-0-2203"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-2204"><a id="__codelineno-0-2204" name="__codelineno-0-2204"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="__span-0-2205"><a id="__codelineno-0-2205" name="__codelineno-0-2205"></a>        <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_grid</span><span class="p">)</span>
</span><span id="__span-0-2206"><a id="__codelineno-0-2206" name="__codelineno-0-2206"></a>        <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
</span><span id="__span-0-2207"><a id="__codelineno-0-2207" name="__codelineno-0-2207"></a>        <span class="n">h_alpha_gamma</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="mi">2</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span>
</span><span id="__span-0-2208"><a id="__codelineno-0-2208" name="__codelineno-0-2208"></a>        <span class="n">one_minus_alpha</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span>
</span><span id="__span-0-2209"><a id="__codelineno-0-2209" name="__codelineno-0-2209"></a>
</span><span id="__span-0-2210"><a id="__codelineno-0-2210" name="__codelineno-0-2210"></a>        <span class="n">_</span><span class="p">,</span> <span class="n">adj_y0</span><span class="p">,</span> <span class="n">adj_params0</span> <span class="o">=</span> <span class="n">y_aug</span>
</span><span id="__span-0-2211"><a id="__codelineno-0-2211" name="__codelineno-0-2211"></a>        <span class="n">device</span> <span class="o">=</span> <span class="n">adj_y0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
</span><span id="__span-0-2212"><a id="__codelineno-0-2212" name="__codelineno-0-2212"></a>        <span class="n">dtype</span> <span class="o">=</span> <span class="n">adj_y0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-2213"><a id="__codelineno-0-2213" name="__codelineno-0-2213"></a>
</span><span id="__span-0-2214"><a id="__codelineno-0-2214" name="__codelineno-0-2214"></a>        <span class="c1"># Initialize adjoint history lists for each component (with initial values)</span>
</span><span id="__span-0-2215"><a id="__codelineno-0-2215" name="__codelineno-0-2215"></a>        <span class="n">adjy_history</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-0-2216"><a id="__codelineno-0-2216" name="__codelineno-0-2216"></a>            <span class="p">[</span>
</span><span id="__span-0-2217"><a id="__codelineno-0-2217" name="__codelineno-0-2217"></a>                <span class="n">xx</span><span class="p">,</span>
</span><span id="__span-0-2218"><a id="__codelineno-0-2218" name="__codelineno-0-2218"></a>            <span class="p">]</span>
</span><span id="__span-0-2219"><a id="__codelineno-0-2219" name="__codelineno-0-2219"></a>            <span class="k">for</span> <span class="n">xx</span> <span class="ow">in</span> <span class="n">adj_y0</span>
</span><span id="__span-0-2220"><a id="__codelineno-0-2220" name="__codelineno-0-2220"></a>        <span class="p">]</span>
</span><span id="__span-0-2221"><a id="__codelineno-0-2221" name="__codelineno-0-2221"></a>
</span><span id="__span-0-2222"><a id="__codelineno-0-2222" name="__codelineno-0-2222"></a>        <span class="c1"># Clone initial adjoint values</span>
</span><span id="__span-0-2223"><a id="__codelineno-0-2223" name="__codelineno-0-2223"></a>        <span class="n">adj_y</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">adj_y0</span><span class="p">)</span>
</span><span id="__span-0-2224"><a id="__codelineno-0-2224" name="__codelineno-0-2224"></a>        <span class="n">adj_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">adj_params0</span><span class="p">)</span>
</span><span id="__span-0-2225"><a id="__codelineno-0-2225" name="__codelineno-0-2225"></a>
</span><span id="__span-0-2226"><a id="__codelineno-0-2226" name="__codelineno-0-2226"></a>        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">2</span><span class="p">):</span>
</span><span id="__span-0-2227"><a id="__codelineno-0-2227" name="__codelineno-0-2227"></a>            <span class="n">tk</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
</span><span id="__span-0-2228"><a id="__codelineno-0-2228" name="__codelineno-0-2228"></a>            <span class="c1"># y_state = list([y[-k - 1] for y in yhistory])</span>
</span><span id="__span-0-2229"><a id="__codelineno-0-2229" name="__codelineno-0-2229"></a>            <span class="n">y_state</span> <span class="o">=</span> <span class="nb">list</span><span class="p">([</span><span class="n">y</span><span class="p">[</span><span class="o">-</span><span class="n">k</span> <span class="o">-</span> <span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">yhistory</span><span class="p">])</span>
</span><span id="__span-0-2230"><a id="__codelineno-0-2230" name="__codelineno-0-2230"></a>
</span><span id="__span-0-2231"><a id="__codelineno-0-2231" name="__codelineno-0-2231"></a>            <span class="n">func_eval</span><span class="p">,</span> <span class="n">vjp_y</span><span class="p">,</span> <span class="n">vjp_params</span> <span class="o">=</span> <span class="n">ode_func</span><span class="p">(</span><span class="n">tk</span><span class="p">,</span> <span class="p">(</span><span class="n">y_state</span><span class="p">,</span> <span class="n">adj_y</span><span class="p">,</span> <span class="n">adj_params</span><span class="p">))</span>
</span><span id="__span-0-2232"><a id="__codelineno-0-2232" name="__codelineno-0-2232"></a>
</span><span id="__span-0-2233"><a id="__codelineno-0-2233" name="__codelineno-0-2233"></a>            <span class="c1"># Determine memory range</span>
</span><span id="__span-0-2234"><a id="__codelineno-0-2234" name="__codelineno-0-2234"></a>            <span class="k">if</span> <span class="n">memory</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-2235"><a id="__codelineno-0-2235" name="__codelineno-0-2235"></a>                <span class="n">memory_length</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="__span-0-2236"><a id="__codelineno-0-2236" name="__codelineno-0-2236"></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-2237"><a id="__codelineno-0-2237" name="__codelineno-0-2237"></a>                <span class="n">memory_length</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-2238"><a id="__codelineno-0-2238" name="__codelineno-0-2238"></a>
</span><span id="__span-0-2239"><a id="__codelineno-0-2239" name="__codelineno-0-2239"></a>            <span class="n">start_idx</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">memory_length</span><span class="p">)</span>
</span><span id="__span-0-2240"><a id="__codelineno-0-2240" name="__codelineno-0-2240"></a>
</span><span id="__span-0-2241"><a id="__codelineno-0-2241" name="__codelineno-0-2241"></a>            <span class="c1"># Compute A_{j,k+1} weights for indices from start_idx to k</span>
</span><span id="__span-0-2242"><a id="__codelineno-0-2242" name="__codelineno-0-2242"></a>            <span class="n">j_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-2243"><a id="__codelineno-0-2243" name="__codelineno-0-2243"></a>
</span><span id="__span-0-2244"><a id="__codelineno-0-2244" name="__codelineno-0-2244"></a>            <span class="c1"># General formula for j &gt;= 1:</span>
</span><span id="__span-0-2245"><a id="__codelineno-0-2245" name="__codelineno-0-2245"></a>            <span class="c1"># A_{j,k+1} = (k+2-j)^{1-α} + (k-j)^{1-α} - 2(k+1-j)^{1-α}</span>
</span><span id="__span-0-2246"><a id="__codelineno-0-2246" name="__codelineno-0-2246"></a>            <span class="n">kjp2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">j_vals</span><span class="p">,</span> <span class="n">one_minus_alpha</span><span class="p">)</span>
</span><span id="__span-0-2247"><a id="__codelineno-0-2247" name="__codelineno-0-2247"></a>            <span class="n">kj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">k</span> <span class="o">-</span> <span class="n">j_vals</span><span class="p">,</span> <span class="n">one_minus_alpha</span><span class="p">)</span>
</span><span id="__span-0-2248"><a id="__codelineno-0-2248" name="__codelineno-0-2248"></a>            <span class="n">kjp1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">j_vals</span><span class="p">,</span> <span class="n">one_minus_alpha</span><span class="p">)</span>
</span><span id="__span-0-2249"><a id="__codelineno-0-2249" name="__codelineno-0-2249"></a>            <span class="n">A_j_kp1</span> <span class="o">=</span> <span class="n">kjp2</span> <span class="o">+</span> <span class="n">kj</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">kjp1</span>
</span><span id="__span-0-2250"><a id="__codelineno-0-2250" name="__codelineno-0-2250"></a>
</span><span id="__span-0-2251"><a id="__codelineno-0-2251" name="__codelineno-0-2251"></a>            <span class="c1"># Special handling for j=0 if it&#39;s in the range:</span>
</span><span id="__span-0-2252"><a id="__codelineno-0-2252" name="__codelineno-0-2252"></a>            <span class="c1"># A_{0,k+1} = k^{1-α} - (k+α)(k+1)^{-α}</span>
</span><span id="__span-0-2253"><a id="__codelineno-0-2253" name="__codelineno-0-2253"></a>            <span class="k">if</span> <span class="n">start_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="__span-0-2254"><a id="__codelineno-0-2254" name="__codelineno-0-2254"></a>                <span class="n">k_power</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span>
</span><span id="__span-0-2255"><a id="__codelineno-0-2255" name="__codelineno-0-2255"></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">one_minus_alpha</span>
</span><span id="__span-0-2256"><a id="__codelineno-0-2256" name="__codelineno-0-2256"></a>                <span class="p">)</span>
</span><span id="__span-0-2257"><a id="__codelineno-0-2257" name="__codelineno-0-2257"></a>                <span class="n">kp1_neg_alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span>
</span><span id="__span-0-2258"><a id="__codelineno-0-2258" name="__codelineno-0-2258"></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="o">-</span><span class="n">alpha</span>
</span><span id="__span-0-2259"><a id="__codelineno-0-2259" name="__codelineno-0-2259"></a>                <span class="p">)</span>
</span><span id="__span-0-2260"><a id="__codelineno-0-2260" name="__codelineno-0-2260"></a>                <span class="n">A_j_kp1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">k_power</span> <span class="o">-</span> <span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">kp1_neg_alpha</span>
</span><span id="__span-0-2261"><a id="__codelineno-0-2261" name="__codelineno-0-2261"></a>
</span><span id="__span-0-2262"><a id="__codelineno-0-2262" name="__codelineno-0-2262"></a>            <span class="c1"># Update all adjoint components</span>
</span><span id="__span-0-2263"><a id="__codelineno-0-2263" name="__codelineno-0-2263"></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">adj_y</span><span class="p">)):</span>
</span><span id="__span-0-2264"><a id="__codelineno-0-2264" name="__codelineno-0-2264"></a>                <span class="c1"># Calculate history sum - note: range goes to k+1 (one more than forward)</span>
</span><span id="__span-0-2265"><a id="__codelineno-0-2265" name="__codelineno-0-2265"></a>                <span class="n">convolution_sum</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-0-2266"><a id="__codelineno-0-2266" name="__codelineno-0-2266"></a>                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-2267"><a id="__codelineno-0-2267" name="__codelineno-0-2267"></a>                    <span class="n">local_idx</span> <span class="o">=</span> <span class="n">j</span> <span class="o">-</span> <span class="n">start_idx</span>
</span><span id="__span-0-2268"><a id="__codelineno-0-2268" name="__codelineno-0-2268"></a>                    <span class="n">convolution_sum</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-2269"><a id="__codelineno-0-2269" name="__codelineno-0-2269"></a>                        <span class="n">convolution_sum</span> <span class="o">+</span> <span class="n">A_j_kp1</span><span class="p">[</span><span class="n">local_idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">adjy_history</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
</span><span id="__span-0-2270"><a id="__codelineno-0-2270" name="__codelineno-0-2270"></a>                    <span class="p">)</span>
</span><span id="__span-0-2271"><a id="__codelineno-0-2271" name="__codelineno-0-2271"></a>
</span><span id="__span-0-2272"><a id="__codelineno-0-2272" name="__codelineno-0-2272"></a>                <span class="c1"># Update adjoint state</span>
</span><span id="__span-0-2273"><a id="__codelineno-0-2273" name="__codelineno-0-2273"></a>                <span class="n">adj_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">h_alpha_gamma</span> <span class="o">*</span> <span class="n">vjp_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">convolution_sum</span>
</span><span id="__span-0-2274"><a id="__codelineno-0-2274" name="__codelineno-0-2274"></a>                <span class="n">adjy_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">adj_y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="__span-0-2275"><a id="__codelineno-0-2275" name="__codelineno-0-2275"></a>
</span><span id="__span-0-2276"><a id="__codelineno-0-2276" name="__codelineno-0-2276"></a>            <span class="c1"># Update parameter gradients</span>
</span><span id="__span-0-2277"><a id="__codelineno-0-2277" name="__codelineno-0-2277"></a>            <span class="k">if</span> <span class="n">adj_params</span> <span class="ow">and</span> <span class="n">vjp_params</span><span class="p">:</span>
</span><span id="__span-0-2278"><a id="__codelineno-0-2278" name="__codelineno-0-2278"></a>                <span class="k">for</span> <span class="n">ap</span><span class="p">,</span> <span class="n">vp</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">adj_params</span><span class="p">,</span> <span class="n">vjp_params</span><span class="p">):</span>
</span><span id="__span-0-2279"><a id="__codelineno-0-2279" name="__codelineno-0-2279"></a>                    <span class="n">ap</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">vp</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">h</span><span class="p">)</span>
</span><span id="__span-0-2280"><a id="__codelineno-0-2280" name="__codelineno-0-2280"></a>
</span><span id="__span-0-2281"><a id="__codelineno-0-2281" name="__codelineno-0-2281"></a>    <span class="k">del</span> <span class="n">adjy_history</span><span class="p">,</span> <span class="n">yhistory</span>
</span><span id="__span-0-2282"><a id="__codelineno-0-2282" name="__codelineno-0-2282"></a>
</span><span id="__span-0-2283"><a id="__codelineno-0-2283" name="__codelineno-0-2283"></a>    <span class="k">return</span> <span class="n">adj_y</span><span class="p">,</span> <span class="n">adj_params</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.forward_l1" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">forward_l1</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">forward_l1</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Forward L1 scheme for Caputo FDEs.</p>
<p>Accuracy <span class="arithmatex">\(O(h^{2-\alpha})\)</span>.
Formula:</p>
<div class="arithmatex">\[y_{k+1} = \frac{h^\alpha}{\Gamma(2-\alpha)} f_k - \sum_{j=0}^{k} c_j^{(k)} y_j\]</div>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></code>)
          –
          <div class="doc-md-description">
            <p>Function <span class="arithmatex">\(f(t, y)\)</span>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y0_tuple</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]</code>)
          –
          <div class="doc-md-description">
            <p>Initial state.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>alpha</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a> | <a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Fractional order.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Time grid.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Memory limit.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>
          –
          <div class="doc-md-description">
            <p>State trajectory.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-2286">2286</a></span>
<span class="normal"><a href="#__codelineno-0-2287">2287</a></span>
<span class="normal"><a href="#__codelineno-0-2288">2288</a></span>
<span class="normal"><a href="#__codelineno-0-2289">2289</a></span>
<span class="normal"><a href="#__codelineno-0-2290">2290</a></span>
<span class="normal"><a href="#__codelineno-0-2291">2291</a></span>
<span class="normal"><a href="#__codelineno-0-2292">2292</a></span>
<span class="normal"><a href="#__codelineno-0-2293">2293</a></span>
<span class="normal"><a href="#__codelineno-0-2294">2294</a></span>
<span class="normal"><a href="#__codelineno-0-2295">2295</a></span>
<span class="normal"><a href="#__codelineno-0-2296">2296</a></span>
<span class="normal"><a href="#__codelineno-0-2297">2297</a></span>
<span class="normal"><a href="#__codelineno-0-2298">2298</a></span>
<span class="normal"><a href="#__codelineno-0-2299">2299</a></span>
<span class="normal"><a href="#__codelineno-0-2300">2300</a></span>
<span class="normal"><a href="#__codelineno-0-2301">2301</a></span>
<span class="normal"><a href="#__codelineno-0-2302">2302</a></span>
<span class="normal"><a href="#__codelineno-0-2303">2303</a></span>
<span class="normal"><a href="#__codelineno-0-2304">2304</a></span>
<span class="normal"><a href="#__codelineno-0-2305">2305</a></span>
<span class="normal"><a href="#__codelineno-0-2306">2306</a></span>
<span class="normal"><a href="#__codelineno-0-2307">2307</a></span>
<span class="normal"><a href="#__codelineno-0-2308">2308</a></span>
<span class="normal"><a href="#__codelineno-0-2309">2309</a></span>
<span class="normal"><a href="#__codelineno-0-2310">2310</a></span>
<span class="normal"><a href="#__codelineno-0-2311">2311</a></span>
<span class="normal"><a href="#__codelineno-0-2312">2312</a></span>
<span class="normal"><a href="#__codelineno-0-2313">2313</a></span>
<span class="normal"><a href="#__codelineno-0-2314">2314</a></span>
<span class="normal"><a href="#__codelineno-0-2315">2315</a></span>
<span class="normal"><a href="#__codelineno-0-2316">2316</a></span>
<span class="normal"><a href="#__codelineno-0-2317">2317</a></span>
<span class="normal"><a href="#__codelineno-0-2318">2318</a></span>
<span class="normal"><a href="#__codelineno-0-2319">2319</a></span>
<span class="normal"><a href="#__codelineno-0-2320">2320</a></span>
<span class="normal"><a href="#__codelineno-0-2321">2321</a></span>
<span class="normal"><a href="#__codelineno-0-2322">2322</a></span>
<span class="normal"><a href="#__codelineno-0-2323">2323</a></span>
<span class="normal"><a href="#__codelineno-0-2324">2324</a></span>
<span class="normal"><a href="#__codelineno-0-2325">2325</a></span>
<span class="normal"><a href="#__codelineno-0-2326">2326</a></span>
<span class="normal"><a href="#__codelineno-0-2327">2327</a></span>
<span class="normal"><a href="#__codelineno-0-2328">2328</a></span>
<span class="normal"><a href="#__codelineno-0-2329">2329</a></span>
<span class="normal"><a href="#__codelineno-0-2330">2330</a></span>
<span class="normal"><a href="#__codelineno-0-2331">2331</a></span>
<span class="normal"><a href="#__codelineno-0-2332">2332</a></span>
<span class="normal"><a href="#__codelineno-0-2333">2333</a></span>
<span class="normal"><a href="#__codelineno-0-2334">2334</a></span>
<span class="normal"><a href="#__codelineno-0-2335">2335</a></span>
<span class="normal"><a href="#__codelineno-0-2336">2336</a></span>
<span class="normal"><a href="#__codelineno-0-2337">2337</a></span>
<span class="normal"><a href="#__codelineno-0-2338">2338</a></span>
<span class="normal"><a href="#__codelineno-0-2339">2339</a></span>
<span class="normal"><a href="#__codelineno-0-2340">2340</a></span>
<span class="normal"><a href="#__codelineno-0-2341">2341</a></span>
<span class="normal"><a href="#__codelineno-0-2342">2342</a></span>
<span class="normal"><a href="#__codelineno-0-2343">2343</a></span>
<span class="normal"><a href="#__codelineno-0-2344">2344</a></span>
<span class="normal"><a href="#__codelineno-0-2345">2345</a></span>
<span class="normal"><a href="#__codelineno-0-2346">2346</a></span>
<span class="normal"><a href="#__codelineno-0-2347">2347</a></span>
<span class="normal"><a href="#__codelineno-0-2348">2348</a></span>
<span class="normal"><a href="#__codelineno-0-2349">2349</a></span>
<span class="normal"><a href="#__codelineno-0-2350">2350</a></span>
<span class="normal"><a href="#__codelineno-0-2351">2351</a></span>
<span class="normal"><a href="#__codelineno-0-2352">2352</a></span>
<span class="normal"><a href="#__codelineno-0-2353">2353</a></span>
<span class="normal"><a href="#__codelineno-0-2354">2354</a></span>
<span class="normal"><a href="#__codelineno-0-2355">2355</a></span>
<span class="normal"><a href="#__codelineno-0-2356">2356</a></span>
<span class="normal"><a href="#__codelineno-0-2357">2357</a></span>
<span class="normal"><a href="#__codelineno-0-2358">2358</a></span>
<span class="normal"><a href="#__codelineno-0-2359">2359</a></span>
<span class="normal"><a href="#__codelineno-0-2360">2360</a></span>
<span class="normal"><a href="#__codelineno-0-2361">2361</a></span>
<span class="normal"><a href="#__codelineno-0-2362">2362</a></span>
<span class="normal"><a href="#__codelineno-0-2363">2363</a></span>
<span class="normal"><a href="#__codelineno-0-2364">2364</a></span>
<span class="normal"><a href="#__codelineno-0-2365">2365</a></span>
<span class="normal"><a href="#__codelineno-0-2366">2366</a></span>
<span class="normal"><a href="#__codelineno-0-2367">2367</a></span>
<span class="normal"><a href="#__codelineno-0-2368">2368</a></span>
<span class="normal"><a href="#__codelineno-0-2369">2369</a></span>
<span class="normal"><a href="#__codelineno-0-2370">2370</a></span>
<span class="normal"><a href="#__codelineno-0-2371">2371</a></span>
<span class="normal"><a href="#__codelineno-0-2372">2372</a></span>
<span class="normal"><a href="#__codelineno-0-2373">2373</a></span>
<span class="normal"><a href="#__codelineno-0-2374">2374</a></span>
<span class="normal"><a href="#__codelineno-0-2375">2375</a></span>
<span class="normal"><a href="#__codelineno-0-2376">2376</a></span>
<span class="normal"><a href="#__codelineno-0-2377">2377</a></span>
<span class="normal"><a href="#__codelineno-0-2378">2378</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-2286"><a id="__codelineno-0-2286" name="__codelineno-0-2286"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward_l1</span><span class="p">(</span>
</span><span id="__span-0-2287"><a id="__codelineno-0-2287" name="__codelineno-0-2287"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
</span><span id="__span-0-2288"><a id="__codelineno-0-2288" name="__codelineno-0-2288"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-2289"><a id="__codelineno-0-2289" name="__codelineno-0-2289"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="__span-0-2290"><a id="__codelineno-0-2290" name="__codelineno-0-2290"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-2291"><a id="__codelineno-0-2291" name="__codelineno-0-2291"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-2292"><a id="__codelineno-0-2292" name="__codelineno-0-2292"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="__span-0-2293"><a id="__codelineno-0-2293" name="__codelineno-0-2293"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-2294"><a id="__codelineno-0-2294" name="__codelineno-0-2294"></a><span class="sd">    Forward L1 scheme for Caputo FDEs.</span>
</span><span id="__span-0-2295"><a id="__codelineno-0-2295" name="__codelineno-0-2295"></a>
</span><span id="__span-0-2296"><a id="__codelineno-0-2296" name="__codelineno-0-2296"></a><span class="sd">    Accuracy $O(h^{2-\alpha})$.</span>
</span><span id="__span-0-2297"><a id="__codelineno-0-2297" name="__codelineno-0-2297"></a><span class="sd">    Formula:</span>
</span><span id="__span-0-2298"><a id="__codelineno-0-2298" name="__codelineno-0-2298"></a>
</span><span id="__span-0-2299"><a id="__codelineno-0-2299" name="__codelineno-0-2299"></a><span class="sd">    $$y_{k+1} = \frac{h^\alpha}{\Gamma(2-\alpha)} f_k - \sum_{j=0}^{k} c_j^{(k)} y_j$$</span>
</span><span id="__span-0-2300"><a id="__codelineno-0-2300" name="__codelineno-0-2300"></a>
</span><span id="__span-0-2301"><a id="__codelineno-0-2301" name="__codelineno-0-2301"></a><span class="sd">    Args:</span>
</span><span id="__span-0-2302"><a id="__codelineno-0-2302" name="__codelineno-0-2302"></a><span class="sd">        ode_func: Function $f(t, y)$.</span>
</span><span id="__span-0-2303"><a id="__codelineno-0-2303" name="__codelineno-0-2303"></a><span class="sd">        y0_tuple: Initial state.</span>
</span><span id="__span-0-2304"><a id="__codelineno-0-2304" name="__codelineno-0-2304"></a><span class="sd">        alpha: Fractional order.</span>
</span><span id="__span-0-2305"><a id="__codelineno-0-2305" name="__codelineno-0-2305"></a><span class="sd">        t_grid: Time grid.</span>
</span><span id="__span-0-2306"><a id="__codelineno-0-2306" name="__codelineno-0-2306"></a><span class="sd">        memory: Memory limit.</span>
</span><span id="__span-0-2307"><a id="__codelineno-0-2307" name="__codelineno-0-2307"></a>
</span><span id="__span-0-2308"><a id="__codelineno-0-2308" name="__codelineno-0-2308"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-2309"><a id="__codelineno-0-2309" name="__codelineno-0-2309"></a><span class="sd">        State trajectory.</span>
</span><span id="__span-0-2310"><a id="__codelineno-0-2310" name="__codelineno-0-2310"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-2311"><a id="__codelineno-0-2311" name="__codelineno-0-2311"></a>    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
</span><span id="__span-0-2312"><a id="__codelineno-0-2312" name="__codelineno-0-2312"></a>    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_grid</span><span class="p">)</span>
</span><span id="__span-0-2313"><a id="__codelineno-0-2313" name="__codelineno-0-2313"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">y0_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
</span><span id="__span-0-2314"><a id="__codelineno-0-2314" name="__codelineno-0-2314"></a>    <span class="n">dtype</span> <span class="o">=</span> <span class="n">y0_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-2315"><a id="__codelineno-0-2315" name="__codelineno-0-2315"></a>    <span class="n">t_grid</span> <span class="o">=</span> <span class="n">t_grid</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-2316"><a id="__codelineno-0-2316" name="__codelineno-0-2316"></a>    <span class="n">h</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># uniform step size</span>
</span><span id="__span-0-2317"><a id="__codelineno-0-2317" name="__codelineno-0-2317"></a>    <span class="n">h_alpha_gamma</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="mi">2</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span>
</span><span id="__span-0-2318"><a id="__codelineno-0-2318" name="__codelineno-0-2318"></a>    <span class="n">one_minus_alpha</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span>
</span><span id="__span-0-2319"><a id="__codelineno-0-2319" name="__codelineno-0-2319"></a>
</span><span id="__span-0-2320"><a id="__codelineno-0-2320" name="__codelineno-0-2320"></a>    <span class="c1"># Initialize history lists for each component</span>
</span><span id="__span-0-2321"><a id="__codelineno-0-2321" name="__codelineno-0-2321"></a>    <span class="n">y_history</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">y0_tuple</span><span class="p">]</span>
</span><span id="__span-0-2322"><a id="__codelineno-0-2322" name="__codelineno-0-2322"></a>    <span class="c1"># Current state</span>
</span><span id="__span-0-2323"><a id="__codelineno-0-2323" name="__codelineno-0-2323"></a>    <span class="n">y_current</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">)</span>
</span><span id="__span-0-2324"><a id="__codelineno-0-2324" name="__codelineno-0-2324"></a>
</span><span id="__span-0-2325"><a id="__codelineno-0-2325" name="__codelineno-0-2325"></a>    <span class="c1"># Main loop: compute y_{k+1} for k = 0, 1, ..., N-2</span>
</span><span id="__span-0-2326"><a id="__codelineno-0-2326" name="__codelineno-0-2326"></a>    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-2327"><a id="__codelineno-0-2327" name="__codelineno-0-2327"></a>        <span class="n">t_k</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
</span><span id="__span-0-2328"><a id="__codelineno-0-2328" name="__codelineno-0-2328"></a>        <span class="c1"># Evaluate f(t_k, y_k)</span>
</span><span id="__span-0-2329"><a id="__codelineno-0-2329" name="__codelineno-0-2329"></a>        <span class="n">f_k</span> <span class="o">=</span> <span class="n">ode_func</span><span class="p">(</span><span class="n">t_k</span><span class="p">,</span> <span class="n">y_current</span><span class="p">)</span>
</span><span id="__span-0-2330"><a id="__codelineno-0-2330" name="__codelineno-0-2330"></a>
</span><span id="__span-0-2331"><a id="__codelineno-0-2331" name="__codelineno-0-2331"></a>        <span class="c1"># Determine memory range</span>
</span><span id="__span-0-2332"><a id="__codelineno-0-2332" name="__codelineno-0-2332"></a>        <span class="k">if</span> <span class="n">memory</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-2333"><a id="__codelineno-0-2333" name="__codelineno-0-2333"></a>            <span class="n">memory_length</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Use all available history</span>
</span><span id="__span-0-2334"><a id="__codelineno-0-2334" name="__codelineno-0-2334"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-2335"><a id="__codelineno-0-2335" name="__codelineno-0-2335"></a>            <span class="n">memory_length</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-2336"><a id="__codelineno-0-2336" name="__codelineno-0-2336"></a>            <span class="k">assert</span> <span class="n">memory_length</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;memory must be greater than 0&quot;</span>
</span><span id="__span-0-2337"><a id="__codelineno-0-2337" name="__codelineno-0-2337"></a>
</span><span id="__span-0-2338"><a id="__codelineno-0-2338" name="__codelineno-0-2338"></a>        <span class="n">start_idx</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">memory_length</span><span class="p">)</span>
</span><span id="__span-0-2339"><a id="__codelineno-0-2339" name="__codelineno-0-2339"></a>
</span><span id="__span-0-2340"><a id="__codelineno-0-2340" name="__codelineno-0-2340"></a>        <span class="c1"># Compute c_j^(k) weights for indices from start_idx to k</span>
</span><span id="__span-0-2341"><a id="__codelineno-0-2341" name="__codelineno-0-2341"></a>        <span class="c1"># General formula for j &gt;= 1: c_j^(k) = (k-j+2)^{1-α} - 2(k-j+1)^{1-α} + (k-j)^{1-α}</span>
</span><span id="__span-0-2342"><a id="__codelineno-0-2342" name="__codelineno-0-2342"></a>        <span class="c1"># Special case for j = 0: c_0^(k) = -[(k+1)^{1-α} - k^{1-α}]</span>
</span><span id="__span-0-2343"><a id="__codelineno-0-2343" name="__codelineno-0-2343"></a>        <span class="n">j_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-2344"><a id="__codelineno-0-2344" name="__codelineno-0-2344"></a>        <span class="n">kjp2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">j_vals</span><span class="p">,</span> <span class="n">one_minus_alpha</span><span class="p">)</span>
</span><span id="__span-0-2345"><a id="__codelineno-0-2345" name="__codelineno-0-2345"></a>        <span class="n">kjp1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">j_vals</span><span class="p">,</span> <span class="n">one_minus_alpha</span><span class="p">)</span>
</span><span id="__span-0-2346"><a id="__codelineno-0-2346" name="__codelineno-0-2346"></a>        <span class="n">kj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">k</span> <span class="o">-</span> <span class="n">j_vals</span><span class="p">,</span> <span class="n">one_minus_alpha</span><span class="p">)</span>
</span><span id="__span-0-2347"><a id="__codelineno-0-2347" name="__codelineno-0-2347"></a>        <span class="n">c_j_k</span> <span class="o">=</span> <span class="n">kjp2</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">kjp1</span> <span class="o">+</span> <span class="n">kj</span>
</span><span id="__span-0-2348"><a id="__codelineno-0-2348" name="__codelineno-0-2348"></a>
</span><span id="__span-0-2349"><a id="__codelineno-0-2349" name="__codelineno-0-2349"></a>        <span class="c1"># Special handling for j=0 if it&#39;s in the range</span>
</span><span id="__span-0-2350"><a id="__codelineno-0-2350" name="__codelineno-0-2350"></a>        <span class="k">if</span> <span class="n">start_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="__span-0-2351"><a id="__codelineno-0-2351" name="__codelineno-0-2351"></a>            <span class="n">kp1_power</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span>
</span><span id="__span-0-2352"><a id="__codelineno-0-2352" name="__codelineno-0-2352"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">one_minus_alpha</span>
</span><span id="__span-0-2353"><a id="__codelineno-0-2353" name="__codelineno-0-2353"></a>            <span class="p">)</span>
</span><span id="__span-0-2354"><a id="__codelineno-0-2354" name="__codelineno-0-2354"></a>            <span class="n">k_power</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span>
</span><span id="__span-0-2355"><a id="__codelineno-0-2355" name="__codelineno-0-2355"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">one_minus_alpha</span>
</span><span id="__span-0-2356"><a id="__codelineno-0-2356" name="__codelineno-0-2356"></a>            <span class="p">)</span>
</span><span id="__span-0-2357"><a id="__codelineno-0-2357" name="__codelineno-0-2357"></a>            <span class="n">c_j_k</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">kp1_power</span> <span class="o">-</span> <span class="n">k_power</span><span class="p">)</span>
</span><span id="__span-0-2358"><a id="__codelineno-0-2358" name="__codelineno-0-2358"></a>
</span><span id="__span-0-2359"><a id="__codelineno-0-2359" name="__codelineno-0-2359"></a>        <span class="c1"># Update ALL state components (forward integrates all, not len-1)</span>
</span><span id="__span-0-2360"><a id="__codelineno-0-2360" name="__codelineno-0-2360"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_current</span><span class="p">)):</span>
</span><span id="__span-0-2361"><a id="__codelineno-0-2361" name="__codelineno-0-2361"></a>            <span class="c1"># Compute convolution sum: sum_{j=start_idx}^{k-1} c_j^(k) * y_j[i]</span>
</span><span id="__span-0-2362"><a id="__codelineno-0-2362" name="__codelineno-0-2362"></a>            <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="__span-0-2363"><a id="__codelineno-0-2363" name="__codelineno-0-2363"></a>                <span class="n">convolution_sum</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-0-2364"><a id="__codelineno-0-2364" name="__codelineno-0-2364"></a>                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
</span><span id="__span-0-2365"><a id="__codelineno-0-2365" name="__codelineno-0-2365"></a>                    <span class="c1"># local_idx = j - start_idx</span>
</span><span id="__span-0-2366"><a id="__codelineno-0-2366" name="__codelineno-0-2366"></a>                    <span class="n">local_idx</span> <span class="o">=</span> <span class="n">j</span> <span class="o">-</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="__span-0-2367"><a id="__codelineno-0-2367" name="__codelineno-0-2367"></a>                    <span class="c1"># the most restrict formulation should be local_idx = j - start_idx + 1</span>
</span><span id="__span-0-2368"><a id="__codelineno-0-2368" name="__codelineno-0-2368"></a>                    <span class="n">convolution_sum</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-2369"><a id="__codelineno-0-2369" name="__codelineno-0-2369"></a>                        <span class="n">convolution_sum</span> <span class="o">+</span> <span class="n">c_j_k</span><span class="p">[</span><span class="n">local_idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">y_history</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
</span><span id="__span-0-2370"><a id="__codelineno-0-2370" name="__codelineno-0-2370"></a>                    <span class="p">)</span>
</span><span id="__span-0-2371"><a id="__codelineno-0-2371" name="__codelineno-0-2371"></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-2372"><a id="__codelineno-0-2372" name="__codelineno-0-2372"></a>                <span class="n">convolution_sum</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-0-2373"><a id="__codelineno-0-2373" name="__codelineno-0-2373"></a>
</span><span id="__span-0-2374"><a id="__codelineno-0-2374" name="__codelineno-0-2374"></a>            <span class="c1"># y_{k+1} = h^α * Γ(2-α) * f_k - convolution_sum</span>
</span><span id="__span-0-2375"><a id="__codelineno-0-2375" name="__codelineno-0-2375"></a>            <span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">h_alpha_gamma</span> <span class="o">*</span> <span class="n">f_k</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">convolution_sum</span>
</span><span id="__span-0-2376"><a id="__codelineno-0-2376" name="__codelineno-0-2376"></a>            <span class="n">y_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="__span-0-2377"><a id="__codelineno-0-2377" name="__codelineno-0-2377"></a>
</span><span id="__span-0-2378"><a id="__codelineno-0-2378" name="__codelineno-0-2378"></a>    <span class="k">return</span> <span class="n">y_history</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.backward_l1" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">backward_l1</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">backward_l1</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y_aug</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">yhistory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]],</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Backward L1 scheme for adjoint sensitivity.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></code>)
          –
          <div class="doc-md-description">
            <p>Augmented dynamics.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y_aug</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>, <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>, <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>]</code>)
          –
          <div class="doc-md-description">
            <p>Initial augmented state.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>alpha</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a> | <a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Fractional order.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Flipped time grid.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>yhistory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>)
          –
          <div class="doc-md-description">
            <p>Forward trajectory.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Memory limit.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>], <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>
          –
          <div class="doc-md-description">
            <p>Final adjoint states and parameter gradients.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-2381">2381</a></span>
<span class="normal"><a href="#__codelineno-0-2382">2382</a></span>
<span class="normal"><a href="#__codelineno-0-2383">2383</a></span>
<span class="normal"><a href="#__codelineno-0-2384">2384</a></span>
<span class="normal"><a href="#__codelineno-0-2385">2385</a></span>
<span class="normal"><a href="#__codelineno-0-2386">2386</a></span>
<span class="normal"><a href="#__codelineno-0-2387">2387</a></span>
<span class="normal"><a href="#__codelineno-0-2388">2388</a></span>
<span class="normal"><a href="#__codelineno-0-2389">2389</a></span>
<span class="normal"><a href="#__codelineno-0-2390">2390</a></span>
<span class="normal"><a href="#__codelineno-0-2391">2391</a></span>
<span class="normal"><a href="#__codelineno-0-2392">2392</a></span>
<span class="normal"><a href="#__codelineno-0-2393">2393</a></span>
<span class="normal"><a href="#__codelineno-0-2394">2394</a></span>
<span class="normal"><a href="#__codelineno-0-2395">2395</a></span>
<span class="normal"><a href="#__codelineno-0-2396">2396</a></span>
<span class="normal"><a href="#__codelineno-0-2397">2397</a></span>
<span class="normal"><a href="#__codelineno-0-2398">2398</a></span>
<span class="normal"><a href="#__codelineno-0-2399">2399</a></span>
<span class="normal"><a href="#__codelineno-0-2400">2400</a></span>
<span class="normal"><a href="#__codelineno-0-2401">2401</a></span>
<span class="normal"><a href="#__codelineno-0-2402">2402</a></span>
<span class="normal"><a href="#__codelineno-0-2403">2403</a></span>
<span class="normal"><a href="#__codelineno-0-2404">2404</a></span>
<span class="normal"><a href="#__codelineno-0-2405">2405</a></span>
<span class="normal"><a href="#__codelineno-0-2406">2406</a></span>
<span class="normal"><a href="#__codelineno-0-2407">2407</a></span>
<span class="normal"><a href="#__codelineno-0-2408">2408</a></span>
<span class="normal"><a href="#__codelineno-0-2409">2409</a></span>
<span class="normal"><a href="#__codelineno-0-2410">2410</a></span>
<span class="normal"><a href="#__codelineno-0-2411">2411</a></span>
<span class="normal"><a href="#__codelineno-0-2412">2412</a></span>
<span class="normal"><a href="#__codelineno-0-2413">2413</a></span>
<span class="normal"><a href="#__codelineno-0-2414">2414</a></span>
<span class="normal"><a href="#__codelineno-0-2415">2415</a></span>
<span class="normal"><a href="#__codelineno-0-2416">2416</a></span>
<span class="normal"><a href="#__codelineno-0-2417">2417</a></span>
<span class="normal"><a href="#__codelineno-0-2418">2418</a></span>
<span class="normal"><a href="#__codelineno-0-2419">2419</a></span>
<span class="normal"><a href="#__codelineno-0-2420">2420</a></span>
<span class="normal"><a href="#__codelineno-0-2421">2421</a></span>
<span class="normal"><a href="#__codelineno-0-2422">2422</a></span>
<span class="normal"><a href="#__codelineno-0-2423">2423</a></span>
<span class="normal"><a href="#__codelineno-0-2424">2424</a></span>
<span class="normal"><a href="#__codelineno-0-2425">2425</a></span>
<span class="normal"><a href="#__codelineno-0-2426">2426</a></span>
<span class="normal"><a href="#__codelineno-0-2427">2427</a></span>
<span class="normal"><a href="#__codelineno-0-2428">2428</a></span>
<span class="normal"><a href="#__codelineno-0-2429">2429</a></span>
<span class="normal"><a href="#__codelineno-0-2430">2430</a></span>
<span class="normal"><a href="#__codelineno-0-2431">2431</a></span>
<span class="normal"><a href="#__codelineno-0-2432">2432</a></span>
<span class="normal"><a href="#__codelineno-0-2433">2433</a></span>
<span class="normal"><a href="#__codelineno-0-2434">2434</a></span>
<span class="normal"><a href="#__codelineno-0-2435">2435</a></span>
<span class="normal"><a href="#__codelineno-0-2436">2436</a></span>
<span class="normal"><a href="#__codelineno-0-2437">2437</a></span>
<span class="normal"><a href="#__codelineno-0-2438">2438</a></span>
<span class="normal"><a href="#__codelineno-0-2439">2439</a></span>
<span class="normal"><a href="#__codelineno-0-2440">2440</a></span>
<span class="normal"><a href="#__codelineno-0-2441">2441</a></span>
<span class="normal"><a href="#__codelineno-0-2442">2442</a></span>
<span class="normal"><a href="#__codelineno-0-2443">2443</a></span>
<span class="normal"><a href="#__codelineno-0-2444">2444</a></span>
<span class="normal"><a href="#__codelineno-0-2445">2445</a></span>
<span class="normal"><a href="#__codelineno-0-2446">2446</a></span>
<span class="normal"><a href="#__codelineno-0-2447">2447</a></span>
<span class="normal"><a href="#__codelineno-0-2448">2448</a></span>
<span class="normal"><a href="#__codelineno-0-2449">2449</a></span>
<span class="normal"><a href="#__codelineno-0-2450">2450</a></span>
<span class="normal"><a href="#__codelineno-0-2451">2451</a></span>
<span class="normal"><a href="#__codelineno-0-2452">2452</a></span>
<span class="normal"><a href="#__codelineno-0-2453">2453</a></span>
<span class="normal"><a href="#__codelineno-0-2454">2454</a></span>
<span class="normal"><a href="#__codelineno-0-2455">2455</a></span>
<span class="normal"><a href="#__codelineno-0-2456">2456</a></span>
<span class="normal"><a href="#__codelineno-0-2457">2457</a></span>
<span class="normal"><a href="#__codelineno-0-2458">2458</a></span>
<span class="normal"><a href="#__codelineno-0-2459">2459</a></span>
<span class="normal"><a href="#__codelineno-0-2460">2460</a></span>
<span class="normal"><a href="#__codelineno-0-2461">2461</a></span>
<span class="normal"><a href="#__codelineno-0-2462">2462</a></span>
<span class="normal"><a href="#__codelineno-0-2463">2463</a></span>
<span class="normal"><a href="#__codelineno-0-2464">2464</a></span>
<span class="normal"><a href="#__codelineno-0-2465">2465</a></span>
<span class="normal"><a href="#__codelineno-0-2466">2466</a></span>
<span class="normal"><a href="#__codelineno-0-2467">2467</a></span>
<span class="normal"><a href="#__codelineno-0-2468">2468</a></span>
<span class="normal"><a href="#__codelineno-0-2469">2469</a></span>
<span class="normal"><a href="#__codelineno-0-2470">2470</a></span>
<span class="normal"><a href="#__codelineno-0-2471">2471</a></span>
<span class="normal"><a href="#__codelineno-0-2472">2472</a></span>
<span class="normal"><a href="#__codelineno-0-2473">2473</a></span>
<span class="normal"><a href="#__codelineno-0-2474">2474</a></span>
<span class="normal"><a href="#__codelineno-0-2475">2475</a></span>
<span class="normal"><a href="#__codelineno-0-2476">2476</a></span>
<span class="normal"><a href="#__codelineno-0-2477">2477</a></span>
<span class="normal"><a href="#__codelineno-0-2478">2478</a></span>
<span class="normal"><a href="#__codelineno-0-2479">2479</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-2381"><a id="__codelineno-0-2381" name="__codelineno-0-2381"></a><span class="k">def</span><span class="w"> </span><span class="nf">backward_l1</span><span class="p">(</span>
</span><span id="__span-0-2382"><a id="__codelineno-0-2382" name="__codelineno-0-2382"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
</span><span id="__span-0-2383"><a id="__codelineno-0-2383" name="__codelineno-0-2383"></a>    <span class="n">y_aug</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">],</span>
</span><span id="__span-0-2384"><a id="__codelineno-0-2384" name="__codelineno-0-2384"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="__span-0-2385"><a id="__codelineno-0-2385" name="__codelineno-0-2385"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-2386"><a id="__codelineno-0-2386" name="__codelineno-0-2386"></a>    <span class="n">yhistory</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
</span><span id="__span-0-2387"><a id="__codelineno-0-2387" name="__codelineno-0-2387"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-2388"><a id="__codelineno-0-2388" name="__codelineno-0-2388"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="__span-0-2389"><a id="__codelineno-0-2389" name="__codelineno-0-2389"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-2390"><a id="__codelineno-0-2390" name="__codelineno-0-2390"></a><span class="sd">    Backward L1 scheme for adjoint sensitivity.</span>
</span><span id="__span-0-2391"><a id="__codelineno-0-2391" name="__codelineno-0-2391"></a>
</span><span id="__span-0-2392"><a id="__codelineno-0-2392" name="__codelineno-0-2392"></a><span class="sd">    Args:</span>
</span><span id="__span-0-2393"><a id="__codelineno-0-2393" name="__codelineno-0-2393"></a><span class="sd">        ode_func: Augmented dynamics.</span>
</span><span id="__span-0-2394"><a id="__codelineno-0-2394" name="__codelineno-0-2394"></a><span class="sd">        y_aug: Initial augmented state.</span>
</span><span id="__span-0-2395"><a id="__codelineno-0-2395" name="__codelineno-0-2395"></a><span class="sd">        alpha: Fractional order.</span>
</span><span id="__span-0-2396"><a id="__codelineno-0-2396" name="__codelineno-0-2396"></a><span class="sd">        t_grid: Flipped time grid.</span>
</span><span id="__span-0-2397"><a id="__codelineno-0-2397" name="__codelineno-0-2397"></a><span class="sd">        yhistory: Forward trajectory.</span>
</span><span id="__span-0-2398"><a id="__codelineno-0-2398" name="__codelineno-0-2398"></a><span class="sd">        memory: Memory limit.</span>
</span><span id="__span-0-2399"><a id="__codelineno-0-2399" name="__codelineno-0-2399"></a>
</span><span id="__span-0-2400"><a id="__codelineno-0-2400" name="__codelineno-0-2400"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-2401"><a id="__codelineno-0-2401" name="__codelineno-0-2401"></a><span class="sd">        Final adjoint states and parameter gradients.</span>
</span><span id="__span-0-2402"><a id="__codelineno-0-2402" name="__codelineno-0-2402"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-2403"><a id="__codelineno-0-2403" name="__codelineno-0-2403"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="__span-0-2404"><a id="__codelineno-0-2404" name="__codelineno-0-2404"></a>        <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_grid</span><span class="p">)</span>
</span><span id="__span-0-2405"><a id="__codelineno-0-2405" name="__codelineno-0-2405"></a>        <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
</span><span id="__span-0-2406"><a id="__codelineno-0-2406" name="__codelineno-0-2406"></a>        <span class="n">h_alpha_gamma</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="mi">2</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span>
</span><span id="__span-0-2407"><a id="__codelineno-0-2407" name="__codelineno-0-2407"></a>        <span class="n">one_minus_alpha</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span>
</span><span id="__span-0-2408"><a id="__codelineno-0-2408" name="__codelineno-0-2408"></a>
</span><span id="__span-0-2409"><a id="__codelineno-0-2409" name="__codelineno-0-2409"></a>        <span class="n">_</span><span class="p">,</span> <span class="n">adj_y0</span><span class="p">,</span> <span class="n">adj_params0</span> <span class="o">=</span> <span class="n">y_aug</span>
</span><span id="__span-0-2410"><a id="__codelineno-0-2410" name="__codelineno-0-2410"></a>        <span class="n">device</span> <span class="o">=</span> <span class="n">adj_y0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
</span><span id="__span-0-2411"><a id="__codelineno-0-2411" name="__codelineno-0-2411"></a>        <span class="n">dtype</span> <span class="o">=</span> <span class="n">adj_y0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-2412"><a id="__codelineno-0-2412" name="__codelineno-0-2412"></a>
</span><span id="__span-0-2413"><a id="__codelineno-0-2413" name="__codelineno-0-2413"></a>        <span class="c1"># Initialize adjoint history lists for each component (with initial values)</span>
</span><span id="__span-0-2414"><a id="__codelineno-0-2414" name="__codelineno-0-2414"></a>        <span class="n">adjy_history</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-0-2415"><a id="__codelineno-0-2415" name="__codelineno-0-2415"></a>            <span class="p">[</span>
</span><span id="__span-0-2416"><a id="__codelineno-0-2416" name="__codelineno-0-2416"></a>                <span class="n">xx</span><span class="p">,</span>
</span><span id="__span-0-2417"><a id="__codelineno-0-2417" name="__codelineno-0-2417"></a>            <span class="p">]</span>
</span><span id="__span-0-2418"><a id="__codelineno-0-2418" name="__codelineno-0-2418"></a>            <span class="k">for</span> <span class="n">xx</span> <span class="ow">in</span> <span class="n">adj_y0</span>
</span><span id="__span-0-2419"><a id="__codelineno-0-2419" name="__codelineno-0-2419"></a>        <span class="p">]</span>
</span><span id="__span-0-2420"><a id="__codelineno-0-2420" name="__codelineno-0-2420"></a>
</span><span id="__span-0-2421"><a id="__codelineno-0-2421" name="__codelineno-0-2421"></a>        <span class="c1"># Clone initial adjoint values</span>
</span><span id="__span-0-2422"><a id="__codelineno-0-2422" name="__codelineno-0-2422"></a>        <span class="n">adj_y</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">adj_y0</span><span class="p">)</span>
</span><span id="__span-0-2423"><a id="__codelineno-0-2423" name="__codelineno-0-2423"></a>        <span class="n">adj_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">adj_params0</span><span class="p">)</span>
</span><span id="__span-0-2424"><a id="__codelineno-0-2424" name="__codelineno-0-2424"></a>
</span><span id="__span-0-2425"><a id="__codelineno-0-2425" name="__codelineno-0-2425"></a>        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">2</span><span class="p">):</span>
</span><span id="__span-0-2426"><a id="__codelineno-0-2426" name="__codelineno-0-2426"></a>            <span class="n">tk</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
</span><span id="__span-0-2427"><a id="__codelineno-0-2427" name="__codelineno-0-2427"></a>            <span class="n">y_state</span> <span class="o">=</span> <span class="nb">list</span><span class="p">([</span><span class="n">y</span><span class="p">[</span><span class="o">-</span><span class="n">k</span> <span class="o">-</span> <span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">yhistory</span><span class="p">])</span>
</span><span id="__span-0-2428"><a id="__codelineno-0-2428" name="__codelineno-0-2428"></a>
</span><span id="__span-0-2429"><a id="__codelineno-0-2429" name="__codelineno-0-2429"></a>            <span class="n">func_eval</span><span class="p">,</span> <span class="n">vjp_y</span><span class="p">,</span> <span class="n">vjp_params</span> <span class="o">=</span> <span class="n">ode_func</span><span class="p">(</span><span class="n">tk</span><span class="p">,</span> <span class="p">(</span><span class="n">y_state</span><span class="p">,</span> <span class="n">adj_y</span><span class="p">,</span> <span class="n">adj_params</span><span class="p">))</span>
</span><span id="__span-0-2430"><a id="__codelineno-0-2430" name="__codelineno-0-2430"></a>
</span><span id="__span-0-2431"><a id="__codelineno-0-2431" name="__codelineno-0-2431"></a>            <span class="c1"># Determine memory range</span>
</span><span id="__span-0-2432"><a id="__codelineno-0-2432" name="__codelineno-0-2432"></a>            <span class="k">if</span> <span class="n">memory</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-2433"><a id="__codelineno-0-2433" name="__codelineno-0-2433"></a>                <span class="n">memory_length</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="__span-0-2434"><a id="__codelineno-0-2434" name="__codelineno-0-2434"></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-2435"><a id="__codelineno-0-2435" name="__codelineno-0-2435"></a>                <span class="n">memory_length</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-2436"><a id="__codelineno-0-2436" name="__codelineno-0-2436"></a>
</span><span id="__span-0-2437"><a id="__codelineno-0-2437" name="__codelineno-0-2437"></a>            <span class="n">start_idx</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">memory_length</span><span class="p">)</span>
</span><span id="__span-0-2438"><a id="__codelineno-0-2438" name="__codelineno-0-2438"></a>
</span><span id="__span-0-2439"><a id="__codelineno-0-2439" name="__codelineno-0-2439"></a>            <span class="c1"># Compute c_j^(k) weights for indices from start_idx to k</span>
</span><span id="__span-0-2440"><a id="__codelineno-0-2440" name="__codelineno-0-2440"></a>            <span class="c1"># General formula for j &gt;= 1: c_j^(k) = (k-j+2)^{1-α} - 2(k-j+1)^{1-α} + (k-j)^{1-α}</span>
</span><span id="__span-0-2441"><a id="__codelineno-0-2441" name="__codelineno-0-2441"></a>            <span class="c1"># Special case for j = 0: c_0^(k) = -[(k+1)^{1-α} - k^{1-α}]</span>
</span><span id="__span-0-2442"><a id="__codelineno-0-2442" name="__codelineno-0-2442"></a>            <span class="n">j_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-2443"><a id="__codelineno-0-2443" name="__codelineno-0-2443"></a>            <span class="n">kjp2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">j_vals</span><span class="p">,</span> <span class="n">one_minus_alpha</span><span class="p">)</span>
</span><span id="__span-0-2444"><a id="__codelineno-0-2444" name="__codelineno-0-2444"></a>            <span class="n">kjp1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">j_vals</span><span class="p">,</span> <span class="n">one_minus_alpha</span><span class="p">)</span>
</span><span id="__span-0-2445"><a id="__codelineno-0-2445" name="__codelineno-0-2445"></a>            <span class="n">kj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">k</span> <span class="o">-</span> <span class="n">j_vals</span><span class="p">,</span> <span class="n">one_minus_alpha</span><span class="p">)</span>
</span><span id="__span-0-2446"><a id="__codelineno-0-2446" name="__codelineno-0-2446"></a>            <span class="n">c_j_k</span> <span class="o">=</span> <span class="n">kjp2</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">kjp1</span> <span class="o">+</span> <span class="n">kj</span>
</span><span id="__span-0-2447"><a id="__codelineno-0-2447" name="__codelineno-0-2447"></a>
</span><span id="__span-0-2448"><a id="__codelineno-0-2448" name="__codelineno-0-2448"></a>            <span class="c1"># Special handling for j=0 if it&#39;s in the range</span>
</span><span id="__span-0-2449"><a id="__codelineno-0-2449" name="__codelineno-0-2449"></a>            <span class="k">if</span> <span class="n">start_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="__span-0-2450"><a id="__codelineno-0-2450" name="__codelineno-0-2450"></a>                <span class="n">kp1_power</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span>
</span><span id="__span-0-2451"><a id="__codelineno-0-2451" name="__codelineno-0-2451"></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">one_minus_alpha</span>
</span><span id="__span-0-2452"><a id="__codelineno-0-2452" name="__codelineno-0-2452"></a>                <span class="p">)</span>
</span><span id="__span-0-2453"><a id="__codelineno-0-2453" name="__codelineno-0-2453"></a>                <span class="n">k_power</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span>
</span><span id="__span-0-2454"><a id="__codelineno-0-2454" name="__codelineno-0-2454"></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">one_minus_alpha</span>
</span><span id="__span-0-2455"><a id="__codelineno-0-2455" name="__codelineno-0-2455"></a>                <span class="p">)</span>
</span><span id="__span-0-2456"><a id="__codelineno-0-2456" name="__codelineno-0-2456"></a>                <span class="n">c_j_k</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">kp1_power</span> <span class="o">-</span> <span class="n">k_power</span><span class="p">)</span>
</span><span id="__span-0-2457"><a id="__codelineno-0-2457" name="__codelineno-0-2457"></a>
</span><span id="__span-0-2458"><a id="__codelineno-0-2458" name="__codelineno-0-2458"></a>            <span class="c1"># Update all adjoint components</span>
</span><span id="__span-0-2459"><a id="__codelineno-0-2459" name="__codelineno-0-2459"></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">adj_y</span><span class="p">)):</span>
</span><span id="__span-0-2460"><a id="__codelineno-0-2460" name="__codelineno-0-2460"></a>                <span class="c1"># Calculate history sum - note: range goes to k+1 (one more than forward)</span>
</span><span id="__span-0-2461"><a id="__codelineno-0-2461" name="__codelineno-0-2461"></a>                <span class="n">convolution_sum</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-0-2462"><a id="__codelineno-0-2462" name="__codelineno-0-2462"></a>                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-2463"><a id="__codelineno-0-2463" name="__codelineno-0-2463"></a>                    <span class="n">local_idx</span> <span class="o">=</span> <span class="n">j</span> <span class="o">-</span> <span class="n">start_idx</span>
</span><span id="__span-0-2464"><a id="__codelineno-0-2464" name="__codelineno-0-2464"></a>                    <span class="n">convolution_sum</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-2465"><a id="__codelineno-0-2465" name="__codelineno-0-2465"></a>                        <span class="n">convolution_sum</span> <span class="o">+</span> <span class="n">c_j_k</span><span class="p">[</span><span class="n">local_idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">adjy_history</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
</span><span id="__span-0-2466"><a id="__codelineno-0-2466" name="__codelineno-0-2466"></a>                    <span class="p">)</span>
</span><span id="__span-0-2467"><a id="__codelineno-0-2467" name="__codelineno-0-2467"></a>
</span><span id="__span-0-2468"><a id="__codelineno-0-2468" name="__codelineno-0-2468"></a>                <span class="c1"># Update adjoint state</span>
</span><span id="__span-0-2469"><a id="__codelineno-0-2469" name="__codelineno-0-2469"></a>                <span class="n">adj_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">h_alpha_gamma</span> <span class="o">*</span> <span class="n">vjp_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">convolution_sum</span>
</span><span id="__span-0-2470"><a id="__codelineno-0-2470" name="__codelineno-0-2470"></a>                <span class="n">adjy_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">adj_y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="__span-0-2471"><a id="__codelineno-0-2471" name="__codelineno-0-2471"></a>
</span><span id="__span-0-2472"><a id="__codelineno-0-2472" name="__codelineno-0-2472"></a>            <span class="c1"># Update parameter gradients</span>
</span><span id="__span-0-2473"><a id="__codelineno-0-2473" name="__codelineno-0-2473"></a>            <span class="k">if</span> <span class="n">adj_params</span> <span class="ow">and</span> <span class="n">vjp_params</span><span class="p">:</span>
</span><span id="__span-0-2474"><a id="__codelineno-0-2474" name="__codelineno-0-2474"></a>                <span class="k">for</span> <span class="n">ap</span><span class="p">,</span> <span class="n">vp</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">adj_params</span><span class="p">,</span> <span class="n">vjp_params</span><span class="p">):</span>
</span><span id="__span-0-2475"><a id="__codelineno-0-2475" name="__codelineno-0-2475"></a>                    <span class="n">ap</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">vp</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">h</span><span class="p">)</span>
</span><span id="__span-0-2476"><a id="__codelineno-0-2476" name="__codelineno-0-2476"></a>
</span><span id="__span-0-2477"><a id="__codelineno-0-2477" name="__codelineno-0-2477"></a>    <span class="k">del</span> <span class="n">adjy_history</span><span class="p">,</span> <span class="n">yhistory</span>
</span><span id="__span-0-2478"><a id="__codelineno-0-2478" name="__codelineno-0-2478"></a>
</span><span id="__span-0-2479"><a id="__codelineno-0-2479" name="__codelineno-0-2479"></a>    <span class="k">return</span> <span class="n">adj_y</span><span class="p">,</span> <span class="n">adj_params</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.forward_pred" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">forward_pred</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">forward_pred</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Forward Adams-Bashforth predictor method.</p>
<p>Uses history of function evaluations <span class="arithmatex">\(f(t, y)\)</span> instead of states <span class="arithmatex">\(y\)</span>.
Formula:</p>
<div class="arithmatex">\[y_{k+1} = \sum_{j=0}^{k} b_{j,k+1} f(t_j, y_j)\]</div>
<p>where <span class="arithmatex">\(b_{j,k+1} = \frac{h^\alpha}{\alpha \Gamma(\alpha)} [(k+1-j)^\alpha - (k-j)^\alpha]\)</span>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></code>)
          –
          <div class="doc-md-description">
            <p>Function <span class="arithmatex">\(f(t, y)\)</span>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y0_tuple</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]</code>)
          –
          <div class="doc-md-description">
            <p>Initial state.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>alpha</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a> | <a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Fractional order.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Time grid.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Memory limit.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>
          –
          <div class="doc-md-description">
            <p>State trajectory.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-2482">2482</a></span>
<span class="normal"><a href="#__codelineno-0-2483">2483</a></span>
<span class="normal"><a href="#__codelineno-0-2484">2484</a></span>
<span class="normal"><a href="#__codelineno-0-2485">2485</a></span>
<span class="normal"><a href="#__codelineno-0-2486">2486</a></span>
<span class="normal"><a href="#__codelineno-0-2487">2487</a></span>
<span class="normal"><a href="#__codelineno-0-2488">2488</a></span>
<span class="normal"><a href="#__codelineno-0-2489">2489</a></span>
<span class="normal"><a href="#__codelineno-0-2490">2490</a></span>
<span class="normal"><a href="#__codelineno-0-2491">2491</a></span>
<span class="normal"><a href="#__codelineno-0-2492">2492</a></span>
<span class="normal"><a href="#__codelineno-0-2493">2493</a></span>
<span class="normal"><a href="#__codelineno-0-2494">2494</a></span>
<span class="normal"><a href="#__codelineno-0-2495">2495</a></span>
<span class="normal"><a href="#__codelineno-0-2496">2496</a></span>
<span class="normal"><a href="#__codelineno-0-2497">2497</a></span>
<span class="normal"><a href="#__codelineno-0-2498">2498</a></span>
<span class="normal"><a href="#__codelineno-0-2499">2499</a></span>
<span class="normal"><a href="#__codelineno-0-2500">2500</a></span>
<span class="normal"><a href="#__codelineno-0-2501">2501</a></span>
<span class="normal"><a href="#__codelineno-0-2502">2502</a></span>
<span class="normal"><a href="#__codelineno-0-2503">2503</a></span>
<span class="normal"><a href="#__codelineno-0-2504">2504</a></span>
<span class="normal"><a href="#__codelineno-0-2505">2505</a></span>
<span class="normal"><a href="#__codelineno-0-2506">2506</a></span>
<span class="normal"><a href="#__codelineno-0-2507">2507</a></span>
<span class="normal"><a href="#__codelineno-0-2508">2508</a></span>
<span class="normal"><a href="#__codelineno-0-2509">2509</a></span>
<span class="normal"><a href="#__codelineno-0-2510">2510</a></span>
<span class="normal"><a href="#__codelineno-0-2511">2511</a></span>
<span class="normal"><a href="#__codelineno-0-2512">2512</a></span>
<span class="normal"><a href="#__codelineno-0-2513">2513</a></span>
<span class="normal"><a href="#__codelineno-0-2514">2514</a></span>
<span class="normal"><a href="#__codelineno-0-2515">2515</a></span>
<span class="normal"><a href="#__codelineno-0-2516">2516</a></span>
<span class="normal"><a href="#__codelineno-0-2517">2517</a></span>
<span class="normal"><a href="#__codelineno-0-2518">2518</a></span>
<span class="normal"><a href="#__codelineno-0-2519">2519</a></span>
<span class="normal"><a href="#__codelineno-0-2520">2520</a></span>
<span class="normal"><a href="#__codelineno-0-2521">2521</a></span>
<span class="normal"><a href="#__codelineno-0-2522">2522</a></span>
<span class="normal"><a href="#__codelineno-0-2523">2523</a></span>
<span class="normal"><a href="#__codelineno-0-2524">2524</a></span>
<span class="normal"><a href="#__codelineno-0-2525">2525</a></span>
<span class="normal"><a href="#__codelineno-0-2526">2526</a></span>
<span class="normal"><a href="#__codelineno-0-2527">2527</a></span>
<span class="normal"><a href="#__codelineno-0-2528">2528</a></span>
<span class="normal"><a href="#__codelineno-0-2529">2529</a></span>
<span class="normal"><a href="#__codelineno-0-2530">2530</a></span>
<span class="normal"><a href="#__codelineno-0-2531">2531</a></span>
<span class="normal"><a href="#__codelineno-0-2532">2532</a></span>
<span class="normal"><a href="#__codelineno-0-2533">2533</a></span>
<span class="normal"><a href="#__codelineno-0-2534">2534</a></span>
<span class="normal"><a href="#__codelineno-0-2535">2535</a></span>
<span class="normal"><a href="#__codelineno-0-2536">2536</a></span>
<span class="normal"><a href="#__codelineno-0-2537">2537</a></span>
<span class="normal"><a href="#__codelineno-0-2538">2538</a></span>
<span class="normal"><a href="#__codelineno-0-2539">2539</a></span>
<span class="normal"><a href="#__codelineno-0-2540">2540</a></span>
<span class="normal"><a href="#__codelineno-0-2541">2541</a></span>
<span class="normal"><a href="#__codelineno-0-2542">2542</a></span>
<span class="normal"><a href="#__codelineno-0-2543">2543</a></span>
<span class="normal"><a href="#__codelineno-0-2544">2544</a></span>
<span class="normal"><a href="#__codelineno-0-2545">2545</a></span>
<span class="normal"><a href="#__codelineno-0-2546">2546</a></span>
<span class="normal"><a href="#__codelineno-0-2547">2547</a></span>
<span class="normal"><a href="#__codelineno-0-2548">2548</a></span>
<span class="normal"><a href="#__codelineno-0-2549">2549</a></span>
<span class="normal"><a href="#__codelineno-0-2550">2550</a></span>
<span class="normal"><a href="#__codelineno-0-2551">2551</a></span>
<span class="normal"><a href="#__codelineno-0-2552">2552</a></span>
<span class="normal"><a href="#__codelineno-0-2553">2553</a></span>
<span class="normal"><a href="#__codelineno-0-2554">2554</a></span>
<span class="normal"><a href="#__codelineno-0-2555">2555</a></span>
<span class="normal"><a href="#__codelineno-0-2556">2556</a></span>
<span class="normal"><a href="#__codelineno-0-2557">2557</a></span>
<span class="normal"><a href="#__codelineno-0-2558">2558</a></span>
<span class="normal"><a href="#__codelineno-0-2559">2559</a></span>
<span class="normal"><a href="#__codelineno-0-2560">2560</a></span>
<span class="normal"><a href="#__codelineno-0-2561">2561</a></span>
<span class="normal"><a href="#__codelineno-0-2562">2562</a></span>
<span class="normal"><a href="#__codelineno-0-2563">2563</a></span>
<span class="normal"><a href="#__codelineno-0-2564">2564</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-2482"><a id="__codelineno-0-2482" name="__codelineno-0-2482"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward_pred</span><span class="p">(</span>
</span><span id="__span-0-2483"><a id="__codelineno-0-2483" name="__codelineno-0-2483"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
</span><span id="__span-0-2484"><a id="__codelineno-0-2484" name="__codelineno-0-2484"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-2485"><a id="__codelineno-0-2485" name="__codelineno-0-2485"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="__span-0-2486"><a id="__codelineno-0-2486" name="__codelineno-0-2486"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-2487"><a id="__codelineno-0-2487" name="__codelineno-0-2487"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-2488"><a id="__codelineno-0-2488" name="__codelineno-0-2488"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="__span-0-2489"><a id="__codelineno-0-2489" name="__codelineno-0-2489"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-2490"><a id="__codelineno-0-2490" name="__codelineno-0-2490"></a><span class="sd">    Forward Adams-Bashforth predictor method.</span>
</span><span id="__span-0-2491"><a id="__codelineno-0-2491" name="__codelineno-0-2491"></a>
</span><span id="__span-0-2492"><a id="__codelineno-0-2492" name="__codelineno-0-2492"></a><span class="sd">    Uses history of function evaluations $f(t, y)$ instead of states $y$.</span>
</span><span id="__span-0-2493"><a id="__codelineno-0-2493" name="__codelineno-0-2493"></a><span class="sd">    Formula:</span>
</span><span id="__span-0-2494"><a id="__codelineno-0-2494" name="__codelineno-0-2494"></a>
</span><span id="__span-0-2495"><a id="__codelineno-0-2495" name="__codelineno-0-2495"></a><span class="sd">    $$y_{k+1} = \sum_{j=0}^{k} b_{j,k+1} f(t_j, y_j)$$</span>
</span><span id="__span-0-2496"><a id="__codelineno-0-2496" name="__codelineno-0-2496"></a>
</span><span id="__span-0-2497"><a id="__codelineno-0-2497" name="__codelineno-0-2497"></a><span class="sd">    where $b_{j,k+1} = \frac{h^\alpha}{\alpha \Gamma(\alpha)} [(k+1-j)^\alpha - (k-j)^\alpha]$.</span>
</span><span id="__span-0-2498"><a id="__codelineno-0-2498" name="__codelineno-0-2498"></a>
</span><span id="__span-0-2499"><a id="__codelineno-0-2499" name="__codelineno-0-2499"></a><span class="sd">    Args:</span>
</span><span id="__span-0-2500"><a id="__codelineno-0-2500" name="__codelineno-0-2500"></a><span class="sd">        ode_func: Function $f(t, y)$.</span>
</span><span id="__span-0-2501"><a id="__codelineno-0-2501" name="__codelineno-0-2501"></a><span class="sd">        y0_tuple: Initial state.</span>
</span><span id="__span-0-2502"><a id="__codelineno-0-2502" name="__codelineno-0-2502"></a><span class="sd">        alpha: Fractional order.</span>
</span><span id="__span-0-2503"><a id="__codelineno-0-2503" name="__codelineno-0-2503"></a><span class="sd">        t_grid: Time grid.</span>
</span><span id="__span-0-2504"><a id="__codelineno-0-2504" name="__codelineno-0-2504"></a><span class="sd">        memory: Memory limit.</span>
</span><span id="__span-0-2505"><a id="__codelineno-0-2505" name="__codelineno-0-2505"></a>
</span><span id="__span-0-2506"><a id="__codelineno-0-2506" name="__codelineno-0-2506"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-2507"><a id="__codelineno-0-2507" name="__codelineno-0-2507"></a><span class="sd">        State trajectory.</span>
</span><span id="__span-0-2508"><a id="__codelineno-0-2508" name="__codelineno-0-2508"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-2509"><a id="__codelineno-0-2509" name="__codelineno-0-2509"></a>    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
</span><span id="__span-0-2510"><a id="__codelineno-0-2510" name="__codelineno-0-2510"></a>    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_grid</span><span class="p">)</span>
</span><span id="__span-0-2511"><a id="__codelineno-0-2511" name="__codelineno-0-2511"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">y0_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
</span><span id="__span-0-2512"><a id="__codelineno-0-2512" name="__codelineno-0-2512"></a>    <span class="n">dtype</span> <span class="o">=</span> <span class="n">y0_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-2513"><a id="__codelineno-0-2513" name="__codelineno-0-2513"></a>    <span class="n">t_grid</span> <span class="o">=</span> <span class="n">t_grid</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-2514"><a id="__codelineno-0-2514" name="__codelineno-0-2514"></a>    <span class="n">h</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># uniform step size</span>
</span><span id="__span-0-2515"><a id="__codelineno-0-2515" name="__codelineno-0-2515"></a>    <span class="c1"># gamma_alpha = 1 / math.gamma(alpha)</span>
</span><span id="__span-0-2516"><a id="__codelineno-0-2516" name="__codelineno-0-2516"></a>    <span class="n">h_alpha_over_alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">))</span>
</span><span id="__span-0-2517"><a id="__codelineno-0-2517" name="__codelineno-0-2517"></a>
</span><span id="__span-0-2518"><a id="__codelineno-0-2518" name="__codelineno-0-2518"></a>    <span class="c1"># Initialize history lists for each component</span>
</span><span id="__span-0-2519"><a id="__codelineno-0-2519" name="__codelineno-0-2519"></a>    <span class="n">y_history</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">y0_tuple</span><span class="p">]</span>
</span><span id="__span-0-2520"><a id="__codelineno-0-2520" name="__codelineno-0-2520"></a>    <span class="c1"># History for function evaluations (for ALL components in forward)</span>
</span><span id="__span-0-2521"><a id="__codelineno-0-2521" name="__codelineno-0-2521"></a>    <span class="n">fhistory</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">y0_tuple</span><span class="p">]</span>
</span><span id="__span-0-2522"><a id="__codelineno-0-2522" name="__codelineno-0-2522"></a>    <span class="c1"># Current state</span>
</span><span id="__span-0-2523"><a id="__codelineno-0-2523" name="__codelineno-0-2523"></a>    <span class="n">y_current</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">)</span>
</span><span id="__span-0-2524"><a id="__codelineno-0-2524" name="__codelineno-0-2524"></a>
</span><span id="__span-0-2525"><a id="__codelineno-0-2525" name="__codelineno-0-2525"></a>    <span class="c1"># Main loop: compute y_{k+1} for k = 0, 1, ..., N-2</span>
</span><span id="__span-0-2526"><a id="__codelineno-0-2526" name="__codelineno-0-2526"></a>    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-2527"><a id="__codelineno-0-2527" name="__codelineno-0-2527"></a>        <span class="n">t_k</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
</span><span id="__span-0-2528"><a id="__codelineno-0-2528" name="__codelineno-0-2528"></a>        <span class="c1"># Evaluate f(t_k, y_k)</span>
</span><span id="__span-0-2529"><a id="__codelineno-0-2529" name="__codelineno-0-2529"></a>        <span class="n">f_k</span> <span class="o">=</span> <span class="n">ode_func</span><span class="p">(</span><span class="n">t_k</span><span class="p">,</span> <span class="n">y_current</span><span class="p">)</span>
</span><span id="__span-0-2530"><a id="__codelineno-0-2530" name="__codelineno-0-2530"></a>
</span><span id="__span-0-2531"><a id="__codelineno-0-2531" name="__codelineno-0-2531"></a>        <span class="c1"># Store function evaluations for ALL components</span>
</span><span id="__span-0-2532"><a id="__codelineno-0-2532" name="__codelineno-0-2532"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_current</span><span class="p">)):</span>
</span><span id="__span-0-2533"><a id="__codelineno-0-2533" name="__codelineno-0-2533"></a>            <span class="n">fhistory</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f_k</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="__span-0-2534"><a id="__codelineno-0-2534" name="__codelineno-0-2534"></a>
</span><span id="__span-0-2535"><a id="__codelineno-0-2535" name="__codelineno-0-2535"></a>        <span class="c1"># Determine memory range</span>
</span><span id="__span-0-2536"><a id="__codelineno-0-2536" name="__codelineno-0-2536"></a>        <span class="k">if</span> <span class="n">memory</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-2537"><a id="__codelineno-0-2537" name="__codelineno-0-2537"></a>            <span class="n">memory_length</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="__span-0-2538"><a id="__codelineno-0-2538" name="__codelineno-0-2538"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-2539"><a id="__codelineno-0-2539" name="__codelineno-0-2539"></a>            <span class="n">memory_length</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-2540"><a id="__codelineno-0-2540" name="__codelineno-0-2540"></a>            <span class="k">assert</span> <span class="n">memory_length</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;memory must be greater than 0&quot;</span>
</span><span id="__span-0-2541"><a id="__codelineno-0-2541" name="__codelineno-0-2541"></a>
</span><span id="__span-0-2542"><a id="__codelineno-0-2542" name="__codelineno-0-2542"></a>        <span class="n">start_idx</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">memory_length</span><span class="p">)</span>
</span><span id="__span-0-2543"><a id="__codelineno-0-2543" name="__codelineno-0-2543"></a>
</span><span id="__span-0-2544"><a id="__codelineno-0-2544" name="__codelineno-0-2544"></a>        <span class="c1"># Compute weights b_{j,k+1} for indices from start_idx to k</span>
</span><span id="__span-0-2545"><a id="__codelineno-0-2545" name="__codelineno-0-2545"></a>        <span class="c1"># b_{j,k+1} = (h^α / α) * [(k+1-j)^α - (k-j)^α]</span>
</span><span id="__span-0-2546"><a id="__codelineno-0-2546" name="__codelineno-0-2546"></a>        <span class="n">j_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-2547"><a id="__codelineno-0-2547" name="__codelineno-0-2547"></a>        <span class="n">b_j_kp1</span> <span class="o">=</span> <span class="n">h_alpha_over_alpha</span> <span class="o">*</span> <span class="p">(</span>
</span><span id="__span-0-2548"><a id="__codelineno-0-2548" name="__codelineno-0-2548"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">j_vals</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">k</span> <span class="o">-</span> <span class="n">j_vals</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
</span><span id="__span-0-2549"><a id="__codelineno-0-2549" name="__codelineno-0-2549"></a>        <span class="p">)</span>
</span><span id="__span-0-2550"><a id="__codelineno-0-2550" name="__codelineno-0-2550"></a>
</span><span id="__span-0-2551"><a id="__codelineno-0-2551" name="__codelineno-0-2551"></a>        <span class="c1"># Update ALL state components</span>
</span><span id="__span-0-2552"><a id="__codelineno-0-2552" name="__codelineno-0-2552"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_current</span><span class="p">)):</span>
</span><span id="__span-0-2553"><a id="__codelineno-0-2553" name="__codelineno-0-2553"></a>            <span class="c1"># Compute convolution sum: sum_{j=start_idx}^{k} b_{j,k+1} * f_j[i]</span>
</span><span id="__span-0-2554"><a id="__codelineno-0-2554" name="__codelineno-0-2554"></a>            <span class="n">convolution_sum</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-0-2555"><a id="__codelineno-0-2555" name="__codelineno-0-2555"></a>            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-2556"><a id="__codelineno-0-2556" name="__codelineno-0-2556"></a>                <span class="n">local_idx</span> <span class="o">=</span> <span class="n">j</span> <span class="o">-</span> <span class="n">start_idx</span>
</span><span id="__span-0-2557"><a id="__codelineno-0-2557" name="__codelineno-0-2557"></a>                <span class="n">convolution_sum</span> <span class="o">=</span> <span class="n">convolution_sum</span> <span class="o">+</span> <span class="n">b_j_kp1</span><span class="p">[</span><span class="n">local_idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">fhistory</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
</span><span id="__span-0-2558"><a id="__codelineno-0-2558" name="__codelineno-0-2558"></a>
</span><span id="__span-0-2559"><a id="__codelineno-0-2559" name="__codelineno-0-2559"></a>            <span class="c1"># y_{k+1} = (1/Γ(α)) * convolution_sum</span>
</span><span id="__span-0-2560"><a id="__codelineno-0-2560" name="__codelineno-0-2560"></a>            <span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">convolution_sum</span>
</span><span id="__span-0-2561"><a id="__codelineno-0-2561" name="__codelineno-0-2561"></a>            <span class="n">y_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_current</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="__span-0-2562"><a id="__codelineno-0-2562" name="__codelineno-0-2562"></a>
</span><span id="__span-0-2563"><a id="__codelineno-0-2563" name="__codelineno-0-2563"></a>    <span class="k">del</span> <span class="n">fhistory</span>
</span><span id="__span-0-2564"><a id="__codelineno-0-2564" name="__codelineno-0-2564"></a>    <span class="k">return</span> <span class="n">y_history</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.backward_pred" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">backward_pred</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">backward_pred</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y_aug</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">yhistory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]],</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Backward Adams-Bashforth predictor method.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></code>)
          –
          <div class="doc-md-description">
            <p>Augmented dynamics.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y_aug</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>, <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>, <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>]</code>)
          –
          <div class="doc-md-description">
            <p>Initial augmented state.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>alpha</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a> | <a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Fractional order.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>Flipped time grid.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>yhistory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>)
          –
          <div class="doc-md-description">
            <p>Forward trajectory.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Memory limit.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>], <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]]</code>
          –
          <div class="doc-md-description">
            <p>Final adjoint states and parameter gradients.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-2567">2567</a></span>
<span class="normal"><a href="#__codelineno-0-2568">2568</a></span>
<span class="normal"><a href="#__codelineno-0-2569">2569</a></span>
<span class="normal"><a href="#__codelineno-0-2570">2570</a></span>
<span class="normal"><a href="#__codelineno-0-2571">2571</a></span>
<span class="normal"><a href="#__codelineno-0-2572">2572</a></span>
<span class="normal"><a href="#__codelineno-0-2573">2573</a></span>
<span class="normal"><a href="#__codelineno-0-2574">2574</a></span>
<span class="normal"><a href="#__codelineno-0-2575">2575</a></span>
<span class="normal"><a href="#__codelineno-0-2576">2576</a></span>
<span class="normal"><a href="#__codelineno-0-2577">2577</a></span>
<span class="normal"><a href="#__codelineno-0-2578">2578</a></span>
<span class="normal"><a href="#__codelineno-0-2579">2579</a></span>
<span class="normal"><a href="#__codelineno-0-2580">2580</a></span>
<span class="normal"><a href="#__codelineno-0-2581">2581</a></span>
<span class="normal"><a href="#__codelineno-0-2582">2582</a></span>
<span class="normal"><a href="#__codelineno-0-2583">2583</a></span>
<span class="normal"><a href="#__codelineno-0-2584">2584</a></span>
<span class="normal"><a href="#__codelineno-0-2585">2585</a></span>
<span class="normal"><a href="#__codelineno-0-2586">2586</a></span>
<span class="normal"><a href="#__codelineno-0-2587">2587</a></span>
<span class="normal"><a href="#__codelineno-0-2588">2588</a></span>
<span class="normal"><a href="#__codelineno-0-2589">2589</a></span>
<span class="normal"><a href="#__codelineno-0-2590">2590</a></span>
<span class="normal"><a href="#__codelineno-0-2591">2591</a></span>
<span class="normal"><a href="#__codelineno-0-2592">2592</a></span>
<span class="normal"><a href="#__codelineno-0-2593">2593</a></span>
<span class="normal"><a href="#__codelineno-0-2594">2594</a></span>
<span class="normal"><a href="#__codelineno-0-2595">2595</a></span>
<span class="normal"><a href="#__codelineno-0-2596">2596</a></span>
<span class="normal"><a href="#__codelineno-0-2597">2597</a></span>
<span class="normal"><a href="#__codelineno-0-2598">2598</a></span>
<span class="normal"><a href="#__codelineno-0-2599">2599</a></span>
<span class="normal"><a href="#__codelineno-0-2600">2600</a></span>
<span class="normal"><a href="#__codelineno-0-2601">2601</a></span>
<span class="normal"><a href="#__codelineno-0-2602">2602</a></span>
<span class="normal"><a href="#__codelineno-0-2603">2603</a></span>
<span class="normal"><a href="#__codelineno-0-2604">2604</a></span>
<span class="normal"><a href="#__codelineno-0-2605">2605</a></span>
<span class="normal"><a href="#__codelineno-0-2606">2606</a></span>
<span class="normal"><a href="#__codelineno-0-2607">2607</a></span>
<span class="normal"><a href="#__codelineno-0-2608">2608</a></span>
<span class="normal"><a href="#__codelineno-0-2609">2609</a></span>
<span class="normal"><a href="#__codelineno-0-2610">2610</a></span>
<span class="normal"><a href="#__codelineno-0-2611">2611</a></span>
<span class="normal"><a href="#__codelineno-0-2612">2612</a></span>
<span class="normal"><a href="#__codelineno-0-2613">2613</a></span>
<span class="normal"><a href="#__codelineno-0-2614">2614</a></span>
<span class="normal"><a href="#__codelineno-0-2615">2615</a></span>
<span class="normal"><a href="#__codelineno-0-2616">2616</a></span>
<span class="normal"><a href="#__codelineno-0-2617">2617</a></span>
<span class="normal"><a href="#__codelineno-0-2618">2618</a></span>
<span class="normal"><a href="#__codelineno-0-2619">2619</a></span>
<span class="normal"><a href="#__codelineno-0-2620">2620</a></span>
<span class="normal"><a href="#__codelineno-0-2621">2621</a></span>
<span class="normal"><a href="#__codelineno-0-2622">2622</a></span>
<span class="normal"><a href="#__codelineno-0-2623">2623</a></span>
<span class="normal"><a href="#__codelineno-0-2624">2624</a></span>
<span class="normal"><a href="#__codelineno-0-2625">2625</a></span>
<span class="normal"><a href="#__codelineno-0-2626">2626</a></span>
<span class="normal"><a href="#__codelineno-0-2627">2627</a></span>
<span class="normal"><a href="#__codelineno-0-2628">2628</a></span>
<span class="normal"><a href="#__codelineno-0-2629">2629</a></span>
<span class="normal"><a href="#__codelineno-0-2630">2630</a></span>
<span class="normal"><a href="#__codelineno-0-2631">2631</a></span>
<span class="normal"><a href="#__codelineno-0-2632">2632</a></span>
<span class="normal"><a href="#__codelineno-0-2633">2633</a></span>
<span class="normal"><a href="#__codelineno-0-2634">2634</a></span>
<span class="normal"><a href="#__codelineno-0-2635">2635</a></span>
<span class="normal"><a href="#__codelineno-0-2636">2636</a></span>
<span class="normal"><a href="#__codelineno-0-2637">2637</a></span>
<span class="normal"><a href="#__codelineno-0-2638">2638</a></span>
<span class="normal"><a href="#__codelineno-0-2639">2639</a></span>
<span class="normal"><a href="#__codelineno-0-2640">2640</a></span>
<span class="normal"><a href="#__codelineno-0-2641">2641</a></span>
<span class="normal"><a href="#__codelineno-0-2642">2642</a></span>
<span class="normal"><a href="#__codelineno-0-2643">2643</a></span>
<span class="normal"><a href="#__codelineno-0-2644">2644</a></span>
<span class="normal"><a href="#__codelineno-0-2645">2645</a></span>
<span class="normal"><a href="#__codelineno-0-2646">2646</a></span>
<span class="normal"><a href="#__codelineno-0-2647">2647</a></span>
<span class="normal"><a href="#__codelineno-0-2648">2648</a></span>
<span class="normal"><a href="#__codelineno-0-2649">2649</a></span>
<span class="normal"><a href="#__codelineno-0-2650">2650</a></span>
<span class="normal"><a href="#__codelineno-0-2651">2651</a></span>
<span class="normal"><a href="#__codelineno-0-2652">2652</a></span>
<span class="normal"><a href="#__codelineno-0-2653">2653</a></span>
<span class="normal"><a href="#__codelineno-0-2654">2654</a></span>
<span class="normal"><a href="#__codelineno-0-2655">2655</a></span>
<span class="normal"><a href="#__codelineno-0-2656">2656</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-2567"><a id="__codelineno-0-2567" name="__codelineno-0-2567"></a><span class="k">def</span><span class="w"> </span><span class="nf">backward_pred</span><span class="p">(</span>
</span><span id="__span-0-2568"><a id="__codelineno-0-2568" name="__codelineno-0-2568"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
</span><span id="__span-0-2569"><a id="__codelineno-0-2569" name="__codelineno-0-2569"></a>    <span class="n">y_aug</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">],</span>
</span><span id="__span-0-2570"><a id="__codelineno-0-2570" name="__codelineno-0-2570"></a>    <span class="n">alpha</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="__span-0-2571"><a id="__codelineno-0-2571" name="__codelineno-0-2571"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-2572"><a id="__codelineno-0-2572" name="__codelineno-0-2572"></a>    <span class="n">yhistory</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
</span><span id="__span-0-2573"><a id="__codelineno-0-2573" name="__codelineno-0-2573"></a>    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-2574"><a id="__codelineno-0-2574" name="__codelineno-0-2574"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="__span-0-2575"><a id="__codelineno-0-2575" name="__codelineno-0-2575"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-2576"><a id="__codelineno-0-2576" name="__codelineno-0-2576"></a><span class="sd">    Backward Adams-Bashforth predictor method.</span>
</span><span id="__span-0-2577"><a id="__codelineno-0-2577" name="__codelineno-0-2577"></a>
</span><span id="__span-0-2578"><a id="__codelineno-0-2578" name="__codelineno-0-2578"></a><span class="sd">    Args:</span>
</span><span id="__span-0-2579"><a id="__codelineno-0-2579" name="__codelineno-0-2579"></a><span class="sd">        ode_func: Augmented dynamics.</span>
</span><span id="__span-0-2580"><a id="__codelineno-0-2580" name="__codelineno-0-2580"></a><span class="sd">        y_aug: Initial augmented state.</span>
</span><span id="__span-0-2581"><a id="__codelineno-0-2581" name="__codelineno-0-2581"></a><span class="sd">        alpha: Fractional order.</span>
</span><span id="__span-0-2582"><a id="__codelineno-0-2582" name="__codelineno-0-2582"></a><span class="sd">        t_grid: Flipped time grid.</span>
</span><span id="__span-0-2583"><a id="__codelineno-0-2583" name="__codelineno-0-2583"></a><span class="sd">        yhistory: Forward trajectory.</span>
</span><span id="__span-0-2584"><a id="__codelineno-0-2584" name="__codelineno-0-2584"></a><span class="sd">        memory: Memory limit.</span>
</span><span id="__span-0-2585"><a id="__codelineno-0-2585" name="__codelineno-0-2585"></a>
</span><span id="__span-0-2586"><a id="__codelineno-0-2586" name="__codelineno-0-2586"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-2587"><a id="__codelineno-0-2587" name="__codelineno-0-2587"></a><span class="sd">        Final adjoint states and parameter gradients.</span>
</span><span id="__span-0-2588"><a id="__codelineno-0-2588" name="__codelineno-0-2588"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-2589"><a id="__codelineno-0-2589" name="__codelineno-0-2589"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="__span-0-2590"><a id="__codelineno-0-2590" name="__codelineno-0-2590"></a>        <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_grid</span><span class="p">)</span>
</span><span id="__span-0-2591"><a id="__codelineno-0-2591" name="__codelineno-0-2591"></a>        <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
</span><span id="__span-0-2592"><a id="__codelineno-0-2592" name="__codelineno-0-2592"></a>        <span class="c1"># gamma_alpha = 1 / math.gamma(alpha)</span>
</span><span id="__span-0-2593"><a id="__codelineno-0-2593" name="__codelineno-0-2593"></a>        <span class="n">h_alpha_over_alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">))</span>
</span><span id="__span-0-2594"><a id="__codelineno-0-2594" name="__codelineno-0-2594"></a>
</span><span id="__span-0-2595"><a id="__codelineno-0-2595" name="__codelineno-0-2595"></a>        <span class="n">_</span><span class="p">,</span> <span class="n">adj_y0</span><span class="p">,</span> <span class="n">adj_params0</span> <span class="o">=</span> <span class="n">y_aug</span>
</span><span id="__span-0-2596"><a id="__codelineno-0-2596" name="__codelineno-0-2596"></a>        <span class="n">device</span> <span class="o">=</span> <span class="n">adj_y0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
</span><span id="__span-0-2597"><a id="__codelineno-0-2597" name="__codelineno-0-2597"></a>        <span class="n">dtype</span> <span class="o">=</span> <span class="n">adj_y0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-2598"><a id="__codelineno-0-2598" name="__codelineno-0-2598"></a>
</span><span id="__span-0-2599"><a id="__codelineno-0-2599" name="__codelineno-0-2599"></a>        <span class="c1"># Initialize adjoint history lists with initial values</span>
</span><span id="__span-0-2600"><a id="__codelineno-0-2600" name="__codelineno-0-2600"></a>        <span class="n">adjf_history</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-0-2601"><a id="__codelineno-0-2601" name="__codelineno-0-2601"></a>            <span class="p">[</span>
</span><span id="__span-0-2602"><a id="__codelineno-0-2602" name="__codelineno-0-2602"></a>                <span class="n">xx</span><span class="p">,</span>
</span><span id="__span-0-2603"><a id="__codelineno-0-2603" name="__codelineno-0-2603"></a>            <span class="p">]</span>
</span><span id="__span-0-2604"><a id="__codelineno-0-2604" name="__codelineno-0-2604"></a>            <span class="k">for</span> <span class="n">xx</span> <span class="ow">in</span> <span class="n">adj_y0</span>
</span><span id="__span-0-2605"><a id="__codelineno-0-2605" name="__codelineno-0-2605"></a>        <span class="p">]</span>
</span><span id="__span-0-2606"><a id="__codelineno-0-2606" name="__codelineno-0-2606"></a>
</span><span id="__span-0-2607"><a id="__codelineno-0-2607" name="__codelineno-0-2607"></a>        <span class="c1"># Clone initial adjoint values</span>
</span><span id="__span-0-2608"><a id="__codelineno-0-2608" name="__codelineno-0-2608"></a>        <span class="n">adj_y</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">adj_y0</span><span class="p">)</span>
</span><span id="__span-0-2609"><a id="__codelineno-0-2609" name="__codelineno-0-2609"></a>        <span class="n">adj_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">adj_params0</span><span class="p">)</span>
</span><span id="__span-0-2610"><a id="__codelineno-0-2610" name="__codelineno-0-2610"></a>
</span><span id="__span-0-2611"><a id="__codelineno-0-2611" name="__codelineno-0-2611"></a>        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">2</span><span class="p">):</span>
</span><span id="__span-0-2612"><a id="__codelineno-0-2612" name="__codelineno-0-2612"></a>            <span class="n">tk</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
</span><span id="__span-0-2613"><a id="__codelineno-0-2613" name="__codelineno-0-2613"></a>            <span class="n">y_state</span> <span class="o">=</span> <span class="nb">list</span><span class="p">([</span><span class="n">y</span><span class="p">[</span><span class="o">-</span><span class="n">k</span> <span class="o">-</span> <span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">yhistory</span><span class="p">])</span>
</span><span id="__span-0-2614"><a id="__codelineno-0-2614" name="__codelineno-0-2614"></a>
</span><span id="__span-0-2615"><a id="__codelineno-0-2615" name="__codelineno-0-2615"></a>            <span class="n">func_eval</span><span class="p">,</span> <span class="n">vjp_y</span><span class="p">,</span> <span class="n">vjp_params</span> <span class="o">=</span> <span class="n">ode_func</span><span class="p">(</span><span class="n">tk</span><span class="p">,</span> <span class="p">(</span><span class="n">y_state</span><span class="p">,</span> <span class="n">adj_y</span><span class="p">,</span> <span class="n">adj_params</span><span class="p">))</span>
</span><span id="__span-0-2616"><a id="__codelineno-0-2616" name="__codelineno-0-2616"></a>
</span><span id="__span-0-2617"><a id="__codelineno-0-2617" name="__codelineno-0-2617"></a>            <span class="c1"># Store adjoint of function evaluation</span>
</span><span id="__span-0-2618"><a id="__codelineno-0-2618" name="__codelineno-0-2618"></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">adj_y</span><span class="p">)):</span>
</span><span id="__span-0-2619"><a id="__codelineno-0-2619" name="__codelineno-0-2619"></a>                <span class="n">adjf_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vjp_y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="__span-0-2620"><a id="__codelineno-0-2620" name="__codelineno-0-2620"></a>
</span><span id="__span-0-2621"><a id="__codelineno-0-2621" name="__codelineno-0-2621"></a>            <span class="c1"># Determine memory range</span>
</span><span id="__span-0-2622"><a id="__codelineno-0-2622" name="__codelineno-0-2622"></a>            <span class="k">if</span> <span class="n">memory</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-2623"><a id="__codelineno-0-2623" name="__codelineno-0-2623"></a>                <span class="n">memory_length</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="__span-0-2624"><a id="__codelineno-0-2624" name="__codelineno-0-2624"></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-2625"><a id="__codelineno-0-2625" name="__codelineno-0-2625"></a>                <span class="n">memory_length</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-2626"><a id="__codelineno-0-2626" name="__codelineno-0-2626"></a>
</span><span id="__span-0-2627"><a id="__codelineno-0-2627" name="__codelineno-0-2627"></a>            <span class="n">start_idx</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">memory_length</span><span class="p">)</span>
</span><span id="__span-0-2628"><a id="__codelineno-0-2628" name="__codelineno-0-2628"></a>
</span><span id="__span-0-2629"><a id="__codelineno-0-2629" name="__codelineno-0-2629"></a>            <span class="c1"># Compute weights b_{j,k+1}</span>
</span><span id="__span-0-2630"><a id="__codelineno-0-2630" name="__codelineno-0-2630"></a>            <span class="c1"># b_{j,k+1} = (h^α / α) * [(k+1-j)^α - (k-j)^α]</span>
</span><span id="__span-0-2631"><a id="__codelineno-0-2631" name="__codelineno-0-2631"></a>            <span class="n">j_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-2632"><a id="__codelineno-0-2632" name="__codelineno-0-2632"></a>            <span class="n">b_j_kp1</span> <span class="o">=</span> <span class="n">h_alpha_over_alpha</span> <span class="o">*</span> <span class="p">(</span>
</span><span id="__span-0-2633"><a id="__codelineno-0-2633" name="__codelineno-0-2633"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">j_vals</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">k</span> <span class="o">-</span> <span class="n">j_vals</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
</span><span id="__span-0-2634"><a id="__codelineno-0-2634" name="__codelineno-0-2634"></a>            <span class="p">)</span>
</span><span id="__span-0-2635"><a id="__codelineno-0-2635" name="__codelineno-0-2635"></a>
</span><span id="__span-0-2636"><a id="__codelineno-0-2636" name="__codelineno-0-2636"></a>            <span class="c1"># Update all adjoint components</span>
</span><span id="__span-0-2637"><a id="__codelineno-0-2637" name="__codelineno-0-2637"></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">adj_y</span><span class="p">)):</span>
</span><span id="__span-0-2638"><a id="__codelineno-0-2638" name="__codelineno-0-2638"></a>                <span class="c1"># Compute convolution sum over adjoint history</span>
</span><span id="__span-0-2639"><a id="__codelineno-0-2639" name="__codelineno-0-2639"></a>                <span class="n">convolution_sum</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-0-2640"><a id="__codelineno-0-2640" name="__codelineno-0-2640"></a>                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-2641"><a id="__codelineno-0-2641" name="__codelineno-0-2641"></a>                    <span class="n">local_idx</span> <span class="o">=</span> <span class="n">j</span> <span class="o">-</span> <span class="n">start_idx</span>
</span><span id="__span-0-2642"><a id="__codelineno-0-2642" name="__codelineno-0-2642"></a>                    <span class="n">convolution_sum</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-2643"><a id="__codelineno-0-2643" name="__codelineno-0-2643"></a>                        <span class="n">convolution_sum</span> <span class="o">+</span> <span class="n">b_j_kp1</span><span class="p">[</span><span class="n">local_idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">adjf_history</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
</span><span id="__span-0-2644"><a id="__codelineno-0-2644" name="__codelineno-0-2644"></a>                    <span class="p">)</span>
</span><span id="__span-0-2645"><a id="__codelineno-0-2645" name="__codelineno-0-2645"></a>
</span><span id="__span-0-2646"><a id="__codelineno-0-2646" name="__codelineno-0-2646"></a>                <span class="c1"># Update adjoint state</span>
</span><span id="__span-0-2647"><a id="__codelineno-0-2647" name="__codelineno-0-2647"></a>                <span class="n">adj_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">adj_y0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">convolution_sum</span>
</span><span id="__span-0-2648"><a id="__codelineno-0-2648" name="__codelineno-0-2648"></a>
</span><span id="__span-0-2649"><a id="__codelineno-0-2649" name="__codelineno-0-2649"></a>            <span class="c1"># Update parameter gradients</span>
</span><span id="__span-0-2650"><a id="__codelineno-0-2650" name="__codelineno-0-2650"></a>            <span class="k">if</span> <span class="n">adj_params</span> <span class="ow">and</span> <span class="n">vjp_params</span><span class="p">:</span>
</span><span id="__span-0-2651"><a id="__codelineno-0-2651" name="__codelineno-0-2651"></a>                <span class="k">for</span> <span class="n">ap</span><span class="p">,</span> <span class="n">vp</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">adj_params</span><span class="p">,</span> <span class="n">vjp_params</span><span class="p">):</span>
</span><span id="__span-0-2652"><a id="__codelineno-0-2652" name="__codelineno-0-2652"></a>                    <span class="n">ap</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">vp</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">h</span><span class="p">)</span>
</span><span id="__span-0-2653"><a id="__codelineno-0-2653" name="__codelineno-0-2653"></a>
</span><span id="__span-0-2654"><a id="__codelineno-0-2654" name="__codelineno-0-2654"></a>    <span class="k">del</span> <span class="n">adjf_history</span><span class="p">,</span> <span class="n">yhistory</span>
</span><span id="__span-0-2655"><a id="__codelineno-0-2655" name="__codelineno-0-2655"></a>
</span><span id="__span-0-2656"><a id="__codelineno-0-2656" name="__codelineno-0-2656"></a>    <span class="k">return</span> <span class="n">adj_y</span><span class="p">,</span> <span class="n">adj_params</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.find_parameters" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">find_parameters</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">find_parameters</span><span class="p">(</span><span class="n">module</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.nn.Module" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module">Module</a></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Extracts all trainable parameters from a PyTorch module.</p>
<p>Handles special cases such as <code>DataParallel</code> replicas where parameters might not
be registered in the standard <code>.parameters()</code> iterator.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>module</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.nn.Module" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module">Module</a></code>)
          –
          <div class="doc-md-description">
            <p>The <code>nn.Module</code> to inspect.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]</code>
          –
          <div class="doc-md-description">
            <p>A list of <code>torch.Tensor</code> parameters that require gradients.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-2659">2659</a></span>
<span class="normal"><a href="#__codelineno-0-2660">2660</a></span>
<span class="normal"><a href="#__codelineno-0-2661">2661</a></span>
<span class="normal"><a href="#__codelineno-0-2662">2662</a></span>
<span class="normal"><a href="#__codelineno-0-2663">2663</a></span>
<span class="normal"><a href="#__codelineno-0-2664">2664</a></span>
<span class="normal"><a href="#__codelineno-0-2665">2665</a></span>
<span class="normal"><a href="#__codelineno-0-2666">2666</a></span>
<span class="normal"><a href="#__codelineno-0-2667">2667</a></span>
<span class="normal"><a href="#__codelineno-0-2668">2668</a></span>
<span class="normal"><a href="#__codelineno-0-2669">2669</a></span>
<span class="normal"><a href="#__codelineno-0-2670">2670</a></span>
<span class="normal"><a href="#__codelineno-0-2671">2671</a></span>
<span class="normal"><a href="#__codelineno-0-2672">2672</a></span>
<span class="normal"><a href="#__codelineno-0-2673">2673</a></span>
<span class="normal"><a href="#__codelineno-0-2674">2674</a></span>
<span class="normal"><a href="#__codelineno-0-2675">2675</a></span>
<span class="normal"><a href="#__codelineno-0-2676">2676</a></span>
<span class="normal"><a href="#__codelineno-0-2677">2677</a></span>
<span class="normal"><a href="#__codelineno-0-2678">2678</a></span>
<span class="normal"><a href="#__codelineno-0-2679">2679</a></span>
<span class="normal"><a href="#__codelineno-0-2680">2680</a></span>
<span class="normal"><a href="#__codelineno-0-2681">2681</a></span>
<span class="normal"><a href="#__codelineno-0-2682">2682</a></span>
<span class="normal"><a href="#__codelineno-0-2683">2683</a></span>
<span class="normal"><a href="#__codelineno-0-2684">2684</a></span>
<span class="normal"><a href="#__codelineno-0-2685">2685</a></span>
<span class="normal"><a href="#__codelineno-0-2686">2686</a></span>
<span class="normal"><a href="#__codelineno-0-2687">2687</a></span>
<span class="normal"><a href="#__codelineno-0-2688">2688</a></span>
<span class="normal"><a href="#__codelineno-0-2689">2689</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-2659"><a id="__codelineno-0-2659" name="__codelineno-0-2659"></a><span class="k">def</span><span class="w"> </span><span class="nf">find_parameters</span><span class="p">(</span><span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="__span-0-2660"><a id="__codelineno-0-2660" name="__codelineno-0-2660"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-2661"><a id="__codelineno-0-2661" name="__codelineno-0-2661"></a><span class="sd">    Extracts all trainable parameters from a PyTorch module.</span>
</span><span id="__span-0-2662"><a id="__codelineno-0-2662" name="__codelineno-0-2662"></a>
</span><span id="__span-0-2663"><a id="__codelineno-0-2663" name="__codelineno-0-2663"></a><span class="sd">    Handles special cases such as `DataParallel` replicas where parameters might not</span>
</span><span id="__span-0-2664"><a id="__codelineno-0-2664" name="__codelineno-0-2664"></a><span class="sd">    be registered in the standard `.parameters()` iterator.</span>
</span><span id="__span-0-2665"><a id="__codelineno-0-2665" name="__codelineno-0-2665"></a>
</span><span id="__span-0-2666"><a id="__codelineno-0-2666" name="__codelineno-0-2666"></a><span class="sd">    Args:</span>
</span><span id="__span-0-2667"><a id="__codelineno-0-2667" name="__codelineno-0-2667"></a><span class="sd">        module: The `nn.Module` to inspect.</span>
</span><span id="__span-0-2668"><a id="__codelineno-0-2668" name="__codelineno-0-2668"></a>
</span><span id="__span-0-2669"><a id="__codelineno-0-2669" name="__codelineno-0-2669"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-2670"><a id="__codelineno-0-2670" name="__codelineno-0-2670"></a><span class="sd">        A list of `torch.Tensor` parameters that require gradients.</span>
</span><span id="__span-0-2671"><a id="__codelineno-0-2671" name="__codelineno-0-2671"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-2672"><a id="__codelineno-0-2672" name="__codelineno-0-2672"></a>
</span><span id="__span-0-2673"><a id="__codelineno-0-2673" name="__codelineno-0-2673"></a>    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
</span><span id="__span-0-2674"><a id="__codelineno-0-2674" name="__codelineno-0-2674"></a>
</span><span id="__span-0-2675"><a id="__codelineno-0-2675" name="__codelineno-0-2675"></a>    <span class="c1"># If called within DataParallel, parameters won&#39;t appear in module.parameters().</span>
</span><span id="__span-0-2676"><a id="__codelineno-0-2676" name="__codelineno-0-2676"></a>    <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s2">&quot;_is_replica&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="__span-0-2677"><a id="__codelineno-0-2677" name="__codelineno-0-2677"></a>
</span><span id="__span-0-2678"><a id="__codelineno-0-2678" name="__codelineno-0-2678"></a>        <span class="k">def</span><span class="w"> </span><span class="nf">find_tensor_attributes</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>
</span><span id="__span-0-2679"><a id="__codelineno-0-2679" name="__codelineno-0-2679"></a>            <span class="n">tuples</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-0-2680"><a id="__codelineno-0-2680" name="__codelineno-0-2680"></a>                <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
</span><span id="__span-0-2681"><a id="__codelineno-0-2681" name="__codelineno-0-2681"></a>                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
</span><span id="__span-0-2682"><a id="__codelineno-0-2682" name="__codelineno-0-2682"></a>                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="ow">and</span> <span class="n">v</span><span class="o">.</span><span class="n">requires_grad</span>
</span><span id="__span-0-2683"><a id="__codelineno-0-2683" name="__codelineno-0-2683"></a>            <span class="p">]</span>
</span><span id="__span-0-2684"><a id="__codelineno-0-2684" name="__codelineno-0-2684"></a>            <span class="k">return</span> <span class="n">tuples</span>
</span><span id="__span-0-2685"><a id="__codelineno-0-2685" name="__codelineno-0-2685"></a>
</span><span id="__span-0-2686"><a id="__codelineno-0-2686" name="__codelineno-0-2686"></a>        <span class="n">gen</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">_named_members</span><span class="p">(</span><span class="n">get_members_fn</span><span class="o">=</span><span class="n">find_tensor_attributes</span><span class="p">)</span>
</span><span id="__span-0-2687"><a id="__codelineno-0-2687" name="__codelineno-0-2687"></a>        <span class="k">return</span> <span class="p">[</span><span class="n">param</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">gen</span><span class="p">]</span>
</span><span id="__span-0-2688"><a id="__codelineno-0-2688" name="__codelineno-0-2688"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-2689"><a id="__codelineno-0-2689" name="__codelineno-0-2689"></a>        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.get_memory_bounds" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">get_memory_bounds</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">get_memory_bounds</span><span class="p">(</span><span class="n">k</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span> <span class="n">memory</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Calculates the range of history indices to include in the convolution sum.</p>
<p>Supports memory truncation for long sequences to reduce computational complexity
from <span class="arithmatex">\(O(N^2)\)</span> to <span class="arithmatex">\(O(N \cdot M)\)</span>, where <span class="arithmatex">\(M\)</span> is the memory length.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>k</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>Current time step index.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>memory</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a> | None</code>)
          –
          <div class="doc-md-description">
            <p>Maximum number of history steps to retain. If <code>None</code> or <code>-1</code>, uses full history.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a>, <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a>]</code>
          –
          <div class="doc-md-description">
            <p>A tuple <code>(start_idx, memory_length)</code> defining the slice of history to use.</p>
<ul>
<li><code>start_idx</code>: The starting index in the history list;</li>
<li><code>memory_length</code>: The number of elements to include.</li>
</ul>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span>
<span class="normal"><a href="#__codelineno-0-290">290</a></span>
<span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-281"><a id="__codelineno-0-281" name="__codelineno-0-281"></a><span class="k">def</span><span class="w"> </span><span class="nf">get_memory_bounds</span><span class="p">(</span><span class="n">k</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
</span><span id="__span-0-282"><a id="__codelineno-0-282" name="__codelineno-0-282"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-283"><a id="__codelineno-0-283" name="__codelineno-0-283"></a><span class="sd">    Calculates the range of history indices to include in the convolution sum.</span>
</span><span id="__span-0-284"><a id="__codelineno-0-284" name="__codelineno-0-284"></a>
</span><span id="__span-0-285"><a id="__codelineno-0-285" name="__codelineno-0-285"></a><span class="sd">    Supports memory truncation for long sequences to reduce computational complexity</span>
</span><span id="__span-0-286"><a id="__codelineno-0-286" name="__codelineno-0-286"></a><span class="sd">    from $O(N^2)$ to $O(N \cdot M)$, where $M$ is the memory length.</span>
</span><span id="__span-0-287"><a id="__codelineno-0-287" name="__codelineno-0-287"></a>
</span><span id="__span-0-288"><a id="__codelineno-0-288" name="__codelineno-0-288"></a><span class="sd">    Args:</span>
</span><span id="__span-0-289"><a id="__codelineno-0-289" name="__codelineno-0-289"></a><span class="sd">        k: Current time step index.</span>
</span><span id="__span-0-290"><a id="__codelineno-0-290" name="__codelineno-0-290"></a><span class="sd">        memory: Maximum number of history steps to retain. If `None` or `-1`, uses full history.</span>
</span><span id="__span-0-291"><a id="__codelineno-0-291" name="__codelineno-0-291"></a>
</span><span id="__span-0-292"><a id="__codelineno-0-292" name="__codelineno-0-292"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-293"><a id="__codelineno-0-293" name="__codelineno-0-293"></a><span class="sd">        A tuple `(start_idx, memory_length)` defining the slice of history to use.</span>
</span><span id="__span-0-294"><a id="__codelineno-0-294" name="__codelineno-0-294"></a>
</span><span id="__span-0-295"><a id="__codelineno-0-295" name="__codelineno-0-295"></a><span class="sd">            - `start_idx`: The starting index in the history list;</span>
</span><span id="__span-0-296"><a id="__codelineno-0-296" name="__codelineno-0-296"></a><span class="sd">            - `memory_length`: The number of elements to include.</span>
</span><span id="__span-0-297"><a id="__codelineno-0-297" name="__codelineno-0-297"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-298"><a id="__codelineno-0-298" name="__codelineno-0-298"></a>    <span class="k">if</span> <span class="n">memory</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">memory</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
</span><span id="__span-0-299"><a id="__codelineno-0-299" name="__codelineno-0-299"></a>        <span class="n">memory_length</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="__span-0-300"><a id="__codelineno-0-300" name="__codelineno-0-300"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-301"><a id="__codelineno-0-301" name="__codelineno-0-301"></a>        <span class="n">memory_length</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-302"><a id="__codelineno-0-302" name="__codelineno-0-302"></a>        <span class="k">assert</span> <span class="n">memory_length</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;memory must be greater than 0&quot;</span>
</span><span id="__span-0-303"><a id="__codelineno-0-303" name="__codelineno-0-303"></a>
</span><span id="__span-0-304"><a id="__codelineno-0-304" name="__codelineno-0-304"></a>    <span class="n">start_idx</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">memory_length</span><span class="p">)</span>
</span><span id="__span-0-305"><a id="__codelineno-0-305" name="__codelineno-0-305"></a>    <span class="k">return</span> <span class="n">start_idx</span><span class="p">,</span> <span class="n">memory_length</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="spikeDE.solver.step_dynamics" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">step_dynamics</span>


</h2>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">step_dynamics</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a></span><span class="p">[[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Tuple" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Steps through a discrete-time dynamical system, collecting boundary outputs.</p>
<p>This function drives the for-loop of an SNN/RNN without numerical integration scaling (no <span class="arithmatex">\(dt\)</span>).
The update function directly computes the next state: <span class="arithmatex">\(y_{k+1} = f(t_k, y_k)\)</span>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>ode_func</code></b>
              (<code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a>[[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, <a class="autorefs autorefs-external" title="typing.Tuple" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a>], <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>]</code>)
          –
          <div class="doc-md-description">
            <p>Callable <code>(t, y_tuple) -&gt; tuple</code>. State update function.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>y0_tuple</code></b>
              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, ...]</code>)
          –
          <div class="doc-md-description">
            <p>Tuple of initial state tensors.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>t_grid</code></b>
              (<code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>)
          –
          <div class="doc-md-description">
            <p>1D tensor of time points (length T+1).</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]</code>
          –
          <div class="doc-md-description">
            <p>List of spike outputs (last component of state) at each time step.</p>
          </div>
        </li>
    </ul>

          

            <details class="mkdocstrings-source">
              <summary>Source code in <code>spikeDE/solver.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1319">1319</a></span>
<span class="normal"><a href="#__codelineno-0-1320">1320</a></span>
<span class="normal"><a href="#__codelineno-0-1321">1321</a></span>
<span class="normal"><a href="#__codelineno-0-1322">1322</a></span>
<span class="normal"><a href="#__codelineno-0-1323">1323</a></span>
<span class="normal"><a href="#__codelineno-0-1324">1324</a></span>
<span class="normal"><a href="#__codelineno-0-1325">1325</a></span>
<span class="normal"><a href="#__codelineno-0-1326">1326</a></span>
<span class="normal"><a href="#__codelineno-0-1327">1327</a></span>
<span class="normal"><a href="#__codelineno-0-1328">1328</a></span>
<span class="normal"><a href="#__codelineno-0-1329">1329</a></span>
<span class="normal"><a href="#__codelineno-0-1330">1330</a></span>
<span class="normal"><a href="#__codelineno-0-1331">1331</a></span>
<span class="normal"><a href="#__codelineno-0-1332">1332</a></span>
<span class="normal"><a href="#__codelineno-0-1333">1333</a></span>
<span class="normal"><a href="#__codelineno-0-1334">1334</a></span>
<span class="normal"><a href="#__codelineno-0-1335">1335</a></span>
<span class="normal"><a href="#__codelineno-0-1336">1336</a></span>
<span class="normal"><a href="#__codelineno-0-1337">1337</a></span>
<span class="normal"><a href="#__codelineno-0-1338">1338</a></span>
<span class="normal"><a href="#__codelineno-0-1339">1339</a></span>
<span class="normal"><a href="#__codelineno-0-1340">1340</a></span>
<span class="normal"><a href="#__codelineno-0-1341">1341</a></span>
<span class="normal"><a href="#__codelineno-0-1342">1342</a></span>
<span class="normal"><a href="#__codelineno-0-1343">1343</a></span>
<span class="normal"><a href="#__codelineno-0-1344">1344</a></span>
<span class="normal"><a href="#__codelineno-0-1345">1345</a></span>
<span class="normal"><a href="#__codelineno-0-1346">1346</a></span>
<span class="normal"><a href="#__codelineno-0-1347">1347</a></span>
<span class="normal"><a href="#__codelineno-0-1348">1348</a></span>
<span class="normal"><a href="#__codelineno-0-1349">1349</a></span>
<span class="normal"><a href="#__codelineno-0-1350">1350</a></span>
<span class="normal"><a href="#__codelineno-0-1351">1351</a></span>
<span class="normal"><a href="#__codelineno-0-1352">1352</a></span>
<span class="normal"><a href="#__codelineno-0-1353">1353</a></span>
<span class="normal"><a href="#__codelineno-0-1354">1354</a></span>
<span class="normal"><a href="#__codelineno-0-1355">1355</a></span>
<span class="normal"><a href="#__codelineno-0-1356">1356</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1319"><a id="__codelineno-0-1319" name="__codelineno-0-1319"></a><span class="k">def</span><span class="w"> </span><span class="nf">step_dynamics</span><span class="p">(</span>
</span><span id="__span-0-1320"><a id="__codelineno-0-1320" name="__codelineno-0-1320"></a>    <span class="n">ode_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">],</span>
</span><span id="__span-0-1321"><a id="__codelineno-0-1321" name="__codelineno-0-1321"></a>    <span class="n">y0_tuple</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="__span-0-1322"><a id="__codelineno-0-1322" name="__codelineno-0-1322"></a>    <span class="n">t_grid</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-1323"><a id="__codelineno-0-1323" name="__codelineno-0-1323"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="__span-0-1324"><a id="__codelineno-0-1324" name="__codelineno-0-1324"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-1325"><a id="__codelineno-0-1325" name="__codelineno-0-1325"></a><span class="sd">    Steps through a discrete-time dynamical system, collecting boundary outputs.</span>
</span><span id="__span-0-1326"><a id="__codelineno-0-1326" name="__codelineno-0-1326"></a>
</span><span id="__span-0-1327"><a id="__codelineno-0-1327" name="__codelineno-0-1327"></a><span class="sd">    This function drives the for-loop of an SNN/RNN without numerical integration scaling (no $dt$).</span>
</span><span id="__span-0-1328"><a id="__codelineno-0-1328" name="__codelineno-0-1328"></a><span class="sd">    The update function directly computes the next state: $y_{k+1} = f(t_k, y_k)$.</span>
</span><span id="__span-0-1329"><a id="__codelineno-0-1329" name="__codelineno-0-1329"></a>
</span><span id="__span-0-1330"><a id="__codelineno-0-1330" name="__codelineno-0-1330"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1331"><a id="__codelineno-0-1331" name="__codelineno-0-1331"></a><span class="sd">        ode_func: Callable `(t, y_tuple) -&gt; tuple`. State update function.</span>
</span><span id="__span-0-1332"><a id="__codelineno-0-1332" name="__codelineno-0-1332"></a><span class="sd">        y0_tuple: Tuple of initial state tensors.</span>
</span><span id="__span-0-1333"><a id="__codelineno-0-1333" name="__codelineno-0-1333"></a><span class="sd">        t_grid: 1D tensor of time points (length T+1).</span>
</span><span id="__span-0-1334"><a id="__codelineno-0-1334" name="__codelineno-0-1334"></a>
</span><span id="__span-0-1335"><a id="__codelineno-0-1335" name="__codelineno-0-1335"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1336"><a id="__codelineno-0-1336" name="__codelineno-0-1336"></a><span class="sd">        List of spike outputs (last component of state) at each time step.</span>
</span><span id="__span-0-1337"><a id="__codelineno-0-1337" name="__codelineno-0-1337"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-1338"><a id="__codelineno-0-1338" name="__codelineno-0-1338"></a>    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
</span><span id="__span-0-1339"><a id="__codelineno-0-1339" name="__codelineno-0-1339"></a>    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_grid</span><span class="p">)</span>
</span><span id="__span-0-1340"><a id="__codelineno-0-1340" name="__codelineno-0-1340"></a>    <span class="k">assert</span> <span class="n">N</span> <span class="o">&gt;=</span> <span class="mi">2</span>
</span><span id="__span-0-1341"><a id="__codelineno-0-1341" name="__codelineno-0-1341"></a>
</span><span id="__span-0-1342"><a id="__codelineno-0-1342" name="__codelineno-0-1342"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">y0_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
</span><span id="__span-0-1343"><a id="__codelineno-0-1343" name="__codelineno-0-1343"></a>    <span class="n">dtype</span> <span class="o">=</span> <span class="n">y0_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-1344"><a id="__codelineno-0-1344" name="__codelineno-0-1344"></a>    <span class="n">t_grid</span> <span class="o">=</span> <span class="n">t_grid</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-1345"><a id="__codelineno-0-1345" name="__codelineno-0-1345"></a>
</span><span id="__span-0-1346"><a id="__codelineno-0-1346" name="__codelineno-0-1346"></a>    <span class="n">y</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">y0_tuple</span><span class="p">)</span>
</span><span id="__span-0-1347"><a id="__codelineno-0-1347" name="__codelineno-0-1347"></a>    <span class="n">spike_history</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-1348"><a id="__codelineno-0-1348" name="__codelineno-0-1348"></a>
</span><span id="__span-0-1349"><a id="__codelineno-0-1349" name="__codelineno-0-1349"></a>    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-1350"><a id="__codelineno-0-1350" name="__codelineno-0-1350"></a>        <span class="n">t_k</span> <span class="o">=</span> <span class="n">t_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
</span><span id="__span-0-1351"><a id="__codelineno-0-1351" name="__codelineno-0-1351"></a>        <span class="n">y</span> <span class="o">=</span> <span class="n">ode_func</span><span class="p">(</span><span class="n">t_k</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
</span><span id="__span-0-1352"><a id="__codelineno-0-1352" name="__codelineno-0-1352"></a>        <span class="n">spike_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="__span-0-1353"><a id="__codelineno-0-1353" name="__codelineno-0-1353"></a>        <span class="c1">###here we only assume one boundary term.</span>
</span><span id="__span-0-1354"><a id="__codelineno-0-1354" name="__codelineno-0-1354"></a>        <span class="c1">###will update to (boundary_1, boundary_2, ...) if necessary.</span>
</span><span id="__span-0-1355"><a id="__codelineno-0-1355" name="__codelineno-0-1355"></a>
</span><span id="__span-0-1356"><a id="__codelineno-0-1356" name="__codelineno-0-1356"></a>    <span class="k">return</span> <span class="n">spike_history</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../snn/" class="md-footer__link md-footer__link--prev" aria-label="Previous: spikeDE.snn">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                spikeDE.snn
              </div>
            </div>
          </a>
        
        
          
          <a href="../surrogate/" class="md-footer__link md-footer__link--next" aria-label="Next: spikeDE.surrogate">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                spikeDE.surrogate
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2026 PhysAGI
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.tabs", "navigation.prune", "navigation.path", "navigation.indexes", "navigation.sections", "navigation.footer", "toc.follow", "search.suggest", "search.highlight", "search.share", "content.code.copy", "content.code.annotate"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../assets/javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>